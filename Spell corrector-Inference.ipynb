{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We tackle the problem of OCR post processing. In OCR, we map the image form of the document into the text domain. This is done first using an CNN+LSTM+CTC model, in our case based on tesseract. Since this output maps only image to text, we need something on top to validate and correct language semantics.\n",
    "\n",
    "The idea is to build a language model, that takes the OCRed text and corrects it based on language knowledge. The langauge model could be:\n",
    "- Char level: the aim is to capture the word morphology. In which case it's like a spelling correction system.\n",
    "- Word level: the aim is to capture the sentence semnatics. But such systems suffer from the OOV problem.\n",
    "- Fusion: to capture semantics and morphology language rules. The output has to be at char level, to avoid the OOV. However, the input can be char, word or both.\n",
    "\n",
    "The fusion model target is to learn:\n",
    "\n",
    "    p(char | char_context, word_context)\n",
    "\n",
    "In this workbook we use seq2seq vanilla Keras implementation, adapted from the lstm_seq2seq example on Eng-Fra translation task. The adaptation involves:\n",
    "\n",
    "- Adapt to spelling correction, on char level\n",
    "- Pre-train on a noisy, medical sentences\n",
    "- Fine tune a residual, to correct the mistakes of tesseract \n",
    "- Limit the input and output sequence lengths\n",
    "- Enusre teacher forcing auto regressive model in the decoder\n",
    "- Limit the padding per batch\n",
    "- Learning rate schedule\n",
    "- Bi-directional LSTM Encoder\n",
    "- Bi-directional GRU Encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Bidirectional, Concatenate, GRU\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, LearningRateScheduler\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from autocorrect import spell\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit gpu allocation. allow_growth, or gpu_fraction\n",
    "def gpu_alloc():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_alloc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_WER_sent(gt, pred):\n",
    "    '''\n",
    "    calculate_WER('calculating wer between two sentences', 'calculate wer between two sentences')\n",
    "    '''\n",
    "    gt_words = gt.lower().split(' ')\n",
    "    pred_words = pred.lower().split(' ')\n",
    "    d = np.zeros(((len(gt_words) + 1), (len(pred_words) + 1)), dtype=np.uint8)\n",
    "    # d = d.reshape((len(gt_words)+1, len(pred_words)+1))\n",
    "\n",
    "    # Initializing error matrix\n",
    "    for i in range(len(gt_words) + 1):\n",
    "        for j in range(len(pred_words) + 1):\n",
    "            if i == 0:\n",
    "                d[0][j] = j\n",
    "            elif j == 0:\n",
    "                d[i][0] = i\n",
    "\n",
    "    # computation\n",
    "    for i in range(1, len(gt_words) + 1):\n",
    "        for j in range(1, len(pred_words) + 1):\n",
    "            if gt_words[i - 1] == pred_words[j - 1]:\n",
    "                d[i][j] = d[i - 1][j - 1]\n",
    "            else:\n",
    "                substitution = d[i - 1][j - 1] + 1\n",
    "                insertion = d[i][j - 1] + 1\n",
    "                deletion = d[i - 1][j] + 1\n",
    "                d[i][j] = min(substitution, insertion, deletion)\n",
    "    return d[len(gt_words)][len(pred_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_WER(gt, pred):\n",
    "    '''\n",
    "\n",
    "    :param gt: list of sentences of the ground truth\n",
    "    :param pred: list of sentences of the predictions\n",
    "    both lists must have the same length\n",
    "    :return: accumulated WER\n",
    "    '''\n",
    "#    assert len(gt) == len(pred)\n",
    "    WER = 0\n",
    "    nb_w = 0\n",
    "    for i in range(len(gt)):\n",
    "        #print(gt[i])\n",
    "        #print(pred[i])\n",
    "        WER += calculate_WER_sent(gt[i], pred[i])\n",
    "        nb_w += len(gt[i])\n",
    "\n",
    "    return WER / nb_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_with_gt(file_name, num_samples, max_sent_len, min_sent_len, delimiter='\\t', gt_index=1, prediction_index=0):\n",
    "    '''Load data from txt file, with each line has: <TXT><TAB><GT>. The  target to the decoder muxt have \\t as the start trigger and \\n as the stop trigger.'''\n",
    "    cnt = 0  \n",
    "    input_texts = []\n",
    "    gt_texts = []\n",
    "    target_texts = []\n",
    "    for row in open(file_name, encoding='utf8'):\n",
    "        if cnt < num_samples :\n",
    "            #print(row)\n",
    "            sents = row.split(delimiter)\n",
    "            input_text = sents[prediction_index]\n",
    "            \n",
    "            target_text = '\\t' + sents[gt_index] + '\\n'\n",
    "            if len(input_text) > min_sent_len and len(input_text) < max_sent_len and len(target_text) > min_sent_len and len(target_text) < max_sent_len:\n",
    "                cnt += 1\n",
    "                \n",
    "                input_texts.append(input_text)\n",
    "                target_texts.append(target_text)\n",
    "                gt_texts.append(sents[gt_index])\n",
    "    return input_texts, target_texts, gt_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name, num_samples, max_sent_len, min_sent_len):\n",
    "    '''Load data from txt file, with each line has: <TXT><TAB><GT>. The  target to the decoder muxt have \\t as the start trigger and \\n as the stop trigger.'''\n",
    "    cnt = 0  \n",
    "    input_texts = []   \n",
    "    \n",
    "    #for row in open(file_name, encoding='utf8'):\n",
    "    for row in open(file_name):\n",
    "        if cnt < num_samples :            \n",
    "            input_text = row           \n",
    "            if len(input_text) > min_sent_len and len(input_text) < max_sent_len:\n",
    "                cnt += 1                \n",
    "                input_texts.append(input_text)\n",
    "    return input_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_data(input_texts, max_encoder_seq_length, num_encoder_tokens, vocab_to_int):\n",
    "    '''Prepares the input text and targets into the proper seq2seq numpy arrays'''\n",
    "    encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length),\n",
    "    dtype='float32')\n",
    "    \n",
    "    for i, input_text in enumerate(input_texts):\n",
    "        for t, char in enumerate(input_text[:max_encoder_seq_length]):\n",
    "            # c0..cn\n",
    "            encoder_input_data[i, t] = vocab_to_int[char]\n",
    "                \n",
    "    return encoder_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, encoder_model, decoder_model, num_decoder_tokens, int_to_vocab):\n",
    "    # Encode the input as state vectors.\n",
    "    encoder_outputs, h, c  = encoder_model.predict(input_seq)\n",
    "    states_value = [h,c]\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = vocab_to_int['\\t']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    #print(input_seq)\n",
    "    attention_density = []\n",
    "    i = 0\n",
    "    special_chars = ['\\\\', '/', '-', '—' , ':', '[', ']', ',', '.', '\"', ';', '%', '~', '(', ')', '{', '}', '$']\n",
    "    #special_chars = []\n",
    "    while not stop_condition:\n",
    "        #print(target_seq)\n",
    "        output_tokens, attention, h, c  = decoder_model.predict(\n",
    "            [target_seq, encoder_outputs] + states_value)\n",
    "        #print(attention.shape)\n",
    "        attention_density.append(attention[0][0])# attention is max_sent_len x 1 since we have num_time_steps = 1 for the output\n",
    "        # Sample a token\n",
    "        #print(output_tokens.shape)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        \n",
    "        #print(sampled_token_index)\n",
    "        sampled_char = int_to_vocab[sampled_token_index]\n",
    "        \n",
    "        orig_char = int_to_vocab[int(input_seq[:,i][0])]\n",
    "        \n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "            sampled_char = ''\n",
    "        \n",
    "        # Copy digits as it, since the spelling corrector is not good at digit corrections\n",
    "        if(orig_char.isdigit() or orig_char in special_chars):\n",
    "            decoded_sentence += orig_char            \n",
    "        else:\n",
    "            if(sampled_char.isdigit() or sampled_char in special_chars):\n",
    "                decoded_sentence += ''\n",
    "            else:\n",
    "                decoded_sentence += sampled_char\n",
    "        \n",
    "        #decoded_sentence += sampled_char\n",
    "\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "        \n",
    "        i += 1\n",
    "        if(i > 48):\n",
    "            i = 0\n",
    "    attention_density = np.array(attention_density)\n",
    "    \n",
    "    # Word level spell correct\n",
    "    '''\n",
    "    corrected_decoded_sentence = ''\n",
    "    for w in decoded_sentence.split(' '):\n",
    "        corrected_decoded_sentence += spell(w) + ' '\n",
    "    decoded_sentence = corrected_decoded_sentence\n",
    "    '''\n",
    "    return decoded_sentence, attention_density\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_spell_correct(decoded_sentence):\n",
    "    corrected_decoded_sentence = ''\n",
    "    special_chars = ['\\\\', '/', '-', '—' , ':', '[', ']', ',', '.', '\"', ';', '%', '~', '(', ')', '{', '}', '$', '#']\n",
    "    for w in decoded_sentence.split(' '):\n",
    "        if((len(re.findall(r'\\d+', w))==0) and not (w in special_chars)):\n",
    "            corrected_decoded_sentence += spell(w) + ' '\n",
    "        else:\n",
    "            corrected_decoded_sentence += w + ' '\n",
    "    return corrected_decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../dat/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = 'vocab-50.npz'\n",
    "model_file = 'best_model-50.hdf5'\n",
    "encoder_model_file = 'encoder_model-50.hdf5'\n",
    "decoder_model_file = 'decoder_model-50.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = np.load(file=vocab_file)\n",
    "vocab_to_int = vocab['vocab_to_int'].item()\n",
    "int_to_vocab = vocab['int_to_vocab'].item()\n",
    "max_sent_len = vocab['max_sent_len']\n",
    "min_sent_len = vocab['min_sent_len']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = sorted(list(vocab_to_int))\n",
    "num_decoder_tokens = num_encoder_tokens = len(input_characters) #int(encoder_model.layers[0].input.shape[2])\n",
    "max_encoder_seq_length = max_decoder_seq_length = max_sent_len - 1#max([len(txt) for txt in input_texts])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000000\n",
    "#tess_correction_data = os.path.join(data_path, 'test_data.txt')\n",
    "#input_texts = load_data(tess_correction_data, num_samples, max_sent_len, min_sent_len)\n",
    "\n",
    "OCR_data = os.path.join(data_path, 'new_trained_data.txt')\n",
    "#input_texts, target_texts, gt_texts = load_data_with_gt(OCR_data, num_samples, max_sent_len, min_sent_len, delimiter='|',gt_index=0, prediction_index=1)\n",
    "input_texts, target_texts, gt_texts = load_data_with_gt(OCR_data, num_samples, max_sent_len, min_sent_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1451\n",
      "Me dieal Provider Roles: Treating  \n",
      " \tMedical Provider Roles: Treating\n",
      "\n",
      "\n",
      "Provider First Name: Christine  \n",
      " \tProvider First Name: Christine\n",
      "\n",
      "\n",
      "Provider Last Name: Nolen, MD  \n",
      " \tProvider Last Name: Nolen, MD\n",
      "\n",
      "\n",
      "Address Line 1 : 7 25 American Avenue  \n",
      " \tAddress Line 1 : 725 American Avenue\n",
      "\n",
      "\n",
      "City. W’aukesha  \n",
      " \tCity: Waukesha\n",
      "\n",
      "\n",
      "StatefProvinee: ‘WI  \n",
      " \tState/Province: WI\n",
      "\n",
      "\n",
      "Postal Code: 5 31 88  \n",
      " \tPostal Code: 53188\n",
      "\n",
      "\n",
      "Country\". US  \n",
      " \tCountry:  US\n",
      "\n",
      "\n",
      "Business Telephone: (2 62) 92 8- 1000  \n",
      " \tBusiness Telephone: (262) 928- 1000\n",
      "\n",
      "\n",
      "Date ot‘Pirst Visit: 1 2/01f20 17  \n",
      " \tDate of First Visit: 12/01/2017\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "print(len(input_texts))\n",
    "for i in range(10):\n",
    "    print(input_texts[i], '\\n', target_texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ninput_texts_ = []\\nfor sent in input_texts:\\n    sent_ = ''\\n    for word in sent.split(' '):\\n        sent_ += spell(word) + ' '\\n    input_texts_.append(sent_)\\ninput_texts = input_texts_\\ninput_texts_ = []\\n# Sample data\\nprint(len(input_texts))\\nfor i in range(10):\\n    print(input_texts[i], '\\n', target_texts[i])\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spell correct before inference\n",
    "'''\n",
    "input_texts_ = []\n",
    "for sent in input_texts:\n",
    "    sent_ = ''\n",
    "    for word in sent.split(' '):\n",
    "        sent_ += spell(word) + ' '\n",
    "    input_texts_.append(sent_)\n",
    "input_texts = input_texts_\n",
    "input_texts_ = []\n",
    "# Sample data\n",
    "print(len(input_texts))\n",
    "for i in range(10):\n",
    "    print(input_texts[i], '\\n', target_texts[i])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights(model_file)\n",
    "\n",
    "model = load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 115)    13225       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) [(None, None, 512),  761856      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 115)    13225       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           bidirectional_1[0][1]            \n",
      "                                                                 bidirectional_1[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 512)          0           bidirectional_1[0][2]            \n",
      "                                                                 bidirectional_1[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 512),  1286144     embedding_2[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, None, None)   0           lstm_2[0][0]                     \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention (Activation)          (None, None, None)   0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, None, 512)    0           attention[0][0]                  \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, 1024)   0           dot_2[0][0]                      \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 115)    117875      concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,192,325\n",
      "Trainable params: 2,165,875\n",
      "Non-trainable params: 26,450\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py:269: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "encoder_model = load_model(encoder_model_file)\n",
    "decoder_model = load_model(decoder_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 115)    13225       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) [(None, None, 512),  761856      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           bidirectional_1[0][1]            \n",
      "                                                                 bidirectional_1[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 512)          0           bidirectional_1[0][2]            \n",
      "                                                                 bidirectional_1[0][4]            \n",
      "==================================================================================================\n",
      "Total params: 775,081\n",
      "Trainable params: 761,856\n",
      "Non-trainable params: 13,225\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 115)    13225       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 512),  1286144     embedding_2[0][0]                \n",
      "                                                                 input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, None, 512)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, None, None)   0           lstm_2[0][0]                     \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Activation)          (None, None, None)   0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, None, 512)    0           attention[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, 1024)   0           dot_2[0][0]                      \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 115)    117875      concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,417,244\n",
      "Trainable params: 1,404,019\n",
      "Non-trainable params: 13,225\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Me dieal Provider Roles: Treating \n",
      "GT sentence: Medical Provider Roles: Treating\n",
      "\n",
      "Decoded sentence: Medical Provider Roles:Treating \n",
      "-\n",
      "Input sentence: Provider First Name: Christine \n",
      "GT sentence: Provider First Name: Christine\n",
      "\n",
      "Decoded sentence: Provider First Name: Christine \n",
      "-\n",
      "Input sentence: Provider Last Name: Nolen, MD \n",
      "GT sentence: Provider Last Name: Nolen, MD\n",
      "\n",
      "Decoded sentence: Provider Last Name: Nolen, MD \n",
      "-\n",
      "Input sentence: Address Line 1 : 7 25 American Avenue \n",
      "GT sentence: Address Line 1 : 725 American Avenue\n",
      "\n",
      "Decoded sentence: Address Line 1 : 725 Americal Avenuer\n",
      "-\n",
      "Input sentence: City. W’aukesha \n",
      "GT sentence: City: Waukesha\n",
      "\n",
      "Decoded sentence: City.Stakes Wesk\n",
      "-\n",
      "Input sentence: StatefProvinee: ‘WI \n",
      "GT sentence: State/Province: WI\n",
      "\n",
      "Decoded sentence: StateProvinee: WI I N S\n",
      "-\n",
      "Input sentence: Postal Code: 5 31 88 \n",
      "GT sentence: Postal Code: 53188\n",
      "\n",
      "Decoded sentence: Postal Code: 5 3188 ?\n",
      "-\n",
      "Input sentence: Country\". US \n",
      "GT sentence: Country:  US\n",
      "\n",
      "Decoded sentence: Country\".US \n",
      "-\n",
      "Input sentence: Business Telephone: (2 62) 92 8- 1000 \n",
      "GT sentence: Business Telephone: (262) 928- 1000\n",
      "\n",
      "Decoded sentence: Business Telephone: (2 62) 928-100\n",
      "-\n",
      "Input sentence: Date ot‘Pirst Visit: 1 2/01f20 17 \n",
      "GT sentence: Date of First Visit: 12/01/2017\n",
      "\n",
      "Decoded sentence: Date of First Visit: 12/012017\n",
      "-\n",
      "Input sentence: Medical Protitler Information — Hospitalization \n",
      "GT sentence: Medical Provider Information - Hospitalization\n",
      "\n",
      "Decoded sentence: Medical Provider Information —Hospitalization\n",
      "-\n",
      "Input sentence: Hospital Name: W'aukesha Memorial Hospital \n",
      "GT sentence: Hospital Name: Waukesha Memorial Hospital\n",
      "\n",
      "Decoded sentence: Hospital Name: Waukesha Memorial Hospital \n",
      "-\n",
      "Input sentence: Address Line 1 : 7\" 25 Arnerie an Drive \n",
      "GT sentence: Address Line 1 : 725 American Drive\n",
      "\n",
      "Decoded sentence: Address Line 1 : 7\" 25  Address\n",
      "-\n",
      "Input sentence: City. ‘Waukesha \n",
      "GT sentence: City: Waukesha\n",
      "\n",
      "Decoded sentence: City.Stakes Lesha\n",
      "-\n",
      "Input sentence: StatefProﬁnoe: W'I \n",
      "GT sentence: State/Province: WI\n",
      "\n",
      "Decoded sentence: StateProvine: Re\n",
      "-\n",
      "Input sentence: Postal Code: 5 31 88 \n",
      "GT sentence: Postal Code: 53188\n",
      "\n",
      "Decoded sentence: Postal Code: 5 3188 ?\n",
      "-\n",
      "Input sentence: Country. US \n",
      "GT sentence: Country: US\n",
      "\n",
      "Decoded sentence: Country. US\n",
      "-\n",
      "Input sentence: Claim Type: VB Accident - Accidental Injury \n",
      "GT sentence: Claim Type: VB Accident - Accidental Injury\n",
      "\n",
      "Decoded sentence: Claim Type: VB Accident - Accidental Injury\n",
      "-\n",
      "Input sentence: Policyhold El':\"0“1l€l' In form ariorl \n",
      "GT sentence: Policyholder/Owner Information\n",
      "\n",
      "Decoded sentence: PolicyholderO:\"0r1Information artor \n",
      "-\n",
      "Input sentence: First Name: \n",
      "GT sentence: First Name:\n",
      "\n",
      "Decoded sentence: First Name: \n",
      "-\n",
      "Input sentence: Middle Narmflnitial: \n",
      "GT sentence: Middle Name/Initial:\n",
      "\n",
      "Decoded sentence: Middle NameInitial: \n",
      "-\n",
      "Input sentence: Last Name: \n",
      "GT sentence: Last Name:\n",
      "\n",
      "Decoded sentence: Last Name: \n",
      "-\n",
      "Input sentence: Social 8 ecurity Number: \n",
      "GT sentence: Social Security Number:\n",
      "\n",
      "Decoded sentence: Social 8ecurity Number:\n",
      "-\n",
      "Input sentence: Birth Date: \n",
      "GT sentence: Birth Date:\n",
      "\n",
      "Decoded sentence: Birth Date: \n",
      "-\n",
      "Input sentence: Gender: \n",
      "GT sentence: Gender:\n",
      "\n",
      "Decoded sentence: Gender: \n",
      "-\n",
      "Input sentence: Language Preference: \n",
      "GT sentence: Language Preference:\n",
      "\n",
      "Decoded sentence: Language Preference:\n",
      "-\n",
      "Input sentence: Address Line 1: \n",
      "GT sentence: Address Line 1:\n",
      "\n",
      "Decoded sentence: Address Line 1: \n",
      "-\n",
      "Input sentence: StatefProvince : \n",
      "GT sentence: State/Province:\n",
      "\n",
      "Decoded sentence: StateProvince:\n",
      "-\n",
      "Input sentence: Postal Code: \n",
      "GT sentence: Postal Code:\n",
      "\n",
      "Decoded sentence: Postal Code: \n",
      "-\n",
      "Input sentence: Country \n",
      "GT sentence: Country:\n",
      "\n",
      "Decoded sentence: Country Country Country\n",
      "-\n",
      "Input sentence: Best Phone Number to be Reached Dming the Day \n",
      "GT sentence: Best Phone Number to be Reached During the Day\n",
      "\n",
      "Decoded sentence: Best Phone Number to be Reached Duming the Day \n",
      "-\n",
      "Input sentence: Email Address: \n",
      "GT sentence: Email Address:\n",
      "\n",
      "Decoded sentence: Email Address: \n",
      "-\n",
      "Input sentence: PROI—IEALTH CARE \n",
      "GT sentence: PROHEALTH CARE\n",
      "\n",
      "Decoded sentence: PROC—DINALTH CARE\n",
      "-\n",
      "Input sentence: STATEMENT OF SERVICES \n",
      "GT sentence: STATEMENT OF SERVICES\n",
      "\n",
      "Decoded sentence: STATEMENT OF SERVICES\n",
      "-\n",
      "Input sentence: GUARANTOR ID _ I \n",
      "GT sentence: GUARANTOR ID\n",
      "\n",
      "Decoded sentence: GUARANTOR ID\n",
      "-\n",
      "Input sentence: STATEMENT DATE 1121/2018\n",
      "GT sentence: STATEMENT DATE 1/21/2018\n",
      "\n",
      "Decoded sentence: STATEMENT DATE 1121/2\n",
      "-\n",
      "Input sentence: PATIENT NAME \n",
      "GT sentence: PATIENT NAME\n",
      "\n",
      "Decoded sentence: PATIENT NAME\n",
      "-\n",
      "Input sentence: DATE \n",
      "GT sentence: DATE\n",
      "\n",
      "Decoded sentence: DATE \n",
      "-\n",
      "Input sentence: DESCRIPTION \n",
      "GT sentence: DESCRIPTION\n",
      "\n",
      "Decoded sentence: DESCRIPTION L\n",
      "-\n",
      "Input sentence: _AYMENTS \n",
      "GT sentence: PAYMENTS\n",
      "\n",
      "Decoded sentence: PAYMENTS\n",
      "-\n",
      "Input sentence: _DJUSTMENTS \n",
      "GT sentence: ADJUSTMENTS\n",
      "\n",
      "Decoded sentence: DESTMENTS\n",
      "-\n",
      "Input sentence: PAT'ENT BALANCE \n",
      "GT sentence: PATIENTS BALANCE\n",
      "\n",
      "Decoded sentence: PATIENT BALANCE \n",
      "-\n",
      "Input sentence: INVOICE NUMBER. ' . \n",
      "GT sentence: INVOICE NUMBER :\n",
      "\n",
      "Decoded sentence: INVOICE NUMBER.\n",
      "-\n",
      "Input sentence: _ Previous Visit Balance - Visit # — .\n",
      "GT sentence: Previous Visit Balance- Visit #\n",
      "\n",
      "Decoded sentence: Previous Visit Balance  -isit # \n",
      "-\n",
      "Input sentence: CURRENT TOTAL VISIT BALANCE \n",
      "GT sentence: CURRENT TOTAL VISIT BALANCE 964.70\n",
      "\n",
      "Decoded sentence: CURRENT TOTAL VISIT BALANCE\n",
      "-\n",
      "Input sentence: PLEASE PAY THIS \n",
      "GT sentence: PLEASE PAY THIS\n",
      "\n",
      "Decoded sentence: PLEASE PAY THIS\n",
      "-\n",
      "Input sentence: RETURN THIS PORTION WITH YOURIPAYMENIT \n",
      "GT sentence: RETURN THIS PORTION WITH YOUR PAYMENT\n",
      "\n",
      "Decoded sentence: RETURN THIS PORTION WITH YOUR PAYMENT \n",
      "-\n",
      "Input sentence: - VIASTERCARD\n",
      "GT sentence: MASTERCARD\n",
      "\n",
      "Decoded sentence: -ASTERCARD\n",
      "-\n",
      "Input sentence: DISCOVER\n",
      "GT sentence: DISCOVER\n",
      "\n",
      "Decoded sentence: DISCOVER\n",
      "-\n",
      "Input sentence: RATIENTIIAME\n",
      "GT sentence: PATIENT NAME\n",
      "\n",
      "Decoded sentence: PATIENT'S IAME\n",
      "-\n",
      "Input sentence: DUEDATE \n",
      "GT sentence: DUE DATE\n",
      "\n",
      "Decoded sentence: DUE DATE\n",
      "-\n",
      "Input sentence: GUARANTORID\n",
      "GT sentence: GUARANTOR ID\n",
      "\n",
      "Decoded sentence: GUARANTOR ID\n",
      "-\n",
      "Input sentence: BALANCE DUE\n",
      "GT sentence: BALANCE DUE\n",
      "\n",
      "Decoded sentence: BALANCE DUE\n",
      "-\n",
      "Input sentence: Amount Enclosed \n",
      "GT sentence: Amount Enclosed\n",
      "\n",
      "Decoded sentence: Amount Enclosed\n",
      "-\n",
      "Input sentence: MAKE CHECK PAYABLE TO PROHEALTH CARE 5535““ (PC \n",
      "GT sentence: MAKE CHECK PAYABLE TO PROHEALTH CARE\n",
      "\n",
      "Decoded sentence: MAKE CHECK PAYABLE TO PROHEALTH CARE 5535& C(RE\n",
      "-\n",
      "Input sentence: EMERGENCY MEDICAL ASSOCIATES : \n",
      "GT sentence: EMERGENCY MEDICAL ASSOCIATES\n",
      "\n",
      "Decoded sentence: EMERGENCY MEDICAL ASSOCIATIS\n",
      "-\n",
      "Input sentence: STATEMENT DATE 01/03/18 \n",
      "GT sentence: STATEMENT DATE  01/03/18\n",
      "\n",
      "Decoded sentence: STATEMENT DATE 01/03/18\n",
      "-\n",
      "Input sentence: —ue DATE _1/13/18 \n",
      "GT sentence: DUE DATE 01/13/18\n",
      "\n",
      "Decoded sentence: —ut DATE I1/13/18e\n",
      "-\n",
      "Input sentence: snow AMOUNT$ PNDHEHE \n",
      "GT sentence: SHOW AMOUNT PAID HERE $\n",
      "\n",
      "Decoded sentence: SuOW AMOUNT$PAID HERE \n",
      "-\n",
      "Input sentence: PHONE: 414—423—4120 —ue \n",
      "GT sentence: PHONE: 414-423-4120\n",
      "\n",
      "Decoded sentence: PHONE: 414—423—4120 —n\n",
      "-\n",
      "Input sentence: PNDHEHE \n",
      "GT sentence: ADDRESSEE:\n",
      "\n",
      "Decoded sentence: ADDHESS \n",
      "-\n",
      "Input sentence: - MAKE CHECKS PHASE “3' \" \n",
      "GT sentence: MAKE CHECKS PAYABLE TO:\n",
      "\n",
      "Decoded sentence: -AKE CHECKS PAYSETUME3\n",
      "-\n",
      "Input sentence: EMERGENCY MEDICAL ASSOCIATES \n",
      "GT sentence: EMERGENCY MEDICAL ASSOCIATES\n",
      "\n",
      "Decoded sentence: EMERGENCY MEDICAL ASSOCIATES\n",
      "-\n",
      "Input sentence: 64-00 INDUSTRIAL LOOP \n",
      "GT sentence: 6400 INDUSTRIAL LOOP\n",
      "\n",
      "Decoded sentence: 64-00INDUSTRIAL LOOP LOOP \n",
      "-\n",
      "Input sentence: GREENDALE, WI \n",
      "GT sentence: GREENDALE, WI\n",
      "\n",
      "Decoded sentence: GRENDIND,WIE WI D\n",
      "-\n",
      "Input sentence: STATEMENT \n",
      "GT sentence: STATEMENT\n",
      "\n",
      "Decoded sentence: STATEMENT D\n",
      "-\n",
      "Input sentence: ACCOUNT# EMA297232\n",
      "GT sentence: ACCOUNT# EMA297232\n",
      "\n",
      "Decoded sentence: ACCOUNT# EMA297232\n",
      "-\n",
      "Input sentence: PATIENT‘S NAME\n",
      "GT sentence: PATIENT'S NAME\n",
      "\n",
      "Decoded sentence: PATIENT'S NAME\n",
      "-\n",
      "Input sentence: CPT CODE\n",
      "GT sentence: CPT CODE\n",
      "\n",
      "Decoded sentence: CPT CODE\n",
      "-\n",
      "Input sentence: SERVICE DESCRIPTION\n",
      "GT sentence: SERVICE DESCRIPTION\n",
      "\n",
      "Decoded sentence: SERVICE DESCRIPTION\n",
      "-\n",
      "Input sentence: AMOUNT\n",
      "GT sentence: AMOUNT\n",
      "\n",
      "Decoded sentence: AMOUNT\n",
      "-\n",
      "Input sentence: UMR FISERV WI \n",
      "GT sentence: UMR FISERV WI BILLED ON 12/12/17\n",
      "\n",
      "Decoded sentence: UMR FISERV WI ID\n",
      "-\n",
      "Input sentence: CURRENT \n",
      "GT sentence: CURRENT \n",
      "\n",
      "Decoded sentence: CURRENT #\n",
      "-\n",
      "Input sentence: IOVER 3D DAYSI \n",
      "GT sentence: OVER 30 DAYS \n",
      "\n",
      "Decoded sentence: OVER 3DAYS DAYS\n",
      "-\n",
      "Input sentence: OVER 60 DAYS \n",
      "GT sentence: OVER 60 DAYS \n",
      "\n",
      "Decoded sentence: OVER 60 DAYS\n",
      "-\n",
      "Input sentence: OVER 30 DAYS \n",
      "GT sentence: OVER 90 DAYS \n",
      "\n",
      "Decoded sentence: OVER 30 DAYS\n",
      "-\n",
      "Input sentence: IOVER 120 DAYS \n",
      "GT sentence: OVER 120 DAYS\n",
      "\n",
      "Decoded sentence: OVER 120DAYS\n",
      "-\n",
      "Input sentence: ILAST PAY DATEI \n",
      "GT sentence: LAST PAY DATE\n",
      "\n",
      "Decoded sentence: LAST PAY DATE\n",
      "-\n",
      "Input sentence: STMT DATE \n",
      "GT sentence: STMT DATE \n",
      "\n",
      "Decoded sentence: STMT DATE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: BALANCE DUE \n",
      "GT sentence: BALANCE DUE\n",
      "\n",
      "Decoded sentence: BALANCE DUE \n",
      "-\n",
      "Input sentence: DOCTOR LEGEND \n",
      "GT sentence: DOCTOR LEGEND\n",
      "\n",
      "Decoded sentence: DOCTOR LEGEND REGED \n",
      "-\n",
      "Input sentence: 1 NOLEN, CHRISTINE, M. D. \n",
      "GT sentence: 1 NOLEN, CHRISTINE, M. D.\n",
      "\n",
      "Decoded sentence: 1 NOLEN, CHRISTINE, M. D.\n",
      "-\n",
      "Input sentence: COMMENTS \n",
      "GT sentence: COMMENTS\n",
      "\n",
      "Decoded sentence: COMMENTS\n",
      "-\n",
      "Input sentence: PRIMARY INSUR: UMR FISERV WI \n",
      "GT sentence: PRIMARY INSUR: UMR FISERV WI\n",
      "\n",
      "Decoded sentence: PRIMARY INSUR: UMR FISERV WI\n",
      "-\n",
      "Input sentence: SECONDARY INSUR: \n",
      "GT sentence: SECONDARY INSUR:\n",
      "\n",
      "Decoded sentence: SECONDARY INSUR: \n",
      "-\n",
      "Input sentence: EMERGENCY MEDICAL ASSOCIATES \n",
      "GT sentence: EMERGENCY MEDICAL ASSOCIATES\n",
      "\n",
      "Decoded sentence: EMERGENCY MEDICAL ASSOCIATES\n",
      "-\n",
      "Input sentence: PHONE: \n",
      "GT sentence: PHONE:\n",
      "\n",
      "Decoded sentence: PHONE: \n",
      "-\n",
      "Input sentence: Web user notes: \n",
      "GT sentence: Web user notes:\n",
      "\n",
      "Decoded sentence: Web user notes: \n",
      "-\n",
      "Input sentence: medical statements \n",
      "GT sentence: medical statements\n",
      "\n",
      "Decoded sentence: medical statements \n",
      "-\n",
      "Input sentence: unum‘D \n",
      "GT sentence: unum\n",
      "\n",
      "Decoded sentence: unum\n",
      "-\n",
      "Input sentence: . . O The Benefits Center \n",
      "GT sentence: The Benefits Center\n",
      "\n",
      "Decoded sentence: .h. Benefits Center \n",
      "-\n",
      "Input sentence: (Not for FMLA Requests) \n",
      "GT sentence: (Not for FMLA Requests)\n",
      "\n",
      "Decoded sentence: (Not for FMLA Requests)\n",
      "-\n",
      "Input sentence: Electronically Signed Insured 5 Signature \n",
      "GT sentence: Electronically Signed Insured's Signature\n",
      "\n",
      "Decoded sentence: Electronically Signed Insured 5ignature \n",
      "-\n",
      "Input sentence: 03/14/2018 Date Signed \n",
      "GT sentence: 03/14/2018 Date Signed\n",
      "\n",
      "Decoded sentence: 03/14/2018 Date Signed Insured \n",
      "-\n",
      "Input sentence: Printed Name \n",
      "GT sentence: Printed Name\n",
      "\n",
      "Decoded sentence: Printed Name \n",
      "-\n",
      "Input sentence: Seeial Security Number \n",
      "GT sentence: Social Security Number\n",
      "\n",
      "Decoded sentence: Social Security Number \n",
      "-\n",
      "Input sentence: CL-1116 ( \n",
      "GT sentence: CL-1116\n",
      "\n",
      "Decoded sentence: CL-1116 (d\n",
      "-\n",
      "Input sentence: Daytime Phone: \n",
      "GT sentence: Daytime Phone:\n",
      "\n",
      "Decoded sentence: Daytime Phone: \n",
      "-\n",
      "Input sentence: Dependent Information \n",
      "GT sentence: Dependent Information\n",
      "\n",
      "Decoded sentence: Dependent Information\n",
      "-\n",
      "Input sentence: First Name: \n",
      "GT sentence: First Name:\n",
      "\n",
      "Decoded sentence: First Name: \n",
      "-\n",
      "Input sentence: Middle Nameﬂnitial: \n",
      "GT sentence: Middle Name/Initial:\n",
      "\n",
      "Decoded sentence: Middle NameInitia: \n",
      "-\n",
      "Input sentence: Last Name: \n",
      "GT sentence: Last Name:\n",
      "\n",
      "Decoded sentence: Last Name: \n",
      "-\n",
      "Input sentence: Social Security Number: \n",
      "GT sentence: Social Security Number:\n",
      "\n",
      "Decoded sentence: Social Security Number: \n",
      "-\n",
      "Input sentence: Birth Date: \n",
      "GT sentence: Birth Date:\n",
      "\n",
      "Decoded sentence: Birth Date: \n",
      "-\n",
      "Input sentence: Gender: \n",
      "GT sentence: Gender:\n",
      "\n",
      "Decoded sentence: Gender: \n",
      "-\n",
      "Input sentence: Claim Event Information \n",
      "GT sentence: Claim Event Information\n",
      "\n",
      "Decoded sentence: Claim Event Information\n",
      "-\n",
      "Input sentence: Accident Work Related: No\n",
      "GT sentence: Accident Work Related: No\n",
      "\n",
      "Decoded sentence: Accident Work Related: No\n",
      "-\n",
      "Input sentence: Time ofAccident: 8:00 PM\n",
      "GT sentence: Time of Accident: 8:00 PM\n",
      "\n",
      "Decoded sentence: Time of Acciden:8:00 P\n",
      "-\n",
      "Input sentence: Accident Date: \n",
      "GT sentence: Accident Date: 12/01/2018\n",
      "\n",
      "Decoded sentence: Accident Date: \n",
      "-\n",
      "Input sentence: 5 n rg erji' Inform ari on \n",
      "GT sentence: Surgery Information\n",
      "\n",
      "Decoded sentence: 5urgery Information arton \n",
      "-\n",
      "Input sentence: 15 Surgery Required: No \n",
      "GT sentence: Is Surgery Required: No\n",
      "\n",
      "Decoded sentence: 15 Surgery Required: No \n",
      "-\n",
      "Input sentence: Medical Provider Information - Physician \n",
      "GT sentence: Medical Provider Information - Physician\n",
      "\n",
      "Decoded sentence: Medical Provider Information - Physician\n",
      "-\n",
      "Input sentence: Medical Provider Specialty: ElVIS \n",
      "GT sentence: Medical Provider Specialty: EMS\n",
      "\n",
      "Decoded sentence: Medical Provider Specialty: Elait\n",
      "-\n",
      "Input sentence: UﬂUﬁT \n",
      "GT sentence: unum\n",
      "\n",
      "Decoded sentence: unum\n",
      "-\n",
      "Input sentence: August 23, 2017 \n",
      "GT sentence: August 28, 2017\n",
      "\n",
      "Decoded sentence: Aujust 23,2017\n",
      "-\n",
      "Input sentence: Confirmation of Coverage \n",
      "GT sentence: Confirmation of Coverage\n",
      "\n",
      "Decoded sentence: Confirmation of Coverage\n",
      "-\n",
      "Input sentence: Employer: \n",
      "GT sentence: Employer:\n",
      "\n",
      "Decoded sentence: Employer:\n",
      "-\n",
      "Input sentence: Group Policy #: \n",
      "GT sentence: Group Policy #:\n",
      "\n",
      "Decoded sentence: Group Policy #:\n",
      "-\n",
      "Input sentence: Customer Policy #: \n",
      "GT sentence: Customer Policy #:\n",
      "\n",
      "Decoded sentence: Customer Policy #:\n",
      "-\n",
      "Input sentence: EE Name: \n",
      "GT sentence: EE Name:\n",
      "\n",
      "Decoded sentence: EE Name: \n",
      "-\n",
      "Input sentence: MONTANO \n",
      "GT sentence: MONTANO\n",
      "\n",
      "Decoded sentence: MONTANO\n",
      "-\n",
      "Input sentence: Total Employee Benefit Amount: $20,000.00 \n",
      "GT sentence: Total Employee Benefit Amount: $20,000.00\n",
      "\n",
      "Decoded sentence: Total Employee Benefit Amount: $20,000.\n",
      "-\n",
      "Input sentence: Total Monthly Premium: $40.40 \n",
      "GT sentence: Total Monthly Premium: $40.40\n",
      "\n",
      "Decoded sentence: Total Monthly Premium: $40.40 ?\n",
      "-\n",
      "Input sentence: Date ofVisithdmission \n",
      "GT sentence: Date of Visit/Admission: 12/01/2017\n",
      "\n",
      "Decoded sentence: Date of VisitAdmission \n",
      "-\n",
      "Input sentence: Date ot’DischaIge: 1210112017 \n",
      "GT sentence: Date of Discharge: 12/01/2017\n",
      "\n",
      "Decoded sentence: Date of Discharge: 1210112017\n",
      "-\n",
      "Input sentence: Proc edure : Cleaning, may: bandage\n",
      "GT sentence: Procedure: Cleaning, xray, bandage\n",
      "\n",
      "Decoded sentence: Procedure :leaning ,and :andage\n",
      "-\n",
      "Input sentence: E11113] arm en t In formation \n",
      "GT sentence: Employment Information\n",
      "\n",
      "Decoded sentence: E11113] arment Information\n",
      "-\n",
      "Input sentence: Employer Name: \n",
      "GT sentence: Employer Name:\n",
      "\n",
      "Decoded sentence: Employer Name: \n",
      "-\n",
      "Input sentence: Electronic Submission \n",
      "GT sentence: Electronic Submission\n",
      "\n",
      "Decoded sentence: Electronic Submission\n",
      "-\n",
      "Input sentence: Claim Event Identiﬁer: \n",
      "GT sentence: Claim Event Identifier:\n",
      "\n",
      "Decoded sentence: Claim Event Identifie: \n",
      "-\n",
      "Input sentence: Submission Date: 03411419018\n",
      "GT sentence: Submission Date: 03/14/2018\n",
      "\n",
      "Decoded sentence: Submission Date: 0341141901\n",
      "-\n",
      "Input sentence: Electronically Signed Indicator: Yes\n",
      "GT sentence: Electronically Signed Indicator:  Yes\n",
      "\n",
      "Decoded sentence: Electronically Signed Indicator: Yes\n",
      "-\n",
      "Input sentence: TWIN CITIES \n",
      "GT sentence: TWIN CITIES\n",
      "\n",
      "Decoded sentence: TWIN CITIES ORTIOS \n",
      "-\n",
      "Input sentence: ORTHOPEDICS \n",
      "GT sentence: ORTHOPEDICS\n",
      "\n",
      "Decoded sentence: ORTHOPEDICS\n",
      "-\n",
      "Input sentence: Twin Cities Orthopedics-Burnsville \n",
      "GT sentence: Twin Cities Orthopedics-Burnsville\n",
      "\n",
      "Decoded sentence: Twin Cities Orthopedics-Burnsville\n",
      "-\n",
      "Input sentence: MRN: . Date of Service: 02/ 15/201 8 9:30AM \n",
      "GT sentence: MRN: Date of Service: 02/15/2018 9:30AM\n",
      "\n",
      "Decoded sentence: MRN: .ate Date of Serv:c02/15/20189:30\n",
      "-\n",
      "Input sentence: Provider: Jamie Birkelo PA \n",
      "GT sentence: Provider: Jamie Birkelo PA\n",
      "\n",
      "Decoded sentence: Provider: Jamie Birkelo PA\n",
      "-\n",
      "Input sentence: Chief Complaint \n",
      "GT sentence: Chief Complaint\n",
      "\n",
      "Decoded sentence: Chief Complaint \n",
      "-\n",
      "Input sentence: Post-Op \n",
      "GT sentence: Post-Op\n",
      "\n",
      "Decoded sentence: Post-Op\n",
      "-\n",
      "Input sentence: Active Problems \n",
      "GT sentence: Active Problems\n",
      "\n",
      "Decoded sentence: Active Problems \n",
      "-\n",
      "Input sentence: 1. Knee injury \n",
      "GT sentence: 1. Knee injury\n",
      "\n",
      "Decoded sentence: 1. Knee injury\n",
      "-\n",
      "Input sentence: Social History \n",
      "GT sentence: Social History\n",
      "\n",
      "Decoded sentence: Social History\n",
      "-\n",
      "Input sentence: 0 Age reporting \n",
      "GT sentence: • Age reporting\n",
      "\n",
      "Decoded sentence: 0 Age reporting Corting Sporite\n",
      "-\n",
      "Input sentence: 0 Consumes alcohol \n",
      "GT sentence: • Consumes alcohol\n",
      "\n",
      "Decoded sentence: 0 Consumes alcohol \n",
      "-\n",
      "Input sentence: I Exercises regularly \n",
      "GT sentence: • Exercises regularly\n",
      "\n",
      "Decoded sentence: I Exercises regularly \n",
      "-\n",
      "Input sentence: - Identifies as female gender \n",
      "GT sentence: • Identifies as female gender\n",
      "\n",
      "Decoded sentence: - Identifies as female gender\n",
      "-\n",
      "Input sentence: 0 Lives with family \n",
      "GT sentence: • Lives with family\n",
      "\n",
      "Decoded sentence: 0 Lives with family\n",
      "-\n",
      "Input sentence: 0 Married \n",
      "GT sentence: • Married\n",
      "\n",
      "Decoded sentence: 0 Married \n",
      "-\n",
      "Input sentence: 0 Tobacco quit date established (287.891) \n",
      "GT sentence: • Tobacco quit date established (287.891)\n",
      "\n",
      "Decoded sentence: 0 Tobacco quit date established (287.891)\n",
      "-\n",
      "Input sentence: 0 : 10 years \n",
      "GT sentence: • : 10 years\n",
      "\n",
      "Decoded sentence: 0 : 10 years\n",
      "-\n",
      "Input sentence: Current Made \n",
      "GT sentence: Current Made\n",
      "\n",
      "Decoded sentence: Current Meds\n",
      "-\n",
      "Input sentence: 3. Multi-Vitamin TABS; \n",
      "GT sentence: 3. Multi-Vitamin TABS;\n",
      "\n",
      "Decoded sentence: 3. Multi-Vitamin TABS;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Therapy: (Recordedz24Jan2018) to Recorded \n",
      "GT sentence: Therapy: (Recorded:24Jan2018) to Recorded\n",
      "\n",
      "Decoded sentence: Therapy: (Recorded24Jan2018) to Recorded\n",
      "-\n",
      "Input sentence: 4. Probiotic CAPS; \n",
      "GT sentence: 4. Probiotic CAPS;\n",
      "\n",
      "Decoded sentence: 4. Probiotic CAPS;\n",
      "-\n",
      "Input sentence: Therapy: 21Jan2018 to Recorded \n",
      "GT sentence: Therapy: 21Jan2018 to Recorded\n",
      "\n",
      "Decoded sentence: Therapy: 21Jan2018 to Recorded\n",
      "-\n",
      "Input sentence: -- McMurray’s \n",
      "GT sentence: -- McMurray’s\n",
      "\n",
      "Decoded sentence: -- McMurray’s\n",
      "-\n",
      "Input sentence: symmetric dial at 0 and 90 degrees \n",
      "GT sentence: symmetric dial at 0 and 90 degrees\n",
      "\n",
      "Decoded sentence: symmetric dial at 0 and 90 degrees \n",
      "-\n",
      "Input sentence: ResultsIData \n",
      "GT sentence: Results/Data\n",
      "\n",
      "Decoded sentence: ResultsDate\n",
      "-\n",
      "Input sentence: Right knee MRI IMPRESSION: \n",
      "GT sentence: Right knee MRI IMPRESSION:\n",
      "\n",
      "Decoded sentence: Right knee MRI IMPRESSION:\n",
      "-\n",
      "Input sentence: 1. ACL tear. \n",
      "GT sentence: 1. ACL tear.\n",
      "\n",
      "Decoded sentence: 1. ACL tear.\n",
      "-\n",
      "Input sentence: 5. Patellar apical grade 1-2 chondromalacia. \n",
      "GT sentence: 5. Patellar apical grade 1-2 chondromalacia.\n",
      "\n",
      "Decoded sentence: 5. Patellar apical grade 1-2 chondromacia\n",
      "-\n",
      "Input sentence: Diagnosis \n",
      "GT sentence: Diagnosis\n",
      "\n",
      "Decoded sentence: Diagnosis\n",
      "-\n",
      "Input sentence: Right knee ACL rupture and high grade MCL tear \n",
      "GT sentence: Right knee ACL rupture and high grade MCL tear\n",
      "\n",
      "Decoded sentence:  Right knee ACL rupture and hight rader MAL tear \n",
      "-\n",
      "Input sentence: Plan \n",
      "GT sentence: Plan\n",
      "\n",
      "Decoded sentence: Plan Cand\n",
      "-\n",
      "Input sentence: Health Maintenance \n",
      "GT sentence: Health Maintenance\n",
      "\n",
      "Decoded sentence: Health Maintenance \n",
      "-\n",
      "Input sentence: DiscussionlSumrnary \n",
      "GT sentence: Discussion/Sumrnary\n",
      "\n",
      "Decoded sentence: DiscussionSumrnary \n",
      "-\n",
      "Input sentence: Scribe - Statements \n",
      "GT sentence: Scribe - Statements\n",
      "\n",
      "Decoded sentence: Scribe - Statements \n",
      "-\n",
      "Input sentence: Signatures \n",
      "GT sentence: Signatures\n",
      "\n",
      "Decoded sentence: Signatures\n",
      "-\n",
      "Input sentence: TWIN CITIES \n",
      "GT sentence: TWIN CITIES\n",
      "\n",
      "Decoded sentence: TWIN CITIES ORTIOS \n",
      "-\n",
      "Input sentence: ORTHOPEDICS \n",
      "GT sentence: ORTHOPEDICS\n",
      "\n",
      "Decoded sentence: ORTHOPEDICS\n",
      "-\n",
      "Input sentence: Twin Cities Orthopedics-Burnsville \n",
      "GT sentence: Twin Cities Orthopedics-Burnsville\n",
      "\n",
      "Decoded sentence: Twin Cities Orthopedics-Burnsville\n",
      "-\n",
      "Input sentence: MRN: Date of Service: 01/24/2018 9:10AM \n",
      "GT sentence: MRN: Date of Service: 01/24/2018 9:10AM\n",
      "\n",
      "Decoded sentence: MRN: Date of Service: 01/24/2018 9:10AM\n",
      "-\n",
      "Input sentence: Provider: Jason Holm MD. \n",
      "GT sentence: Provider: Jason Holm M.D.\n",
      "\n",
      "Decoded sentence: Provider: Jason Holm M. \n",
      "-\n",
      "Input sentence: Chief Complaint \n",
      "GT sentence: Chief Complaint\n",
      "\n",
      "Decoded sentence: Chief Complaint \n",
      "-\n",
      "Input sentence: right knee (DOE 1l21f18) \n",
      "GT sentence: right knee (DOI 1/21/18)\n",
      "\n",
      "Decoded sentence: Bight knee (DOB 12118\n",
      "-\n",
      "Input sentence: History of Present illness \n",
      "GT sentence: History of Present Illness\n",
      "\n",
      "Decoded sentence: History of Present Illness\n",
      "-\n",
      "Input sentence: Review of Systems \n",
      "GT sentence: Review of Systems\n",
      "\n",
      "Decoded sentence: Review of Systems \n",
      "-\n",
      "Input sentence: General: no constitutional symptoms. \n",
      "GT sentence: General: no constitutional symptoms.\n",
      "\n",
      "Decoded sentence: General: no constitutional symptoms.\n",
      "-\n",
      "Input sentence: Cardiovascular: no cardiovascular symptoms. \n",
      "GT sentence: Cardiovascular: no cardiovascular symptoms.\n",
      "\n",
      "Decoded sentence: Cardiovascular: no cardiovascular symptoms.\n",
      "-\n",
      "Input sentence: Skin no skin symptoms. \n",
      "GT sentence: Skin no skin symptoms.\n",
      "\n",
      "Decoded sentence: Skin no skin symptoms.\n",
      "-\n",
      "Input sentence: ENT: no ears, nose or throat symptoms. \n",
      "GT sentence: ENT: no ears, nose or throat symptoms.\n",
      "\n",
      "Decoded sentence: ENT: no eare, nose throat symptoms\n",
      "-\n",
      "Input sentence: Endocrine: no endocrine symptoms. \n",
      "GT sentence: Endocrine: no endocrine symptoms.\n",
      "\n",
      "Decoded sentence: Endocrine: no endocrine symptoms.\n",
      "-\n",
      "Input sentence: Eyes: glasseslcontact. \n",
      "GT sentence: Eyes: glasses/contact.\n",
      "\n",
      "Decoded sentence: Eyes: glassescontact.\n",
      "-\n",
      "Input sentence: Genitourinary: no genitourinary symptoms. \n",
      "GT sentence: Genitourinary: no genitourinary symptoms.\n",
      "\n",
      "Decoded sentence: Genitourinary: no genitourinary symptoms.\n",
      "-\n",
      "Input sentence: HematologicILymphatlc no hematologic symptoms. \n",
      "GT sentence: Hematologic/Lymphatlc no hematologic symptoms.\n",
      "\n",
      "Decoded sentence: HematologicLymphatlc no hematologic symptoms.\n",
      "-\n",
      "Input sentence: Neurological: no neurological symptoms. \n",
      "GT sentence: Neurological: no neurological symptoms.\n",
      "\n",
      "Decoded sentence: Neurological: no neurological symptoms.\n",
      "-\n",
      "Input sentence: Psychiatric: no psychiatric symptoms. \n",
      "GT sentence: Psychiatric: no psychiatric symptoms.\n",
      "\n",
      "Decoded sentence: Psychiatric: no psychiatric symptoms.\n",
      "-\n",
      "Input sentence: Respiratory: no respiratory symptoms. \n",
      "GT sentence: Respiratory: no respiratory symptoms.\n",
      "\n",
      "Decoded sentence: Respiratory: no respiratory symptoms.\n",
      "-\n",
      "Input sentence: Active Problems \n",
      "GT sentence: Active Problems\n",
      "\n",
      "Decoded sentence: Active Problems \n",
      "-\n",
      "Input sentence: 1. Knee injury (889.90XA) \n",
      "GT sentence: 1. Knee injury (S89.90XA)\n",
      "\n",
      "Decoded sentence: 1. Knee injury (889.90XA)\n",
      "-\n",
      "Input sentence: Past Medical History \n",
      "GT sentence: Past Medical History\n",
      "\n",
      "Decoded sentence: Past Medical History\n",
      "-\n",
      "Input sentence: 0 No signiﬁcant past medical history \n",
      "GT sentence: • No significant past medical history\n",
      "\n",
      "Decoded sentence: 0 No significant past medical history\n",
      "-\n",
      "Input sentence: Surgical History \n",
      "GT sentence: Surgical History\n",
      "\n",
      "Decoded sentence: Surgical History\n",
      "-\n",
      "Input sentence: 0 History of Ankle Surgery \n",
      "GT sentence: • History of Ankle Surgery\n",
      "\n",
      "Decoded sentence: 0 History of Ankle Surgery \n",
      "-\n",
      "Input sentence: Family History \n",
      "GT sentence: Family History\n",
      "\n",
      "Decoded sentence: Family History\n",
      "-\n",
      "Input sentence: TWIN CITIES \n",
      "GT sentence: TWIN CITIES\n",
      "\n",
      "Decoded sentence: TWIN CITIES ORTIOS \n",
      "-\n",
      "Input sentence: ORTHOPEDICS \n",
      "GT sentence: ORTHOPEDICS\n",
      "\n",
      "Decoded sentence: ORTHOPEDICS\n",
      "-\n",
      "Input sentence: Twin Cities Orthopedics-Burnsville \n",
      "GT sentence: Twin Cities Orthopedics-Burnsville\n",
      "\n",
      "Decoded sentence: Twin Cities Orthopedics-Burnsville\n",
      "-\n",
      "Input sentence: Date of Service: 01/21/2018 7:30PM \n",
      "GT sentence: Date of Service: 01/21/2018 7:30PM\n",
      "\n",
      "Decoded sentence: Date of Service: 01/21/2018 7:30\n",
      "-\n",
      "Input sentence: Provider: David Feivor PA-C \n",
      "GT sentence: Provider: David Feivor PA-C\n",
      "\n",
      "Decoded sentence: Provider: David Feivor PA-C AT\n",
      "-\n",
      "Input sentence: Chief Complaint \n",
      "GT sentence: Chief Complaint\n",
      "\n",
      "Decoded sentence: Chief Complaint \n",
      "-\n",
      "Input sentence: Right knee injury \n",
      "GT sentence: Right knee injury\n",
      "\n",
      "Decoded sentence: Right knee injury\n",
      "-\n",
      "Input sentence: DOI 112112018 \n",
      "GT sentence: DOI 1/21/2018\n",
      "\n",
      "Decoded sentence: DO 112112018\n",
      "-\n",
      "Input sentence: History of Present Illness - \n",
      "GT sentence: History of Present Illness\n",
      "\n",
      "Decoded sentence: History of Present Illness\n",
      "-\n",
      "Input sentence: Review of Systems \n",
      "GT sentence: Review of Systems\n",
      "\n",
      "Decoded sentence: Review of Systems \n",
      "-\n",
      "Input sentence: General: no constitutional symptoms. \n",
      "GT sentence: General: no constitutional symptoms.\n",
      "\n",
      "Decoded sentence: General: no constitutional symptoms.\n",
      "-\n",
      "Input sentence: Cardlovascular: no cardiovascular symptoms. \n",
      "GT sentence: Cardiovascular: no cardiovascular symptoms.\n",
      "\n",
      "Decoded sentence: Cardiovascular: no cardiovascular symptoms.\n",
      "-\n",
      "Input sentence: Skin no skin symptoms. \n",
      "GT sentence: Skin no skin symptoms.\n",
      "\n",
      "Decoded sentence: Skin no skin symptoms.\n",
      "-\n",
      "Input sentence: ENT: no ears. nose or throat symptoms. \n",
      "GT sentence: ENT: no ears, nose or throat symptoms.\n",
      "\n",
      "Decoded sentence: ENT: no eare. nose throat symptoms\n",
      "-\n",
      "Input sentence: Endocrine: no endocrine symptoms. \n",
      "GT sentence: Endocrine: no endocrine symptoms.\n",
      "\n",
      "Decoded sentence: Endocrine: no endocrine symptoms.\n",
      "-\n",
      "Input sentence: Eyes: glassesicontact. \n",
      "GT sentence: Eyes: glasses/contact.\n",
      "\n",
      "Decoded sentence: Eyes: glassessiconta.t\n",
      "-\n",
      "Input sentence: Genitourinary: no genitourinary symptoms. \n",
      "GT sentence: Genitourinary: no genitourinary symptoms.\n",
      "\n",
      "Decoded sentence: Genitourinary: no genitourinary symptoms.\n",
      "-\n",
      "Input sentence: HematologiciLymphatic no hematologic symptoms. \n",
      "GT sentence: Hematologic/Lymphatic no hematologic symptoms.\n",
      "\n",
      "Decoded sentence: HematologicLymphatic no hematologic symptoms.\n",
      "-\n",
      "Input sentence: Neurological: no neurological symptoms. \n",
      "GT sentence: Neurological: no neurological symptoms.\n",
      "\n",
      "Decoded sentence: Neurological: no neurological symptoms.\n",
      "-\n",
      "Input sentence: Psychiatric: no psychiatric symptoms. \n",
      "GT sentence: Psychiatric: no psychiatric symptoms.\n",
      "\n",
      "Decoded sentence: Psychiatric: no psychiatric symptoms.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-55b4fbcaeb03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_input_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtarget_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdecoded_sentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_decoder_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_to_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-bcd88bcf6533>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq, encoder_model, decoder_model, num_decoder_tokens, int_to_vocab)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#print(target_seq)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         output_tokens, attention, h, c  = decoder_model.predict(\n\u001b[0;32m---> 22\u001b[0;31m             [target_seq, encoder_outputs] + states_value)\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m#print(attention.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mattention_density\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# attention is max_sent_len x 1 since we have num_time_steps = 1 for the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1165\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "encoder_input_data = vectorize_data(input_texts=input_texts, max_encoder_seq_length=max_encoder_seq_length, num_encoder_tokens=num_encoder_tokens, vocab_to_int=vocab_to_int)\n",
    "\n",
    "# Sample output from train data\n",
    "decoded_sentences = []\n",
    "\n",
    "for seq_index in range(len(input_texts)):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    target_text = gt_texts[seq_index]\n",
    "    decoded_sentence,_  = decode_sequence(input_seq, encoder_model, decoder_model, num_decoder_tokens, int_to_vocab)\n",
    "    \n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('GT sentence:', target_text)\n",
    "    print('Decoded sentence:', decoded_sentence)   \n",
    "    decoded_sentences.append(decoded_sentence)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Gender Date of Birth(mm / dd / yyyy) Does the\n",
      "Decoded sentence: Gender Date of Birth(mm/ddy/ Ded)Ded the Dey\n"
     ]
    }
   ],
   "source": [
    "input_text = 'Gender Date of Birth(mm / dd / yyyy) Does the'\n",
    "\n",
    "encoder_input_data = vectorize_data(input_texts=[input_text], max_encoder_seq_length=max_encoder_seq_length, num_encoder_tokens=num_encoder_tokens, vocab_to_int=vocab_to_int)\n",
    "\n",
    "\n",
    "input_seq = encoder_input_data\n",
    "\n",
    "decoded_sentence,_  = decode_sequence(input_seq, encoder_model, decoder_model, num_decoder_tokens, int_to_vocab)\n",
    "\n",
    "print('-')\n",
    "print('Input sentence:', input_text)\n",
    "print('Decoded sentence:', decoded_sentence)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WER_spell_correction = calculate_WER(gt_texts, decoded_sentences)\n",
    "print('WER_spell_correction |TEST= ', WER_spell_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WER_OCR = calculate_WER(gt_texts, input_texts)\n",
    "print('WER_OCR |TEST= ', WER_OCR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
