{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We tackle the problem of OCR post processing. In OCR, we map the image form of the document into the text domain. This is done first using an CNN+LSTM+CTC model, in our case based on tesseract. Since this output maps only image to text, we need something on top to validate and correct language semantics.\n",
    "\n",
    "The idea is to build a language model, that takes the OCRed text and corrects it based on language knowledge. The langauge model could be:\n",
    "- Char level: the aim is to capture the word morphology. In which case it's like a spelling correction system.\n",
    "- Word level: the aim is to capture the sentence semnatics. But such systems suffer from the OOV problem.\n",
    "- Fusion: to capture semantics and morphology language rules. The output has to be at char level, to avoid the OOV. However, the input can be char, word or both.\n",
    "\n",
    "The fusion model target is to learn:\n",
    "\n",
    "    p(char | char_context, word_context)\n",
    "\n",
    "In this workbook we use seq2seq vanilla Keras implementation, adapted from the lstm_seq2seq example on Eng-Fra translation task. The adaptation involves:\n",
    "\n",
    "- Adapt to spelling correction, on char level\n",
    "- Pre-train on a noisy, medical sentences\n",
    "- Fine tune a residual, to correct the mistakes of tesseract \n",
    "- Limit the input and output sequence lengths\n",
    "- Enusre teacher forcing auto regressive model in the decoder\n",
    "- Limit the padding per batch\n",
    "- Learning rate schedule\n",
    "- Bi-directional LSTM Encoder\n",
    "- Bi-directional GRU Encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmad/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Bidirectional, Concatenate, GRU\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, LearningRateScheduler\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit gpu allocation. allow_growth, or gpu_fraction\n",
    "def gpu_alloc():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_alloc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_WER_sent(gt, pred):\n",
    "    '''\n",
    "    calculate_WER('calculating wer between two sentences', 'calculate wer between two sentences')\n",
    "    '''\n",
    "    gt_words = gt.lower().split(' ')\n",
    "    pred_words = pred.lower().split(' ')\n",
    "    d = np.zeros(((len(gt_words) + 1), (len(pred_words) + 1)), dtype=np.uint8)\n",
    "    # d = d.reshape((len(gt_words)+1, len(pred_words)+1))\n",
    "\n",
    "    # Initializing error matrix\n",
    "    for i in range(len(gt_words) + 1):\n",
    "        for j in range(len(pred_words) + 1):\n",
    "            if i == 0:\n",
    "                d[0][j] = j\n",
    "            elif j == 0:\n",
    "                d[i][0] = i\n",
    "\n",
    "    # computation\n",
    "    for i in range(1, len(gt_words) + 1):\n",
    "        for j in range(1, len(pred_words) + 1):\n",
    "            if gt_words[i - 1] == pred_words[j - 1]:\n",
    "                d[i][j] = d[i - 1][j - 1]\n",
    "            else:\n",
    "                substitution = d[i - 1][j - 1] + 1\n",
    "                insertion = d[i][j - 1] + 1\n",
    "                deletion = d[i - 1][j] + 1\n",
    "                d[i][j] = min(substitution, insertion, deletion)\n",
    "    return d[len(gt_words)][len(pred_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_WER(gt, pred):\n",
    "    '''\n",
    "\n",
    "    :param gt: list of sentences of the ground truth\n",
    "    :param pred: list of sentences of the predictions\n",
    "    both lists must have the same length\n",
    "    :return: accumulated WER\n",
    "    '''\n",
    "#    assert len(gt) == len(pred)\n",
    "    WER = 0\n",
    "    nb_w = 0\n",
    "    for i in range(len(gt)):\n",
    "        #print(gt[i])\n",
    "        #print(pred[i])\n",
    "        WER += calculate_WER_sent(gt[i], pred[i])\n",
    "        nb_w += len(gt[i])\n",
    "\n",
    "    return WER / nb_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_with_gt(file_name, num_samples, max_sent_len, min_sent_len, delimiter='\\t', gt_index=1, prediction_index=0):\n",
    "    '''Load data from txt file, with each line has: <TXT><TAB><GT>. The  target to the decoder muxt have \\t as the start trigger and \\n as the stop trigger.'''\n",
    "    cnt = 0  \n",
    "    input_texts = []\n",
    "    gt_texts = []\n",
    "    target_texts = []\n",
    "    for row in open(file_name, encoding='utf8'):\n",
    "        if cnt < num_samples :\n",
    "            #print(row)\n",
    "            sents = row.split(delimiter)\n",
    "            input_text = sents[prediction_index]\n",
    "            \n",
    "            target_text = '\\t' + sents[gt_index] + '\\n'\n",
    "            if len(input_text) > min_sent_len and len(input_text) < max_sent_len and len(target_text) > min_sent_len and len(target_text) < max_sent_len:\n",
    "                cnt += 1\n",
    "                \n",
    "                input_texts.append(input_text)\n",
    "                target_texts.append(target_text)\n",
    "                gt_texts.append(sents[gt_index])\n",
    "    return input_texts, target_texts, gt_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name, num_samples, max_sent_len, min_sent_len):\n",
    "    '''Load data from txt file, with each line has: <TXT><TAB><GT>. The  target to the decoder muxt have \\t as the start trigger and \\n as the stop trigger.'''\n",
    "    cnt = 0  \n",
    "    input_texts = []   \n",
    "    \n",
    "    #for row in open(file_name, encoding='utf8'):\n",
    "    for row in open(file_name):\n",
    "        if cnt < num_samples :            \n",
    "            input_text = row           \n",
    "            if len(input_text) > min_sent_len and len(input_text) < max_sent_len:\n",
    "                cnt += 1                \n",
    "                input_texts.append(input_text)\n",
    "    return input_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_data(input_texts, max_encoder_seq_length, num_encoder_tokens, vocab_to_int):\n",
    "    '''Prepares the input text and targets into the proper seq2seq numpy arrays'''\n",
    "    encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "    for i, input_text in enumerate(input_texts):\n",
    "        for t, char in enumerate(input_text):\n",
    "            # c0..cn\n",
    "            encoder_input_data[i, t, vocab_to_int[char]] = 1.\n",
    "                \n",
    "    return encoder_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, encoder_model, decoder_model, num_decoder_tokens, int_to_vocab):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, vocab_to_int['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = int_to_vocab[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../dat/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = 'vocab.npz'\n",
    "model_file = 'best_model.hdf5'\n",
    "encoder_model_file = 'encoder_model.hdf5'\n",
    "decoder_model_file = 'decoder_model.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = np.load(file=vocab_file)\n",
    "vocab_to_int = vocab['vocab_to_int'].item()\n",
    "int_to_vocab = vocab['int_to_vocab'].item()\n",
    "max_sent_len = vocab['max_sent_len']\n",
    "min_sent_len = vocab['min_sent_len']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = sorted(list(vocab_to_int))\n",
    "num_decoder_tokens = num_encoder_tokens = len(input_characters) #int(encoder_model.layers[0].input.shape[2])\n",
    "max_encoder_seq_length = max_decoder_seq_length = max_sent_len - 1#max([len(txt) for txt in input_texts])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000000\n",
    "#tess_correction_data = os.path.join(data_path, 'test_data.txt')\n",
    "#input_texts = load_data(tess_correction_data, num_samples, max_sent_len, min_sent_len)\n",
    "\n",
    "OCR_data = os.path.join(data_path, 'output_handwritten.txt')\n",
    "input_texts, target_texts, gt_texts = load_data_with_gt(OCR_data, num_samples, max_sent_len, min_sent_len, delimiter='|',gt_index=0, prediction_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229\n",
      "gunshot wound to ardamen\n",
      " \n",
      " \tgunshot wound to abdomen\n",
      "\n",
      "Csmner\n",
      " \n",
      " \tConner\n",
      "\n",
      "Lifting restriotions\n",
      " \n",
      " \tLifting restrictions\n",
      "\n",
      "Meofhithey\n",
      " \n",
      " \tWebb, Whitney\n",
      "\n",
      "soo Venerol Surgery\n",
      " \n",
      " \tM.D. General Surgery\n",
      "\n",
      "athens\n",
      " \n",
      " \tAthens\n",
      "\n",
      "Ofr nomkn . tilett\n",
      " \n",
      " \tOFF ALVAREZ File #\n",
      "\n",
      "Nemours\n",
      " \n",
      " \tNemours\n",
      "\n",
      "w gto\n",
      " \n",
      " \tWilmingto\n",
      "\n",
      "taientsopp bover\n",
      " \n",
      " \tPaige Koppnhaver\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "print(len(input_texts))\n",
    "for i in range(10):\n",
    "    print(input_texts[i], '\\n', target_texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights(model_file)\n",
    "\n",
    "model = load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 114)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) [(None, 512), (None, 759808      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 114)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           bidirectional_1[0][1]            \n",
      "                                                                 bidirectional_1[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 512)          0           bidirectional_1[0][2]            \n",
      "                                                                 bidirectional_1[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 512),  1284096     input_2[0][0]                    \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 114)    58482       lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,102,386\n",
      "Trainable params: 2,102,386\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmad/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py:269: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "encoder_model = load_model(encoder_model_file)\n",
    "decoder_model = load_model(decoder_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 114)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) [(None, 512), (None, 759808      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           bidirectional_1[0][1]            \n",
      "                                                                 bidirectional_1[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 512)          0           bidirectional_1[0][2]            \n",
      "                                                                 bidirectional_1[0][4]            \n",
      "==================================================================================================\n",
      "Total params: 759,808\n",
      "Trainable params: 759,808\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None, 114)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 512),  1284096     input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 114)    58482       lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,342,578\n",
      "Trainable params: 1,342,578\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: gunshot wound to ardamen\n",
      "\n",
      "GT sentence: gunshot wound to abdomen\n",
      "Decoded sentence: ununurh - Hospate streas\n",
      "\n",
      "-\n",
      "Input sentence: Csmner\n",
      "\n",
      "GT sentence: Conner\n",
      "Decoded sentence: CLIIDENT\n",
      "\n",
      "-\n",
      "Input sentence: Lifting restriotions\n",
      "\n",
      "GT sentence: Lifting restrictions\n",
      "Decoded sentence: Lintring should rigros\n",
      "\n",
      "-\n",
      "Input sentence: Meofhithey\n",
      "\n",
      "GT sentence: Webb, Whitney\n",
      "Decoded sentence: Medithobit\n",
      "\n",
      "-\n",
      "Input sentence: soo Venerol Surgery\n",
      "\n",
      "GT sentence: M.D. General Surgery\n",
      "Decoded sentence: Sorned Status Dev\n",
      "\n",
      "-\n",
      "Input sentence: athens\n",
      "\n",
      "GT sentence: Athens\n",
      "Decoded sentence: Date s:\n",
      "\n",
      "-\n",
      "Input sentence: Ofr nomkn . tilett\n",
      "\n",
      "GT sentence: OFF ALVAREZ File #\n",
      "Decoded sentence: Office Hame available\n",
      "\n",
      "-\n",
      "Input sentence: Nemours\n",
      "\n",
      "GT sentence: Nemours\n",
      "Decoded sentence: Neprone:\n",
      "\n",
      "-\n",
      "Input sentence: w gto\n",
      "\n",
      "GT sentence: Wilmingto\n",
      "Decoded sentence: • Wow.\n",
      "\n",
      "-\n",
      "Input sentence: taientsopp bover\n",
      "\n",
      "GT sentence: Paige Koppnhaver\n",
      "Decoded sentence: Cate note workl ara\n",
      "\n",
      "-\n",
      "Input sentence: cniched mnenden\n",
      "\n",
      "GT sentence: Michael Mastadeo\n",
      "Decoded sentence: ccrdched ed: dreared\n",
      "\n",
      "-\n",
      "Input sentence: 57A7\n",
      "\n",
      "GT sentence: STAT\n",
      "Decoded sentence: 777576 ?\n",
      "\n",
      "-\n",
      "Input sentence: refhnee\n",
      "\n",
      "GT sentence: Rt knee\n",
      "Decoded sentence: Derenter:\n",
      "\n",
      "-\n",
      "Input sentence: Soerme\n",
      "\n",
      "GT sentence: SOFTBALL\n",
      "Decoded sentence: Sorter\n",
      "\n",
      "-\n",
      "Input sentence: twef\n",
      "\n",
      "GT sentence: KNEE\n",
      "Decoded sentence: • Wte \n",
      "\n",
      "-\n",
      "Input sentence: mrom\n",
      "\n",
      "GT sentence: MOM\n",
      "Decoded sentence: Impro\n",
      "\n",
      "-\n",
      "Input sentence: Yossers fatrot cole ayg\n",
      "\n",
      "GT sentence: posterolateral corner injury\n",
      "Decoded sentence: Yous serred arthorkers?\n",
      "\n",
      "-\n",
      "Input sentence: Gnnkrters thelslles\n",
      "\n",
      "GT sentence: quad sets Heel slides Bike\n",
      "Decoded sentence: Gnnerner Larkens day:\n",
      "\n",
      "-\n",
      "Input sentence: G Siuts\n",
      "\n",
      "GT sentence: Ȼ spurs\n",
      "Decoded sentence: Gunure: T\n",
      "\n",
      "-\n",
      "Input sentence: Peste\n",
      "\n",
      "GT sentence: Pediatric\n",
      "Decoded sentence: Pester\n",
      "\n",
      "-\n",
      "Input sentence: Unterlicnl Heenig\n",
      "\n",
      "GT sentence: Umbilical Hernia\n",
      "Decoded sentence: Unurntted Enterprens Pllated\n",
      "\n",
      "-\n",
      "Input sentence: sRpininbiHemin\n",
      "\n",
      "GT sentence: Lap Repair Umb, Hernia\n",
      "Decoded sentence: Risitial Higrthy:\n",
      "\n",
      "-\n",
      "Input sentence: mreDicay\n",
      "\n",
      "GT sentence: meDica\n",
      "Decoded sentence: Indication\n",
      "\n",
      "-\n",
      "Input sentence: meDica\n",
      "\n",
      "GT sentence: meDica\n",
      "Decoded sentence: Depariden:\n",
      "\n",
      "-\n",
      "Input sentence: Beth harer\n",
      "\n",
      "GT sentence: Beth Harper\n",
      "Decoded sentence: Beran: Brithe\n",
      "\n",
      "-\n",
      "Input sentence: mane\n",
      "\n",
      "GT sentence: none\n",
      "Decoded sentence: Pame 1 :\n",
      "\n",
      "-\n",
      "Input sentence: nome\n",
      "\n",
      "GT sentence: none\n",
      "Decoded sentence: no no\n",
      "\n",
      "-\n",
      "Input sentence: none\n",
      "\n",
      "GT sentence: none\n",
      "Decoded sentence: nonnent\n",
      "\n",
      "-\n",
      "Input sentence: neiom\n",
      "\n",
      "GT sentence: nexium\n",
      "Decoded sentence: ne Indection:\n",
      "\n",
      "-\n",
      "Input sentence: none\n",
      "\n",
      "GT sentence: none\n",
      "Decoded sentence: nonnent\n",
      "\n",
      "-\n",
      "Input sentence: nane\n",
      "\n",
      "GT sentence: none\n",
      "Decoded sentence: n-neg\n",
      "\n",
      "-\n",
      "Input sentence: mone\n",
      "\n",
      "GT sentence: none\n",
      "Decoded sentence: Dopens\n",
      "\n",
      "-\n",
      "Input sentence: Stevenson , wiliam\n",
      "\n",
      "GT sentence: Stevenson, William\n",
      "Decoded sentence: Seevent Physician\n",
      "\n",
      "-\n",
      "Input sentence: mofeeneralsargery\n",
      "\n",
      "GT sentence: MD / General Surgery\n",
      "Decoded sentence: A: neerge sevlees No\n",
      "\n",
      "-\n",
      "Input sentence: tsdshinglen couebavse\n",
      "\n",
      "GT sentence: Washington Covet House\n",
      "Decoded sentence: 1s nong andeg of service:\n",
      "\n",
      "-\n",
      "Input sentence: antle ecar in otfce\n",
      "\n",
      "GT sentence: ankle exam in office\n",
      "Decoded sentence: Patient the peasones\n",
      "\n",
      "-\n",
      "Input sentence: Short teg cast\n",
      "\n",
      "GT sentence: Short leg cast\n",
      "Decoded sentence: Shourectront Tore\n",
      "\n",
      "-\n",
      "Input sentence: antile teray\n",
      "\n",
      "GT sentence: Ankle x-ray\n",
      "Decoded sentence: tiated atter\n",
      "\n",
      "-\n",
      "Input sentence: Tose brdley s\n",
      "\n",
      "GT sentence: Morse, Badley J.\n",
      "Decoded sentence: Tores doves wity \n",
      "\n",
      "-\n",
      "Input sentence: cithopedies\n",
      "\n",
      "GT sentence: Orthopedics\n",
      "Decoded sentence: Cote stion:\n",
      "\n",
      "-\n",
      "Input sentence: Grego\n",
      "\n",
      "GT sentence: Oregon\n",
      "Decoded sentence: Ground\n",
      "\n",
      "-\n",
      "Input sentence: f Fiburo\n",
      "\n",
      "GT sentence: fx fibula\n",
      "Decoded sentence: Furtion:\n",
      "\n",
      "-\n",
      "Input sentence: DeMvese\n",
      "\n",
      "GT sentence: Dr. Morse\n",
      "Decoded sentence: Devife se\n",
      "\n",
      "-\n",
      "Input sentence: Fieesr\n",
      "\n",
      "GT sentence: R Thumb Spica Pink Cast\n",
      "Decoded sentence: Fiees Na\n",
      "\n",
      "-\n",
      "Input sentence: wote a aratent i\n",
      "\n",
      "GT sentence: work nursing home\n",
      "Decoded sentence: wow - rast ng the\n",
      "\n",
      "-\n",
      "Input sentence: sacd\n",
      "\n",
      "GT sentence: INCC\n",
      "Decoded sentence: Casd cton:\n",
      "\n",
      "-\n",
      "Input sentence: at paen\n",
      "\n",
      "GT sentence: due to pain\n",
      "Decoded sentence: Spart Number\n",
      "\n",
      "-\n",
      "Input sentence: tn an\n",
      "\n",
      "GT sentence: tenderness on perpectium\n",
      "Decoded sentence: • Lang Name\n",
      "\n",
      "-\n",
      "Input sentence: herphs n Fhens Thee were h\n",
      "\n",
      "GT sentence: helping a Friend This were a\n",
      "Decoded sentence: Pherenden without Yest the Prist\n",
      "\n",
      "-\n",
      "Input sentence: ncteil ghlw\n",
      "\n",
      "GT sentence: AccidentAl injury\n",
      "Decoded sentence: Sective: 21-yrs\n",
      "\n",
      "-\n",
      "Input sentence: Vese Decs\n",
      "\n",
      "GT sentence: VeLASCO DIEGO\n",
      "Decoded sentence: Verore Dev, \n",
      "\n",
      "-\n",
      "Input sentence: Weay Porar me\n",
      "\n",
      "GT sentence: WesT PoinT MS\n",
      "Decoded sentence: Wor Tele: 66 (D\n",
      "\n",
      "-\n",
      "Input sentence: DR. Velasce\n",
      "\n",
      "GT sentence: DR. Velasco\n",
      "Decoded sentence: DROVMTH Alle:\n",
      "\n",
      "-\n",
      "Input sentence: cogRfeach onie\n",
      "\n",
      "GT sentence: R Complete Chronic RTC tear\n",
      "Decoded sentence: Oocical Right Yes\n",
      "\n",
      "-\n",
      "Input sentence: spanes . Nrged\n",
      "\n",
      "GT sentence: Sparks, Nigel\n",
      "Decoded sentence: Spassiby Number:\n",
      "\n",
      "-\n",
      "Input sentence: omhopaedics\n",
      "\n",
      "GT sentence: Orthopaedics\n",
      "Decoded sentence: 1hod of chinges\n",
      "\n",
      "-\n",
      "Input sentence: sntnowr\n",
      "\n",
      "GT sentence: Unknown\n",
      "Decoded sentence: Step:r) L\n",
      "\n",
      "-\n",
      "Input sentence: ntorn\n",
      "\n",
      "GT sentence: Unknown\n",
      "Decoded sentence: Sountry:\n",
      "\n",
      "-\n",
      "Input sentence: Foow Rerapor cos.n soveer\n",
      "\n",
      "GT sentence: Torn rotator cuff RT shoulder\n",
      "Decoded sentence: Fowwew work Service required\n",
      "\n",
      "-\n",
      "Input sentence: Fomreraeor cse\n",
      "\n",
      "GT sentence: Torn rotator cuff\n",
      "Decoded sentence: Foreer stons Ne\n",
      "\n",
      "-\n",
      "Input sentence: Nse spantee\n",
      "\n",
      "GT sentence: Nigel Sparks\n",
      "Decoded sentence: Nesp rencerp\n",
      "\n",
      "-\n",
      "Input sentence: Np/15\n",
      "\n",
      "GT sentence: Unum\n",
      "Decoded sentence: • NOU9\n",
      "\n",
      "-\n",
      "Input sentence: GCcidenCnFoo\n",
      "\n",
      "GT sentence: Accident claim Form\n",
      "Decoded sentence: Gencrndinor:\n",
      "\n",
      "-\n",
      "Input sentence: 0200/00740/1Ckamn 1or\n",
      "\n",
      "GT sentence: Claim for dependent child\n",
      "Decoded sentence: 02/06/18 2018 v 18 STT\n",
      "\n",
      "-\n",
      "Input sentence: barent\n",
      "\n",
      "GT sentence: Parent\n",
      "Decoded sentence: Serater:\n",
      "\n",
      "-\n",
      "Input sentence: toeratio\n",
      "\n",
      "GT sentence: Laceration\n",
      "Decoded sentence: Strotion\n",
      "\n",
      "-\n",
      "Input sentence: Julit ( Thill\n",
      "\n",
      "GT sentence: Julie C. Thiel\n",
      "Decoded sentence: Julth (mm/dd/yy)\n",
      "\n",
      "-\n",
      "Input sentence: Lavradionc0breal Tae\n",
      "\n",
      "GT sentence: Laceration L Great Toe\n",
      "Decoded sentence: Lantary Dr.chiption\n",
      "\n",
      "-\n",
      "Input sentence: feilly Bobel5\n",
      "\n",
      "GT sentence: Reilly, Robert J.\n",
      "Decoded sentence: Afilley Relate\n",
      "\n",
      "-\n",
      "Input sentence: Pijrcien Mrrstand\n",
      "\n",
      "GT sentence: Physician Assistant\n",
      "Decoded sentence: Printed Name: Ryhardeg\n",
      "\n",
      "-\n",
      "Input sentence: dennites bengston\n",
      "\n",
      "GT sentence: Jennifer Bengston\n",
      "Decoded sentence: dending Dessind ne\n",
      "\n",
      "-\n",
      "Input sentence: Famly Prachre\n",
      "\n",
      "GT sentence: Family Practice\n",
      "Decoded sentence: Parghed PriHa.r.\n",
      "\n",
      "-\n",
      "Input sentence: Rot Beny\n",
      "\n",
      "GT sentence: Robert Reilly\n",
      "Decoded sentence: Rotun By:\n",
      "\n",
      "-\n",
      "Input sentence: tamn Pactre\n",
      "\n",
      "GT sentence: Family Practice\n",
      "Decoded sentence: Pat. Pate: 5 14 - %\n",
      "\n",
      "-\n",
      "Input sentence: Dn Banap Thempson\n",
      "\n",
      "GT sentence: Dr. Barry Thompson\n",
      "Decoded sentence: Dan Ex Birker: Dev, PA\n",
      "\n",
      "-\n",
      "Input sentence: Right sided Sciatical\n",
      "\n",
      "GT sentence: Right Sided Sciatica\n",
      "Decoded sentence: Right Status Services\n",
      "\n",
      "-\n",
      "Input sentence: Barry atee Mhompsonpi.D.\n",
      "\n",
      "GT sentence: Barry V. Thompson, M.D.\n",
      "Decoded sentence: Brrancar the Physician\n",
      "\n",
      "-\n",
      "Input sentence: Beneral Family\n",
      "\n",
      "GT sentence: General Family\n",
      "Decoded sentence: Benent admint\n",
      "\n",
      "-\n",
      "Input sentence: CrpSSot\n",
      "\n",
      "GT sentence: Crossett\n",
      "Decoded sentence: Surusen Sover.\n",
      "\n",
      "-\n",
      "Input sentence: tn poming tor nor on coere\n",
      "\n",
      "GT sentence: In parking lot not on clock\n",
      "Decoded sentence: In no notion Eave of Service:\n",
      "\n",
      "-\n",
      "Input sentence: Matrior\n",
      "\n",
      "GT sentence: Mother\n",
      "Decoded sentence: Mational History\n",
      "\n",
      "-\n",
      "Input sentence: Unum\n",
      "\n",
      "GT sentence: Unum\n",
      "Decoded sentence: Unum\n",
      "\n",
      "-\n",
      "Input sentence: Mother\n",
      "\n",
      "GT sentence: Mother\n",
      "Decoded sentence: Mother:\n",
      "\n",
      "-\n",
      "Input sentence: mother\n",
      "\n",
      "GT sentence: mother\n",
      "Decoded sentence: hother \n",
      "\n",
      "-\n",
      "Input sentence: ttheny reflesno\n",
      "\n",
      "GT sentence: Anthony Szefler, MD\n",
      "Decoded sentence: htep ere - nalder\n",
      "\n",
      "-\n",
      "Input sentence: beng\n",
      "\n",
      "GT sentence: LEM\n",
      "Decoded sentence: Sebsent\n",
      "\n",
      "-\n",
      "Input sentence: Shalder ramdaler\n",
      "\n",
      "GT sentence: Shoulder Immobilizer\n",
      "Decoded sentence: Shoral date Neeccr.\n",
      "\n",
      "-\n",
      "Input sentence: UnOm\n",
      "\n",
      "GT sentence: Unum\n",
      "Decoded sentence: Unun\n",
      "\n",
      "-\n",
      "Input sentence: Haordent Corm foem eTe\n",
      "\n",
      "GT sentence: Accident Claim form etc.\n",
      "Decoded sentence: Horap Information - 038\n",
      "\n",
      "-\n",
      "Input sentence: De Peitite\n",
      "\n",
      "GT sentence: Dr. Gentile\n",
      "Decoded sentence: Devintifiers\n",
      "\n",
      "-\n",
      "Input sentence: Penine\n",
      "\n",
      "GT sentence: Pending\n",
      "Decoded sentence: Pendent:\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: clsed oi Murkrs\n",
      "\n",
      "GT sentence: Closed fx R humenus\n",
      "Decoded sentence: Acsered For Tex:\n",
      "\n",
      "-\n",
      "Input sentence: Depleed ae prosmaf end\n",
      "\n",
      "GT sentence: Displaced fx. proximal end\n",
      "Decoded sentence: Dedered and eren nger -\n",
      "\n",
      "-\n",
      "Input sentence: Rhomows-othice visit\n",
      "\n",
      "GT sentence: R humenus - Office visit\n",
      "Decoded sentence: Rhos of werk - 031-325-\n",
      "\n",
      "-\n",
      "Input sentence: OEte oisi't\n",
      "\n",
      "GT sentence: Office visit\n",
      "Decoded sentence: OtE Motist:\n",
      "\n",
      "-\n",
      "Input sentence: Rrohinal end-homers S- night\n",
      "\n",
      "GT sentence: Proximal end-humerus fx-right\n",
      "Decoded sentence: Rivital higled Procedure congl.\n",
      "\n",
      "-\n",
      "Input sentence: Gentile Dohin\n",
      "\n",
      "GT sentence: Gentile, John\n",
      "Decoded sentence: Gencreding Physician\n",
      "\n",
      "-\n",
      "Input sentence: Oethosede trooma\n",
      "\n",
      "GT sentence: Orthopedic trauma\n",
      "Decoded sentence: Other Ortacis Plist\n",
      "\n",
      "-\n",
      "Input sentence: founestevw\n",
      "\n",
      "GT sentence: Youngstown\n",
      "Decoded sentence: :obeenser:\n",
      "\n",
      "-\n",
      "Input sentence: tmme Cartes\n",
      "\n",
      "GT sentence: Womens Services\n",
      "Decoded sentence: Impurter Languages\n",
      "\n",
      "-\n",
      "Input sentence: Trsenrapactation\n",
      "\n",
      "GT sentence: RN/Educator/Lactation\n",
      "Decoded sentence: Trentrry Comrencard\n",
      "\n",
      "-\n",
      "Input sentence: Ohio\n",
      "\n",
      "GT sentence: Ohio\n",
      "Decoded sentence: Oth:\n",
      "\n",
      "-\n",
      "Input sentence: themetet hend Fracture-rlght\n",
      "\n",
      "GT sentence: Humeral head fracture-right\n",
      "Decoded sentence: hterented at the Periorally aver\n",
      "\n",
      "-\n",
      "Input sentence: Facial hermateme-rlant\n",
      "\n",
      "GT sentence: Facial hematoma-right\n",
      "Decoded sentence: Ficcarthectert Name available.\n",
      "\n",
      "-\n",
      "Input sentence: Fall\n",
      "\n",
      "GT sentence: Fall\n",
      "Decoded sentence: Palder:\n",
      "\n",
      "-\n",
      "Input sentence: pathor\n",
      "\n",
      "GT sentence: Mother\n",
      "Decoded sentence: Pator: \n",
      "\n",
      "-\n",
      "Input sentence: rceni tirammdon\n",
      "\n",
      "GT sentence: Brooke William, R.M.D.\n",
      "Decoded sentence: Sericr Insurad’s Namm\n",
      "\n",
      "-\n",
      "Input sentence: prather\n",
      "\n",
      "GT sentence: Mother\n",
      "Decoded sentence: Sparter:\n",
      "\n",
      "-\n",
      "Input sentence: Te elullachell\n",
      "\n",
      "GT sentence: TERI WillochEll\n",
      "Decoded sentence: Teeal chedure:\n",
      "\n",
      "-\n",
      "Input sentence: WiNlockerl Fer\n",
      "\n",
      "GT sentence: Willochell, Teri\n",
      "Decoded sentence: Westory No First\n",
      "\n",
      "-\n",
      "Input sentence: nteral medicine\n",
      "\n",
      "GT sentence: internal medicine\n",
      "Decoded sentence: Senure Lare larle\n",
      "\n",
      "-\n",
      "Input sentence: se15\n",
      "\n",
      "GT sentence: self\n",
      "Decoded sentence: Sers\n",
      "\n",
      "-\n",
      "Input sentence: ER Dorce\n",
      "\n",
      "GT sentence: ER DOCTOR\n",
      "Decoded sentence: EX DOTED\n",
      "\n",
      "-\n",
      "Input sentence: Gandera Remold a Fup\n",
      "\n",
      "GT sentence: Sandra Reynolds FNP\n",
      "Decoded sentence: Gended Name Starencer\n",
      "\n",
      "-\n",
      "Input sentence: Oeraaedics\n",
      "\n",
      "GT sentence: Orthopaedics\n",
      "Decoded sentence: Officearing\n",
      "\n",
      "-\n",
      "Input sentence: taif\n",
      "\n",
      "GT sentence: FNP\n",
      "Decoded sentence: Tate: m\n",
      "\n",
      "-\n",
      "Input sentence: Ninsten Saler\n",
      "\n",
      "GT sentence: Winston Salem\n",
      "Decoded sentence: Ins. Number Spen\n",
      "\n",
      "-\n",
      "Input sentence: Mnum .,\n",
      "\n",
      "GT sentence: Unum\n",
      "Decoded sentence: Mnnua:\n",
      "\n",
      "-\n",
      "Input sentence: Meatica Dasa Miller\n",
      "\n",
      "GT sentence: Medical Plaza Miller\n",
      "Decoded sentence: Meecaictirged andret\n",
      "\n",
      "-\n",
      "Input sentence: sanra dernslds\n",
      "\n",
      "GT sentence: Sandra Reynolds\n",
      "Decoded sentence: Past dalenal serger:\n",
      "\n",
      "-\n",
      "Input sentence: See atacheer\n",
      "\n",
      "GT sentence: See attached\n",
      "Decoded sentence: Seecares regated\n",
      "\n",
      "-\n",
      "Input sentence: Thimn, Brithur E.\n",
      "\n",
      "GT sentence: Flynn, Arthur E.\n",
      "Decoded sentence: Thin ELange: 346-08 \n",
      "\n",
      "-\n",
      "Input sentence: MTplastio surgeny\n",
      "\n",
      "GT sentence: MD / Plastic Surgery\n",
      "Decoded sentence: TMEasl/sutinst/dick.\n",
      "\n",
      "-\n",
      "Input sentence: Ttewwra\n",
      "\n",
      "GT sentence: Ventura\n",
      "Decoded sentence: Tetwork: No\n",
      "\n",
      "-\n",
      "Input sentence: Todmp-\n",
      "\n",
      "GT sentence: Today\n",
      "Decoded sentence: Today’s\n",
      "\n",
      "-\n",
      "Input sentence: reovary ,\n",
      "\n",
      "GT sentence: recovery\n",
      "Decoded sentence: Services.\n",
      "\n",
      "-\n",
      "Input sentence: Tdop\n",
      "\n",
      "GT sentence: Today\n",
      "Decoded sentence: Th Aps\n",
      "\n",
      "-\n",
      "Input sentence: Mrnt care\n",
      "\n",
      "GT sentence: Urgent Care\n",
      "Decoded sentence: Mre Expr:\n",
      "\n",
      "-\n",
      "Input sentence: Matefatasm\n",
      "\n",
      "GT sentence: Lake Jackson\n",
      "Decoded sentence: Date onts:\n",
      "\n",
      "-\n",
      "Input sentence: geghiefndye\n",
      "\n",
      "GT sentence: Wayne Rutledge\n",
      "Decoded sentence: Seevined by:\n",
      "\n",
      "-\n",
      "Input sentence: Paio\n",
      "\n",
      "GT sentence: FNP\n",
      "Decoded sentence: Pain:\n",
      "\n",
      "-\n",
      "Input sentence: Nor Menie\n",
      "\n",
      "GT sentence: West Monroe\n",
      "Decoded sentence: No MExer\n",
      "\n",
      "-\n",
      "Input sentence: Bonold Bwe MD\n",
      "\n",
      "GT sentence: Donald Govler MD\n",
      "Decoded sentence: Bod By: 3418\n",
      "\n",
      "-\n",
      "Input sentence: pest Miorve\n",
      "\n",
      "GT sentence: West Monroe\n",
      "Decoded sentence: peese Name:\n",
      "\n",
      "-\n",
      "Input sentence: Stomr Mihal teM\n",
      "\n",
      "GT sentence: Stump Michael C MD\n",
      "Decoded sentence: Stomaral Regional\n",
      "\n",
      "-\n",
      "Input sentence: frimiiy Come Sprals Mediane\n",
      "\n",
      "GT sentence: Primary Care Sports Medicine\n",
      "Decoded sentence: Ifion Symonr Status: Semphons\n",
      "\n",
      "-\n",
      "Input sentence: Edley\n",
      "\n",
      "GT sentence: Findlay\n",
      "Decoded sentence: Edde:\n",
      "\n",
      "-\n",
      "Input sentence: coegnt beaing in crbect\n",
      "\n",
      "GT sentence: Weight bearing in cam boot\n",
      "Decoded sentence: Concented strmine /30.1305\n",
      "\n",
      "-\n",
      "Input sentence: tr te\n",
      "\n",
      "GT sentence: MRI RLE\n",
      "Decoded sentence: Atter\n",
      "\n",
      "-\n",
      "Input sentence: Banchs pani\n",
      "\n",
      "GT sentence: Blancho, David\n",
      "Decoded sentence: Barsing Physician\n",
      "\n",
      "-\n",
      "Input sentence: Fonl\n",
      "\n",
      "GT sentence: Podiatry\n",
      "Decoded sentence: Pountry:\n",
      "\n",
      "-\n",
      "Input sentence: Catina\n",
      "\n",
      "GT sentence: Galena\n",
      "Decoded sentence: Courtant\n",
      "\n",
      "-\n",
      "Input sentence: so-sancto\n",
      "\n",
      "GT sentence: Dr. Blancho\n",
      "Decoded sentence: Costant Date:\n",
      "\n",
      "-\n",
      "Input sentence: Pescript\n",
      "\n",
      "GT sentence: Pt Script\n",
      "Decoded sentence: Pescrapic\n",
      "\n",
      "-\n",
      "Input sentence: wuite\n",
      "\n",
      "GT sentence: wife\n",
      "Decoded sentence: Cotut)\n",
      "\n",
      "-\n",
      "Input sentence: Calts Lowrence\n",
      "\n",
      "GT sentence: Cathy Lawrence\n",
      "Decoded sentence: Co-Insure no eard.\n",
      "\n",
      "-\n",
      "Input sentence: Dand inacast\n",
      "\n",
      "GT sentence: David Macias\n",
      "Decoded sentence: Dann al changes\n",
      "\n",
      "-\n",
      "Input sentence: Fnpany\n",
      "\n",
      "GT sentence: knee pain gout\n",
      "Decoded sentence: P-mat:\n",
      "\n",
      "-\n",
      "Input sentence: fnegng\n",
      "\n",
      "GT sentence: knee pain gout\n",
      "Decoded sentence: Unngeng\n",
      "\n",
      "-\n",
      "Input sentence: Gfpeineapey\n",
      "\n",
      "GT sentence: left medial knee pain\n",
      "Decoded sentence: Gendent paint\n",
      "\n",
      "-\n",
      "Input sentence: fneic fifere\n",
      "\n",
      "GT sentence: menidus left knee\n",
      "Decoded sentence: nfine 2 1 yrs\n",
      "\n",
      "-\n",
      "Input sentence: n epyna\n",
      "\n",
      "GT sentence: Kathy Laurence\n",
      "Decoded sentence: Spedial:\n",
      "\n",
      "-\n",
      "Input sentence: Fngly\n",
      "\n",
      "GT sentence: Family\n",
      "Decoded sentence: Pontary:\n",
      "\n",
      "-\n",
      "Input sentence: Gclcley\n",
      "\n",
      "GT sentence: Kosciusko\n",
      "Decoded sentence: Geccedur:\n",
      "\n",
      "-\n",
      "Input sentence: Penasov\n",
      "\n",
      "GT sentence: Afternoon\n",
      "Decoded sentence: Pnented:\n",
      "\n",
      "-\n",
      "Input sentence: sliepeds febackugoich\n",
      "\n",
      "GT sentence: slipped off back porch\n",
      "Decoded sentence: stedied by Stemslated:\n",
      "\n",
      "-\n",
      "Input sentence: tees cnogd wmererias\n",
      "\n",
      "GT sentence: Acute Chest Wall Pain\n",
      "Decoded sentence: Insected eragusent armsrm\n",
      "\n",
      "-\n",
      "Input sentence: Be Imiense be\n",
      "\n",
      "GT sentence: Bevelle, Michael A\n",
      "Decoded sentence: Be knem for pagne\n",
      "\n",
      "-\n",
      "Input sentence: sagso ,cewesserr\n",
      "\n",
      "GT sentence: Jackson, Tennessee\n",
      "Decoded sentence: sasesusedure selere\n",
      "\n",
      "-\n",
      "Input sentence: Mentartienereerpracesafff\n",
      "\n",
      "GT sentence: Lumbar transverse process fx.\n",
      "Decoded sentence: Mencrivt Language anterprext\n",
      "\n",
      "-\n",
      "Input sentence: gpprpevisit\n",
      "\n",
      "GT sentence: Office visit\n",
      "Decoded sentence: Sprviver/mare\n",
      "\n",
      "-\n",
      "Input sentence: oce bist\n",
      "\n",
      "GT sentence: Office visit\n",
      "Decoded sentence: Accessions.\n",
      "\n",
      "-\n",
      "Input sentence: seeast\n",
      "\n",
      "GT sentence: Office visit\n",
      "Decoded sentence: Seesares\n",
      "\n",
      "-\n",
      "Input sentence: gceclt\n",
      "\n",
      "GT sentence: Office visit\n",
      "Decoded sentence: Seccenter\n",
      "\n",
      "-\n",
      "Input sentence: Derstieet Jerner\n",
      "\n",
      "GT sentence: Overstreet Jennifer\n",
      "Decoded sentence: Deristre: Jage 12\n",
      "\n",
      "-\n",
      "Input sentence: Cfunhe\n",
      "\n",
      "GT sentence: Columbia\n",
      "Decoded sentence: Co-neer Recerd\n",
      "\n",
      "-\n",
      "Input sentence: Sennsee verstreed\n",
      "\n",
      "GT sentence: Jennifer Overstreet\n",
      "Decoded sentence: Seenens ereler enengr.\n",
      "\n",
      "-\n",
      "Input sentence: sereltuelle\n",
      "\n",
      "GT sentence: Morel-lavallee\n",
      "Decoded sentence: sersed are:\n",
      "\n",
      "-\n",
      "Input sentence: Monel-avetle\n",
      "\n",
      "GT sentence: Morel-lavallee\n",
      "Decoded sentence: Monenal Proned\n",
      "\n",
      "-\n",
      "Input sentence: carby\n",
      "\n",
      "GT sentence: GRADY\n",
      "Decoded sentence: ciac tura\n",
      "\n",
      "-\n",
      "Input sentence: gese\n",
      "\n",
      "GT sentence: Above\n",
      "Decoded sentence: Regrod\n",
      "\n",
      "-\n",
      "Input sentence: Thia tier mnow\n",
      "\n",
      "GT sentence: Huai Ming Phon\n",
      "Decoded sentence: Thia nitt of Clargered\n",
      "\n",
      "-\n",
      "Input sentence: senmg\n",
      "\n",
      "GT sentence: Trauma\n",
      "Decoded sentence: Sendure:\n",
      "\n",
      "-\n",
      "Input sentence: Geny\n",
      "\n",
      "GT sentence: GRADY\n",
      "Decoded sentence: Cenden:\n",
      "\n",
      "-\n",
      "Input sentence: ootT\n",
      "\n",
      "GT sentence: Atlanta\n",
      "Decoded sentence: Totp\n",
      "\n",
      "-\n",
      "Input sentence: pri eake\n",
      "\n",
      "GT sentence: Colin Clarke\n",
      "Decoded sentence: Prig  at:\n",
      "\n",
      "-\n",
      "Input sentence: sashaier 5f5/\n",
      "\n",
      "GT sentence: Bilatshalder s/s\n",
      "Decoded sentence: shin ast crint.\n",
      "\n",
      "-\n",
      "Input sentence: i19ocerscap\n",
      "\n",
      "GT sentence: TPI R periscap.\n",
      "Decoded sentence: Inserageres\n",
      "\n",
      "-\n",
      "Input sentence: as ofs\n",
      "\n",
      "GT sentence: CS s/s\n",
      "Decoded sentence: Yes sore\n",
      "\n",
      "-\n",
      "Input sentence: Ts 3/5\n",
      "\n",
      "GT sentence: TS s/s\n",
      "Decoded sentence: Thass\n",
      "\n",
      "-\n",
      "Input sentence: Ts B/5\n",
      "\n",
      "GT sentence: LS s/s\n",
      "Decoded sentence: Tere, MO\n",
      "\n",
      "-\n",
      "Input sentence: T5/2\n",
      "\n",
      "GT sentence: N/A\n",
      "Decoded sentence: Trist\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Cstine eraenation\n",
      "\n",
      "GT sentence: Initial evaluation\n",
      "Decoded sentence: Cottent Indective: \n",
      "\n",
      "-\n",
      "Input sentence: the orymet resulls\n",
      "\n",
      "GT sentence: Flu OV, MRI results\n",
      "Decoded sentence: hhe for correncagers in\n",
      "\n",
      "-\n",
      "Input sentence: Fennings bittian Bryan\n",
      "\n",
      "GT sentence: Jennings, William Bryan\n",
      "Decoded sentence: Innding Seavide stanus:\n",
      "\n",
      "-\n",
      "Input sentence: orthopaediy purgery\n",
      "\n",
      "GT sentence: Orthopaedic Surgery\n",
      "Decoded sentence: Other of cricked or:\n",
      "\n",
      "-\n",
      "Input sentence: hrston Satem\n",
      "\n",
      "GT sentence: Winston Salem\n",
      "Decoded sentence: Pristed Date:\n",
      "\n",
      "-\n",
      "Input sentence: T mings\n",
      "\n",
      "GT sentence: JeNNiNgs\n",
      "Decoded sentence: Tientis:\n",
      "\n",
      "-\n",
      "Input sentence: De iheet Alley\n",
      "\n",
      "GT sentence: Dr. Albert Alley\n",
      "Decoded sentence: De knee (Dention\n",
      "\n",
      "-\n",
      "Input sentence: Flanke Pai\n",
      "\n",
      "GT sentence: Flank Pain\n",
      "Decoded sentence: Pain Pat Pline.\n",
      "\n",
      "-\n",
      "Input sentence: Tha Pain\n",
      "\n",
      "GT sentence: Abd Pain\n",
      "Decoded sentence: Thie Pain.\n",
      "\n",
      "-\n",
      "Input sentence: thrme\n",
      "\n",
      "GT sentence: thru.\n",
      "Decoded sentence: hhert\n",
      "\n",
      "-\n",
      "Input sentence: DrSiiertiey\n",
      "\n",
      "GT sentence: Dr. Albert Alley\n",
      "Decoded sentence: irition Signarule\n",
      "\n",
      "-\n",
      "Input sentence: Famiytheg\n",
      "\n",
      "GT sentence: Family Med\n",
      "Decoded sentence: Family Higrte\n",
      "\n",
      "-\n",
      "Input sentence: Berck\n",
      "\n",
      "GT sentence: Berwick\n",
      "Decoded sentence: Berent\n",
      "\n",
      "-\n",
      "Input sentence: Frma\n",
      "\n",
      "GT sentence: Trauma\n",
      "Decoded sentence: Parm\n",
      "\n",
      "-\n",
      "Input sentence: Pnchil Pehos\n",
      "\n",
      "GT sentence: Rachel Cobos\n",
      "Decoded sentence: Pieqhequin:\n",
      "\n",
      "-\n",
      "Input sentence: lhghh Pealtheng\n",
      "\n",
      "GT sentence: University Health Trauma Team\n",
      "Decoded sentence: hhinhor Phister\n",
      "\n",
      "-\n",
      "Input sentence: giitentio\n",
      "\n",
      "GT sentence: SAN ANtoNio\n",
      "Decoded sentence: istiont.\n",
      "\n",
      "-\n",
      "Input sentence: Fenms\n",
      "\n",
      "GT sentence: TEXAS\n",
      "Decoded sentence: Finns.\n",
      "\n",
      "-\n",
      "Input sentence: theelal a\n",
      "\n",
      "GT sentence: FRED Corely G\n",
      "Decoded sentence: Shedialty:\n",
      "\n",
      "-\n",
      "Input sentence: lthepeche\n",
      "\n",
      "GT sentence: Orthopedic\n",
      "Decoded sentence: htep eched\n",
      "\n",
      "-\n",
      "Input sentence: 29 Antonio\n",
      "\n",
      "GT sentence: SAn Antonio\n",
      "Decoded sentence: 2. Sorent atrorid\n",
      "\n",
      "-\n",
      "Input sentence: Ferss\n",
      "\n",
      "GT sentence: TEXAS\n",
      "Decoded sentence: Forser\n",
      "\n",
      "-\n",
      "Input sentence: Tiursiry MelihNptis\n",
      "\n",
      "GT sentence: University Health Hospital\n",
      "Decoded sentence: Tient istived Individent:\n",
      "\n",
      "-\n",
      "Input sentence: atlor\n",
      "\n",
      "GT sentence: N/A\n",
      "Decoded sentence: Stovital:\n",
      "\n",
      "-\n",
      "Input sentence: 57. M\n",
      "\n",
      "GT sentence: SA TX\n",
      "Decoded sentence: S: 64.5\n",
      "\n",
      "-\n",
      "Input sentence: Fasbeasleson\n",
      "\n",
      "GT sentence: Zachary Jameson\n",
      "Decoded sentence: Fabssobse ack\n",
      "\n",
      "-\n",
      "Input sentence: cfioprctie medlaie\n",
      "\n",
      "GT sentence: Chiropractic Medicine\n",
      "Decoded sentence: ccrocident of ble95\n",
      "\n",
      "-\n",
      "Input sentence: Brorgut\n",
      "\n",
      "GT sentence: Dr Fiegan\n",
      "Decoded sentence: Brrent To:\n",
      "\n",
      "-\n",
      "Input sentence: fifanican\n",
      "\n",
      "GT sentence: Pediatrician\n",
      "Decoded sentence: Cffin: Erich\n",
      "\n",
      "-\n",
      "Input sentence: Dkyons\n",
      "\n",
      "GT sentence: Dr. Lyons\n",
      "Decoded sentence: Dy-1- no\n",
      "\n",
      "-\n",
      "Input sentence: Mirainl tawe Matr\n",
      "\n",
      "GT sentence: Urgent Care Doctor\n",
      "Decoded sentence: Miriat status: Farrid\n",
      "\n",
      "-\n",
      "Input sentence: plnl Athur\n",
      "\n",
      "GT sentence: Dr. Kyle Arthur\n",
      "Decoded sentence: Paid Athes\n",
      "\n",
      "-\n",
      "Input sentence: Drotmenties lsond Mat\n",
      "\n",
      "GT sentence: Orthopedics/Sports Med.\n",
      "Decoded sentence: Atorsens Mfortacted ON:\n",
      "\n",
      "-\n",
      "Input sentence: Tor Soih Mrintlane\n",
      "\n",
      "GT sentence: Cox South Urgent Care\n",
      "Decoded sentence: Tor Phint Precurention\n",
      "\n",
      "-\n",
      "Input sentence: nay Lusit\n",
      "\n",
      "GT sentence: X-Ray/Visit\n",
      "Decoded sentence: Lant Long\n",
      "\n",
      "-\n",
      "Input sentence: DrToshua Gluoke\n",
      "\n",
      "GT sentence: Dr. Joshua Gluck\n",
      "Decoded sentence: DaTh of Date:\n",
      "\n",
      "-\n",
      "Input sentence: Nuw lehent Betided\n",
      "\n",
      "GT sentence: New Patient Detailed\n",
      "Decoded sentence: Neursule - echast 19)\n",
      "\n",
      "-\n",
      "Input sentence: Sey reffened\n",
      "\n",
      "GT sentence: Self Refferred\n",
      "Decoded sentence: Servery - note:\n",
      "\n",
      "-\n",
      "Input sentence: ste gofh aensi whia Tredeil\n",
      "\n",
      "GT sentence: Gluck, Joshua S. M.D/Medical\n",
      "Decoded sentence: stre should vars - yes inn.\n",
      "\n",
      "-\n",
      "Input sentence: o hpedrea\n",
      "\n",
      "GT sentence: Orthopedics\n",
      "Decoded sentence: • Proredre\n",
      "\n",
      "-\n",
      "Input sentence: medieal\n",
      "\n",
      "GT sentence: Medical\n",
      "Decoded sentence: Indicated:\n",
      "\n",
      "-\n",
      "Input sentence: pentun\n",
      "\n",
      "GT sentence: Ventura\n",
      "Decoded sentence: Specialtn\n",
      "\n",
      "-\n",
      "Input sentence: 1has dauion faceesr\n",
      "\n",
      "GT sentence: I was playing soccer\n",
      "Decoded sentence: 11  sertices by Surghons\n",
      "\n",
      "-\n",
      "Input sentence: Glavup\n",
      "\n",
      "GT sentence: follow-up\n",
      "Decoded sentence: Claperag\n",
      "\n",
      "-\n",
      "Input sentence: not yat\n",
      "\n",
      "GT sentence: not yet\n",
      "Decoded sentence: on work-\n",
      "\n",
      "-\n",
      "Input sentence: Solboup\n",
      "\n",
      "GT sentence: follow-up\n",
      "Decoded sentence: Soctolinup\n",
      "\n",
      "-\n",
      "Input sentence: Flctrontally Sraned\n",
      "\n",
      "GT sentence: Electronically Signed\n",
      "Decoded sentence: Firstrdary/day M.GH\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "encoder_input_data = vectorize_data(input_texts=input_texts, max_encoder_seq_length=max_encoder_seq_length, num_encoder_tokens=num_encoder_tokens, vocab_to_int=vocab_to_int)\n",
    "\n",
    "# Sample output from train data\n",
    "decoded_sentences = []\n",
    "\n",
    "for seq_index in range(len(input_texts)):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    target_text = gt_texts[seq_index]\n",
    "    decoded_sentence = decode_sequence(input_seq, encoder_model, decoder_model, num_decoder_tokens, int_to_vocab)\n",
    "    \n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('GT sentence:', target_text)\n",
    "    print('Decoded sentence:', decoded_sentence)   \n",
    "    decoded_sentences.append(decoded_sentence)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER_spell_correction |TEST=  0.18949468085106383\n"
     ]
    }
   ],
   "source": [
    "WER_spell_correction = calculate_WER(gt_texts, decoded_sentences)\n",
    "print('WER_spell_correction |TEST= ', WER_spell_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER_OCR |TEST=  0.16023936170212766\n"
     ]
    }
   ],
   "source": [
    "WER_OCR = calculate_WER(gt_texts, input_texts)\n",
    "print('WER_OCR |TEST= ', WER_OCR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
