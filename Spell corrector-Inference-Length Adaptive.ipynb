{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We tackle the problem of OCR post processing. In OCR, we map the image form of the document into the text domain. This is done first using an CNN+LSTM+CTC model, in our case based on tesseract. Since this output maps only image to text, we need something on top to validate and correct language semantics.\n",
    "\n",
    "The idea is to build a language model, that takes the OCRed text and corrects it based on language knowledge. The langauge model could be:\n",
    "- Char level: the aim is to capture the word morphology. In which case it's like a spelling correction system.\n",
    "- Word level: the aim is to capture the sentence semnatics. But such systems suffer from the OOV problem.\n",
    "- Fusion: to capture semantics and morphology language rules. The output has to be at char level, to avoid the OOV. However, the input can be char, word or both.\n",
    "\n",
    "The fusion model target is to learn:\n",
    "\n",
    "    p(char | char_context, word_context)\n",
    "\n",
    "In this workbook we use seq2seq vanilla Keras implementation, adapted from the lstm_seq2seq example on Eng-Fra translation task. The adaptation involves:\n",
    "\n",
    "- Adapt to spelling correction, on char level\n",
    "- Pre-train on a noisy, medical sentences\n",
    "- Fine tune a residual, to correct the mistakes of tesseract \n",
    "- Limit the input and output sequence lengths\n",
    "- Enusre teacher forcing auto regressive model in the decoder\n",
    "- Limit the padding per batch\n",
    "- Learning rate schedule\n",
    "- Bi-directional LSTM Encoder\n",
    "- Bi-directional GRU Encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Bidirectional, Concatenate, GRU\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, LearningRateScheduler\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from autocorrect import spell\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit gpu allocation. allow_growth, or gpu_fraction\n",
    "def gpu_alloc():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_alloc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_WER_sent(gt, pred):\n",
    "    '''\n",
    "    calculate_WER('calculating wer between two sentences', 'calculate wer between two sentences')\n",
    "    '''\n",
    "    gt_words = gt.lower().split(' ')\n",
    "    pred_words = pred.lower().split(' ')\n",
    "    d = np.zeros(((len(gt_words) + 1), (len(pred_words) + 1)), dtype=np.uint8)\n",
    "    # d = d.reshape((len(gt_words)+1, len(pred_words)+1))\n",
    "\n",
    "    # Initializing error matrix\n",
    "    for i in range(len(gt_words) + 1):\n",
    "        for j in range(len(pred_words) + 1):\n",
    "            if i == 0:\n",
    "                d[0][j] = j\n",
    "            elif j == 0:\n",
    "                d[i][0] = i\n",
    "\n",
    "    # computation\n",
    "    for i in range(1, len(gt_words) + 1):\n",
    "        for j in range(1, len(pred_words) + 1):\n",
    "            if gt_words[i - 1] == pred_words[j - 1]:\n",
    "                d[i][j] = d[i - 1][j - 1]\n",
    "            else:\n",
    "                substitution = d[i - 1][j - 1] + 1\n",
    "                insertion = d[i][j - 1] + 1\n",
    "                deletion = d[i - 1][j] + 1\n",
    "                d[i][j] = min(substitution, insertion, deletion)\n",
    "    return d[len(gt_words)][len(pred_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_WER(gt, pred):\n",
    "    '''\n",
    "\n",
    "    :param gt: list of sentences of the ground truth\n",
    "    :param pred: list of sentences of the predictions\n",
    "    both lists must have the same length\n",
    "    :return: accumulated WER\n",
    "    '''\n",
    "#    assert len(gt) == len(pred)\n",
    "    WER = 0\n",
    "    nb_w = 0\n",
    "    for i in range(len(gt)):\n",
    "        #print(gt[i])\n",
    "        #print(pred[i])\n",
    "        WER += calculate_WER_sent(gt[i], pred[i])\n",
    "        nb_w += len(gt[i])\n",
    "\n",
    "    return WER / nb_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_with_gt(file_name, num_samples, max_sent_len, min_sent_len, delimiter='\\t', gt_index=1, prediction_index=0):\n",
    "    '''Load data from txt file, with each line has: <TXT><TAB><GT>. The  target to the decoder muxt have \\t as the start trigger and \\n as the stop trigger.'''\n",
    "    cnt = 0  \n",
    "    input_texts = []\n",
    "    gt_texts = []\n",
    "    target_texts = []\n",
    "    for row in open(file_name, encoding='utf8'):\n",
    "        if cnt < num_samples :\n",
    "            #print(row)\n",
    "            sents = row.split(delimiter)\n",
    "            input_text = sents[prediction_index]\n",
    "            \n",
    "            target_text = '\\t' + sents[gt_index] + '\\n'\n",
    "            if len(input_text) > min_sent_len and len(input_text) < max_sent_len and len(target_text) > min_sent_len and len(target_text) < max_sent_len:\n",
    "                cnt += 1\n",
    "                \n",
    "                input_texts.append(input_text)\n",
    "                target_texts.append(target_text)\n",
    "                gt_texts.append(sents[gt_index])\n",
    "    return input_texts, target_texts, gt_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name, num_samples, max_sent_len, min_sent_len):\n",
    "    '''Load data from txt file, with each line has: <TXT><TAB><GT>. The  target to the decoder muxt have \\t as the start trigger and \\n as the stop trigger.'''\n",
    "    cnt = 0  \n",
    "    input_texts = []   \n",
    "    \n",
    "    #for row in open(file_name, encoding='utf8'):\n",
    "    for row in open(file_name):\n",
    "        if cnt < num_samples :            \n",
    "            input_text = row           \n",
    "            if len(input_text) > min_sent_len and len(input_text) < max_sent_len:\n",
    "                cnt += 1                \n",
    "                input_texts.append(input_text)\n",
    "    return input_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_data(input_texts, max_encoder_seq_length, num_encoder_tokens, vocab_to_int):\n",
    "    \n",
    "    if(len(input_texts) > max_encoder_seq_length):\n",
    "        input_texts = input_texts[:max_encoder_seq_length]\n",
    "    \n",
    "    '''Prepares the input text and targets into the proper seq2seq numpy arrays'''\n",
    "    encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length),\n",
    "    dtype='float32')\n",
    "    \n",
    "    for i, input_text in enumerate(input_texts):\n",
    "        for t, char in enumerate(input_text[:max_encoder_seq_length]):\n",
    "            # c0..cn\n",
    "            encoder_input_data[i, t] = vocab_to_int[char]\n",
    "                \n",
    "    return encoder_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, encoder_model, decoder_model, num_decoder_tokens, max_decoder_seq_length, vocab_to_int, int_to_vocab):\n",
    "    \n",
    "    #print(max_decoder_seq_length)\n",
    "    # Encode the input as state vectors.\n",
    "    encoder_outputs, h, c  = encoder_model.predict(input_seq)\n",
    "    states_value = [h,c]\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = vocab_to_int['\\t']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    #print(input_seq)\n",
    "    attention_density = []\n",
    "    i = 0\n",
    "    special_chars = ['\\\\', '/', '-', '—' , ':', '[', ']', ',', '.', '\"', ';', '%', '~', '(', ')', '{', '}', '$', '#']\n",
    "    #special_chars = []\n",
    "    while not stop_condition:\n",
    "        #print(target_seq)\n",
    "        output_tokens, attention, h, c  = decoder_model.predict(\n",
    "            [target_seq, encoder_outputs] + states_value)\n",
    "        #print(attention.shape)\n",
    "        attention_density.append(attention[0][0])# attention is max_sent_len x 1 since we have num_time_steps = 1 for the output\n",
    "        # Sample a token\n",
    "        #print(output_tokens.shape)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        \n",
    "        #print(sampled_token_index)\n",
    "        sampled_char = int_to_vocab[sampled_token_index]\n",
    "        \n",
    "        orig_char = int_to_vocab[int(input_seq[:,i][0])]\n",
    "        \n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "            #print('End', sampled_char, 'Len ', len(decoded_sentence), 'Max len ', max_decoder_seq_length)\n",
    "            sampled_char = ''\n",
    "        \n",
    "        # Copy digits as it, since the spelling corrector is not good at digit corrections\n",
    "        \n",
    "        if(orig_char.isdigit() or orig_char in special_chars):\n",
    "            decoded_sentence += orig_char            \n",
    "        else:\n",
    "            if(sampled_char.isdigit() or sampled_char in special_chars):\n",
    "                decoded_sentence += ''\n",
    "            else:\n",
    "                decoded_sentence += sampled_char\n",
    "        \n",
    "        #decoded_sentence += sampled_char\n",
    "\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "        \n",
    "        i += 1\n",
    "        if(i > 48):\n",
    "            i = 0\n",
    "    attention_density = np.array(attention_density)\n",
    "    \n",
    "    # Word level spell correct\n",
    "    '''\n",
    "    corrected_decoded_sentence = ''\n",
    "    for w in decoded_sentence.split(' '):\n",
    "        corrected_decoded_sentence += spell(w) + ' '\n",
    "    decoded_sentence = corrected_decoded_sentence\n",
    "    '''\n",
    "    return decoded_sentence, attention_density\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_spell_correct(decoded_sentence):\n",
    "    corrected_decoded_sentence = ''\n",
    "    special_chars = ['\\\\', '/', '-', '—' , ':', '[', ']', ',', '.', '\"', ';', '%', '~', '(', ')', '{', '}', '$', '#']\n",
    "    for w in decoded_sentence.split(' '):\n",
    "        if((len(re.findall(r'\\d+', w))==0) and not (w in special_chars)):\n",
    "            corrected_decoded_sentence += spell(w) + ' '\n",
    "        else:\n",
    "            corrected_decoded_sentence += w + ' '\n",
    "    return corrected_decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence, vocab):\n",
    "    s = ''\n",
    "    for c in sentence.strip():\n",
    "        if c not in vocab or c == '  ':\n",
    "            s += ''\n",
    "        else:\n",
    "            s += c\n",
    "            \n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../dat/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sent_lengths = [50, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = {}\n",
    "model_file = {}\n",
    "encoder_model_file = {}\n",
    "decoder_model_file = {}\n",
    "model = {}\n",
    "encoder_model = {}\n",
    "decoder_model = {}\n",
    "vocab = {}\n",
    "vocab_to_int = {}\n",
    "int_to_vocab = {}\n",
    "max_sent_len = {}\n",
    "min_sent_len = {}\n",
    "num_decoder_tokens = {}\n",
    "num_encoder_tokens = {}\n",
    "max_encoder_seq_length = {}\n",
    "max_decoder_seq_length = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py:269: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in max_sent_lengths:\n",
    "    vocab_file[i] = 'vocab-{}.npz'.format(i)\n",
    "    model_file[i] = 'best_model-{}.hdf5'.format(i)\n",
    "    encoder_model_file[i] = 'encoder_model-{}.hdf5'.format(i)\n",
    "    decoder_model_file[i] = 'decoder_model-{}.hdf5'.format(i)\n",
    "    \n",
    "    vocab = np.load(file=vocab_file[i])\n",
    "    vocab_to_int[i] = vocab['vocab_to_int'].item()\n",
    "    int_to_vocab[i] = vocab['int_to_vocab'].item()\n",
    "    max_sent_len[i] = vocab['max_sent_len']\n",
    "    min_sent_len[i] = vocab['min_sent_len']\n",
    "    input_characters = sorted(list(vocab_to_int))\n",
    "    num_decoder_tokens[i] = num_encoder_tokens[i] = len(input_characters) #int(encoder_model.layers[0].input.shape[2])\n",
    "    max_encoder_seq_length[i] = max_decoder_seq_length[i] = max_sent_len[i] - 1#max([len(txt) for txt in input_texts])\n",
    "    \n",
    "    model[i] = load_model(model_file[i])\n",
    "    encoder_model[i] = load_model(encoder_model_file[i])\n",
    "    decoder_model[i] = load_model(decoder_model_file[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000000\n",
    "#tess_correction_data = os.path.join(data_path, 'test_data.txt')\n",
    "#input_texts = load_data(tess_correction_data, num_samples, max_sent_len, min_sent_len)\n",
    "\n",
    "OCR_data = os.path.join(data_path, 'new_trained_data.txt')\n",
    "#input_texts, target_texts, gt_texts = load_data_with_gt(OCR_data, num_samples, max_sent_len, min_sent_len, delimiter='|',gt_index=0, prediction_index=1)\n",
    "input_texts, target_texts, gt_texts = load_data_with_gt(OCR_data, num_samples, max_sent_len=10000, min_sent_len=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951\n",
      "Me dieal Provider Roles: Treating  \n",
      " \tMedical Provider Roles: Treating\n",
      "\n",
      "\n",
      "Provider First Name: Christine  \n",
      " \tProvider First Name: Christine\n",
      "\n",
      "\n",
      "Provider Last Name: Nolen, MD  \n",
      " \tProvider Last Name: Nolen, MD\n",
      "\n",
      "\n",
      "Address Line 1 : 7 25 American Avenue  \n",
      " \tAddress Line 1 : 725 American Avenue\n",
      "\n",
      "\n",
      "City. W’aukesha  \n",
      " \tCity: Waukesha\n",
      "\n",
      "\n",
      "StatefProvinee: ‘WI  \n",
      " \tState/Province: WI\n",
      "\n",
      "\n",
      "Postal Code: 5 31 88  \n",
      " \tPostal Code: 53188\n",
      "\n",
      "\n",
      "Country\". US  \n",
      " \tCountry:  US\n",
      "\n",
      "\n",
      "Business Telephone: (2 62) 92 8- 1000  \n",
      " \tBusiness Telephone: (262) 928- 1000\n",
      "\n",
      "\n",
      "Date ot‘Pirst Visit: 1 2/01f20 17  \n",
      " \tDate of First Visit: 12/01/2017\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "print(len(input_texts))\n",
    "for i in range(10):\n",
    "    print(input_texts[i], '\\n', target_texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ninput_texts_ = []\\nfor sent in input_texts:\\n    sent_ = ''\\n    for word in sent.split(' '):\\n        sent_ += spell(word) + ' '\\n    input_texts_.append(sent_)\\ninput_texts = input_texts_\\ninput_texts_ = []\\n# Sample data\\nprint(len(input_texts))\\nfor i in range(10):\\n    print(input_texts[i], '\\n', target_texts[i])\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spell correct before inference\n",
    "'''\n",
    "input_texts_ = []\n",
    "for sent in input_texts:\n",
    "    sent_ = ''\n",
    "    for word in sent.split(' '):\n",
    "        sent_ += spell(word) + ' '\n",
    "    input_texts_.append(sent_)\n",
    "input_texts = input_texts_\n",
    "input_texts_ = []\n",
    "# Sample data\n",
    "print(len(input_texts))\n",
    "for i in range(10):\n",
    "    print(input_texts[i], '\\n', target_texts[i])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Lenght =  50\n",
      "Input sentence: Me dieal Provider Roles: Treating\n",
      "GT sentence: Medical Provider Roles: Treating\n",
      "Char Decoded sentence: Medical Provider Roles:Treating\n",
      "Word Decoded sentence: Me deal Provider Roles Treating \n",
      "-Lenght =  50\n",
      "Input sentence: Provider First Name: Christine\n",
      "GT sentence: Provider First Name: Christine\n",
      "Char Decoded sentence: Provider First Name: Christine\n",
      "Word Decoded sentence: Provider First Name Christine \n",
      "-Lenght =  50\n",
      "Input sentence: Provider Last Name: Nolen, MD\n",
      "GT sentence: Provider Last Name: Nolen, MD\n",
      "Char Decoded sentence: Provider Last Name: Nolen, MD\n",
      "Word Decoded sentence: Provider Last Name Dolens MD \n",
      "-Lenght =  50\n",
      "Input sentence: Address Line 1 : 7 25 American Avenue\n",
      "GT sentence: Address Line 1 : 725 American Avenue\n",
      "Char Decoded sentence: Address Line 1 : 7 25rden Abuerter\n",
      "Word Decoded sentence: Address Line 1 : 7 25 American Avenue \n",
      "-Lenght =  50\n",
      "Input sentence: City. W’aukesha\n",
      "GT sentence: City: Waukesha\n",
      "Char Decoded sentence: City. Way Warl ’ialth\n",
      "Word Decoded sentence: City Waukesha \n",
      "-Lenght =  50\n",
      "Input sentence: StatefProvinee: ‘WI\n",
      "GT sentence: State/Province: WI\n",
      "Char Decoded sentence: StateProvince: \n",
      "Word Decoded sentence: StatefProvinee: OWI \n",
      "-Lenght =  50\n",
      "Input sentence: Postal Code: 5 31 88\n",
      "GT sentence: Postal Code: 53188\n",
      "Char Decoded sentence: Postal Code: 5\n",
      "Word Decoded sentence: Postal Codes 5 31 88 \n",
      "-Lenght =  50\n",
      "Input sentence: Country\". US\n",
      "GT sentence: Country:  US\n",
      "Char Decoded sentence: Country\".\n",
      "Word Decoded sentence: Country US \n",
      "-Lenght =  50\n",
      "Input sentence: Business Telephone: (2 62) 92 8- 1000\n",
      "GT sentence: Business Telephone: (262) 928- 1000\n",
      "Char Decoded sentence: Business Telephone: (2’62)t92a8- 1000Uk\n",
      "Word Decoded sentence: Business Telephone (2 62) 92 8- 1000 \n",
      "-Lenght =  50\n",
      "Input sentence: Date ot‘Pirst Visit: 1 2/01f20 17\n",
      "GT sentence: Date of First Visit: 12/01/2017\n",
      "Char Decoded sentence: Date of First Visit: 12/012\n",
      "Word Decoded sentence: Date ot‘Pirst Visit 1 2/01f20 17 \n",
      "-Lenght =  50\n",
      "Input sentence: Medical Protitler Information — Hospitalization\n",
      "GT sentence: Medical Provider Information - Hospitalization\n",
      "Char Decoded sentence: Medical Provider Information —ospitaliation\n",
      "Word Decoded sentence: Medical Profiteer Information — Hospitalization \n",
      "-Lenght =  50\n",
      "Input sentence: Hospital Name: W'aukesha Memorial Hospital\n",
      "GT sentence: Hospital Name: Waukesha Memorial Hospital\n",
      "Char Decoded sentence: Coparthreal N:me Wadhes Momplate Malsh\n",
      "Word Decoded sentence: Hospital Name Waukesha Memorial Hospital \n",
      "-Lenght =  50\n",
      "Input sentence: Address Line 1 : 7\" 25 Arnerie an Drive\n",
      "GT sentence: Address Line 1 : 725 American Drive\n",
      "Char Decoded sentence: Address Line 1 : 7\"A25in shoevitired\n",
      "Word Decoded sentence: Address Line 1 : 7\" 25 Arteries an Drive \n",
      "-Lenght =  50\n",
      "Input sentence: City. ‘Waukesha\n",
      "GT sentence: City: Waukesha\n",
      "Char Decoded sentence: City. Way Ware Must\n",
      "Word Decoded sentence: City Waukesha \n",
      "-Lenght =  50\n",
      "Input sentence: StatefProﬁnoe: W'I\n",
      "GT sentence: State/Province: WI\n",
      "Char Decoded sentence: StateProvinc: \n",
      "Word Decoded sentence: StatefProﬁnoe: Wei \n",
      "-Lenght =  50\n",
      "Input sentence: Postal Code: 5 31 88\n",
      "GT sentence: Postal Code: 53188\n",
      "Char Decoded sentence: Postal Code: 5\n",
      "Word Decoded sentence: Postal Codes 5 31 88 \n",
      "-Lenght =  50\n",
      "Input sentence: Country. US\n",
      "GT sentence: Country: US\n",
      "Char Decoded sentence: Country. H\n",
      "Word Decoded sentence: Country US \n",
      "-Lenght =  50\n",
      "Input sentence: Claim Type: VB Accident - Accidental Injury\n",
      "GT sentence: Claim Type: VB Accident - Accidental Injury\n",
      "Char Decoded sentence: Claim Type: VB Accident - Accidental Injury\n",
      "Word Decoded sentence: Claim Type VB Accident - Accidental Injury \n",
      "-Lenght =  100\n",
      "Input sentence: Who The Reporled ETEIII Happened To: ErrployeefPolicyholders Child\n",
      "GT sentence: Who The Reported Event Happened To: Employee/Policyholder's child\n",
      "Char Decoded sentence: Who The Reported Evert Happened To:Erployee Policyholders Child\n",
      "Word Decoded sentence: Who The Reported ETEIII Happened To ErrployeefPolicyholders Child \n",
      "-Lenght =  50\n",
      "Input sentence: Policyhold El':\"0“1l€l' In form ariorl\n",
      "GT sentence: Policyholder/Owner Information\n",
      "Char Decoded sentence: Policyholder I:\"0t1fier Information\n",
      "Word Decoded sentence: Policyholder El':\"0“1l€l' In form prior \n",
      "-Lenght =  50\n",
      "Input sentence: First Name:\n",
      "GT sentence: First Name:\n",
      "Char Decoded sentence: First Name:\n",
      "Word Decoded sentence: First Name \n",
      "-Lenght =  50\n",
      "Input sentence: Middle Narmflnitial:\n",
      "GT sentence: Middle Name/Initial:\n",
      "Char Decoded sentence: Middle NameInitial:\n",
      "Word Decoded sentence: Middle Narmflnitial: \n",
      "-Lenght =  50\n",
      "Input sentence: Last Name:\n",
      "GT sentence: Last Name:\n",
      "Char Decoded sentence: Last Name:\n",
      "Word Decoded sentence: Last Name \n",
      "-Lenght =  50\n",
      "Input sentence: Social 8 ecurity Number:\n",
      "GT sentence: Social Security Number:\n",
      "Char Decoded sentence: Social 8ecurity Number:\n",
      "Word Decoded sentence: Social 8 security Number \n",
      "-Lenght =  50\n",
      "Input sentence: Birth Date:\n",
      "GT sentence: Birth Date:\n",
      "Char Decoded sentence: Birth Date:\n",
      "Word Decoded sentence: Birth Date \n",
      "-Lenght =  50\n",
      "Input sentence: Gender:\n",
      "GT sentence: Gender:\n",
      "Char Decoded sentence: Gender:\n",
      "Word Decoded sentence: Gender \n",
      "-Lenght =  50\n",
      "Input sentence: Language Preference:\n",
      "GT sentence: Language Preference:\n",
      "Char Decoded sentence: Language Preference:\n",
      "Word Decoded sentence: Language Preference \n",
      "-Lenght =  50\n",
      "Input sentence: Address Line 1:\n",
      "GT sentence: Address Line 1:\n",
      "Char Decoded sentence: Address Line 1:\n",
      "Word Decoded sentence: Address Line 1: \n",
      "-Lenght =  50\n",
      "Input sentence: CW-\n",
      "GT sentence: City:\n",
      "Char Decoded sentence: Co-pay\n",
      "Word Decoded sentence: CWO \n",
      "-Lenght =  50\n",
      "Input sentence: StatefProvince :\n",
      "GT sentence: State/Province:\n",
      "Char Decoded sentence: StateProvince:\n",
      "Word Decoded sentence: StatefProvince : \n",
      "-Lenght =  50\n",
      "Input sentence: Postal Code:\n",
      "GT sentence: Postal Code:\n",
      "Char Decoded sentence: Postal Code:\n",
      "Word Decoded sentence: Postal Codes \n",
      "-Lenght =  50\n",
      "Input sentence: Country\n",
      "GT sentence: Country:\n",
      "Char Decoded sentence: Country\n",
      "Word Decoded sentence: Country \n",
      "-Lenght =  50\n",
      "Input sentence: Best Phone Number to be Reached Dming the Day\n",
      "GT sentence: Best Phone Number to be Reached During the Day\n",
      "Char Decoded sentence: Best Phone Number to be Reached Dumine Date\n",
      "Word Decoded sentence: Best Phone Number to be Reached Doing the Day \n",
      "-Lenght =  50\n",
      "Input sentence: Email Address:\n",
      "GT sentence: Email Address:\n",
      "Char Decoded sentence: Email Address:\n",
      "Word Decoded sentence: Email Address \n",
      "-Lenght =  50\n",
      "Input sentence: PROI—IEALTH CARE\n",
      "GT sentence: PROHEALTH CARE\n",
      "Char Decoded sentence: PROI—DIKE CAIE\n",
      "Word Decoded sentence: PROI—IEALTH CARE \n",
      "-Lenght =  100\n",
      "Input sentence: Waukesha Memorial Hospital. Inc. drbla ProHealth Waukesha Memorial Hospital\n",
      "GT sentence: Waukesha Memorial Hospital, Inc,d/b/a ProHealth Waukesha Memorial Hospital\n",
      "Char Decoded sentence: Wauke ha Memorial Hospital. Inc. drelate anc Workeshal Memorial Hospital\n",
      "Word Decoded sentence: Waukesha Memorial Hospital Inch dobla ProHealth Waukesha Memorial Hospital \n",
      "-Lenght =  100\n",
      "Input sentence: 0conomowoc Memorial Hospital, Inc., dinla ProHealIh Oconornowoc Memorial Hospi\n",
      "GT sentence: Oconomowoc Memorial Hospital, Inc., d/b/a ProHealth Oconomowoc Memorial Hospital\n",
      "Char Decoded sentence: 0conomoc Memorial Hospital ,nc.,dino ProHeal 0nconowococ Memorial Hospita, Hos.,\n",
      "Word Decoded sentence: 0conomowoc Memorial Hospital Inch dinka ProHealIh Oconornowoc Memorial Hopi \n",
      "-Lenght =  100\n",
      "Input sentence: PraI-Iealth Care Msdicai Aseoolelas. Ino. di‘ba'a ProHeaith Medical Group\n",
      "GT sentence: ProHealth Care Medical Associates, Inc., d/b/a ProHealth Medical Group\n",
      "Char Decoded sentence: Prov-l Care Medical Addical Aderal .dera. Crovedental-Cendicate Medical Cespone\n",
      "Word Decoded sentence: PraI-Iealth Care Medical Aseoolelas. Inoc di‘ba'a ProHeaith Medical Group \n",
      "-Lenght =  50\n",
      "Input sentence: STATEMENT OF SERVICES\n",
      "GT sentence: STATEMENT OF SERVICES\n",
      "Char Decoded sentence: STATEMENT OF SERVICES\n",
      "Word Decoded sentence: STATEMENT OF SERVICES \n",
      "-Lenght =  50\n",
      "Input sentence: GUARANTOR ID _ I\n",
      "GT sentence: GUARANTOR ID\n",
      "Char Decoded sentence: GKARANTOR ID\n",
      "Word Decoded sentence: GUARANTOR ID a I \n",
      "-Lenght =  100\n",
      "Input sentence: TT INSURANCIEINFORMATICN PRIMARY: UMR SECONDARY: '\n",
      "GT sentence: INSURANCE INFORMATION PRIMARY: UMR SECONDARY:\n",
      "Char Decoded sentence: INSURANCEN ORN ORMATION PRIMARY:UMMARY UMCOND:RY\n",
      "Word Decoded sentence: TT INSURANCIEINFORMATICN PRIMARY UMW SECONDARY a \n",
      "-Lenght =  50\n",
      "Input sentence: STATEMENT DATE 1121/2018\n",
      "GT sentence: STATEMENT DATE 1/21/2018\n",
      "Char Decoded sentence: STATEMENT DATE 1121/2\n",
      "Word Decoded sentence: STATEMENT DATE 1121/2018 \n",
      "-Lenght =  50\n",
      "Input sentence: PATIENT NAME\n",
      "GT sentence: PATIENT NAME\n",
      "Char Decoded sentence: PATIENT NAME\n",
      "Word Decoded sentence: PATIENT NAME \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Lenght =  100\n",
      "Input sentence: pAvMENTsm'E—I: STATEMENT DATE WILL NOT APPEAR ON THIS STATEMENT\n",
      "GT sentence: PAYMENTS RECEIVED AFTER STATE DATE WILL NOT APPEAR ON THIS STATEMENT\n",
      "Char Decoded sentence: PAYMENTSERV—N: STATEMENT DATE WILL NOT APPEAR ON THIS STATEM—N:\n",
      "Word Decoded sentence: pAvMENTsm'E—I: STATEMENT DATE WILL NOT APPEAR ON THIS STATEMENT \n",
      "-Lenght =  50\n",
      "Input sentence: DATE\n",
      "GT sentence: DATE\n",
      "Char Decoded sentence: DATE\n",
      "Word Decoded sentence: DATE \n",
      "-Lenght =  50\n",
      "Input sentence: DESCRIPTION\n",
      "GT sentence: DESCRIPTION\n",
      "Char Decoded sentence: DESCRIPTION\n",
      "Word Decoded sentence: DESCRIPTION \n",
      "-Lenght =  50\n",
      "Input sentence: _AYMENTS\n",
      "GT sentence: PAYMENTS\n",
      "Char Decoded sentence: PAYMENTS\n",
      "Word Decoded sentence: PAYMENTS \n",
      "-Lenght =  50\n",
      "Input sentence: _DJUSTMENTS\n",
      "GT sentence: ADJUSTMENTS\n",
      "Char Decoded sentence: DJJT MSTIES\n",
      "Word Decoded sentence: ADJUSTMENTS \n",
      "-Lenght =  50\n",
      "Input sentence: PAT'ENT BALANCE\n",
      "GT sentence: PATIENTS BALANCE\n",
      "Char Decoded sentence: PATIENT BALANCE\n",
      "Word Decoded sentence: PATIENT BALANCE \n",
      "-Lenght =  50\n",
      "Input sentence: INVOICE NUMBER. ' .\n",
      "GT sentence: INVOICE NUMBER :\n",
      "Char Decoded sentence: INVOICE NKMBER.\n",
      "Word Decoded sentence: INVOICE NUMBER a . \n",
      "-Lenght =  50\n",
      "Input sentence: _ Previous Visit Balance - Visit # — .\n",
      "GT sentence: Previous Visit Balance- Visit #\n",
      "Char Decoded sentence: • Provide Visit Balance -isit k#—\n",
      "Word Decoded sentence: a Previous Visit Balance - Visit # — . \n",
      "-Lenght =  50\n",
      "Input sentence: CURRENT TOTAL VISIT BALANCE\n",
      "GT sentence: CURRENT TOTAL VISIT BALANCE 964.70\n",
      "Char Decoded sentence: CUREROTAT OF BALLECT BALANCE\n",
      "Word Decoded sentence: CURRENT TOTAL VISIT BALANCE \n",
      "-Lenght =  100\n",
      "Input sentence: - IF YOU HAVE ANY QUESTIONS OR TOI MAKE PAYMENT CALL, ONLY INVOICESI WITH A BALANCE DU_E_ APPEAR FOR ONLINE PAYMENTS www. Qrohealthoare. org.\n",
      "GT sentence: IF YOU HAVE ANY QUESTIONS OR TO MAKE PAYMENT CALL, ONLY INVOICES  WITH A BALANCE DUE APPEAR. FOR ONLINE PAYMENTS www.prohealthcare.org.\n",
      "Char Decoded sentence: - IN OU HAVE AN WON MALE INS OR TOINS ORNS INAL M-KE INS ONE WINAICE DUE APLANCE DUE APPEAR FOP-EAR \n",
      "Word Decoded sentence: - IF YOU HAVE ANY QUESTIONS OR TOI MAKE PAYMENT CALL ONLY INVOICES WITH A BALANCE DUE APPEAR FOR ONLINE PAYMENTS www Qrohealthoare. org \n",
      "-Lenght =  50\n",
      "Input sentence: PLEASE PAY THIS\n",
      "GT sentence: PLEASE PAY THIS\n",
      "Char Decoded sentence: PLEASE PAY TIS\n",
      "Word Decoded sentence: PLEASE PAY THIS \n",
      "-Lenght =  100\n",
      "Input sentence: MESSAGES: Please see reverse side for additional information\n",
      "GT sentence: MESSAGES: Please see reverse side for additional information\n",
      "Char Decoded sentence: MESSAGES: Please see reverse sede for additional informat:on\n",
      "Word Decoded sentence: MESSAGES Please see reverse side for additional information \n",
      "-Lenght =  100\n",
      "Input sentence: I The balance due' Is your responsibility Pay the full balance or contact Customer Relations to set up a SiIJitable payment arrangement -\n",
      "GT sentence: The balance due is your responsibility. Pay the full balance or contact Customer Relations to set up a suitable payment arrangement.\n",
      "Char Decoded sentence: Is The balanced cont hent calance Cast the full and contact Cust the full Contations to seltions to \n",
      "Word Decoded sentence: I The balance due Is your responsibility Pay the full balance or contact Customer Relations to set up a SiIJitable payment arrangement - \n",
      "-Lenght =  50\n",
      "Input sentence: RETURN THIS PORTION WITH YOURIPAYMENIT\n",
      "GT sentence: RETURN THIS PORTION WITH YOUR PAYMENT\n",
      "Char Decoded sentence: RETKRN PE STATE IN O R POYMENT\n",
      "Word Decoded sentence: RETURN THIS PORTION WITH YOURIPAYMENIT \n",
      "-Lenght =  100\n",
      "Input sentence: [:I Piease Check box if address is inoorreot or insurawce information has changed andmdicatechange(s)0n revalse side.\n",
      "GT sentence: Please check if address is incorrect or insurance information has changed and indicate charge(s) on reverse side\n",
      "Char Decoded sentence: [:ese Check box insurated in ore insurang and in[:race information has changed and dis cantechang[:\n",
      "Word Decoded sentence: I Please Check box if address is inoorreot or insurance information has changed andmdicatechange(s)0n revulse side \n",
      "-Lenght =  50\n",
      "Input sentence: - VIASTERCARD\n",
      "GT sentence: MASTERCARD\n",
      "Char Decoded sentence: -ASTOVER\n",
      "Word Decoded sentence: - VIASTERCARD \n",
      "-Lenght =  50\n",
      "Input sentence: DISCOVER\n",
      "GT sentence: DISCOVER\n",
      "Char Decoded sentence: DISCOVER\n",
      "Word Decoded sentence: DISCOVER \n",
      "-Lenght =  50\n",
      "Input sentence: VISA\n",
      "GT sentence: VISA\n",
      "Char Decoded sentence: VISCA\n",
      "Word Decoded sentence: VISA \n",
      "-Lenght =  50\n",
      "Input sentence: RATIENTIIAME\n",
      "GT sentence: PATIENT NAME\n",
      "Char Decoded sentence: PATIENT INCE\n",
      "Word Decoded sentence: RATIENTIIAME \n",
      "-Lenght =  50\n",
      "Input sentence: DUEDATE\n",
      "GT sentence: DUE DATE\n",
      "Char Decoded sentence: DKE DATE\n",
      "Word Decoded sentence: DEBATE \n",
      "-Lenght =  50\n",
      "Input sentence: GUARANTORID\n",
      "GT sentence: GUARANTOR ID\n",
      "Char Decoded sentence: GKARANTOR ID\n",
      "Word Decoded sentence: GUARANTORID \n",
      "-Lenght =  50\n",
      "Input sentence: BALANCE DUE\n",
      "GT sentence: BALANCE DUE\n",
      "Char Decoded sentence: BALANCE DKE\n",
      "Word Decoded sentence: BALANCE DUE \n",
      "-Lenght =  50\n",
      "Input sentence: Amount Enclosed\n",
      "GT sentence: Amount Enclosed\n",
      "Char Decoded sentence: Amount Encloped\n",
      "Word Decoded sentence: Amount Enclosed \n",
      "-Lenght =  50\n",
      "Input sentence: MAKE CHECK PAYABLE TO PROHEALTH CARE 5535““ (PC\n",
      "GT sentence: MAKE CHECK PAYABLE TO PROHEALTH CARE\n",
      "Char Decoded sentence: AKTOCEN CARD KST  CONPRASTIENT \n",
      "Word Decoded sentence: MAKE CHECK PAYABLE TO PROHEALTH CARE 5535““ SPC \n",
      "-Lenght =  50\n",
      "Input sentence: EMERGENCY MEDICAL ASSOCIATES :\n",
      "GT sentence: EMERGENCY MEDICAL ASSOCIATES\n",
      "Char Decoded sentence: EMERGENCY MEDICAL ASSOCIATES\n",
      "Word Decoded sentence: EMERGENCY MEDICAL ASSOCIATES : \n",
      "-Lenght =  50\n",
      "Input sentence: STATEMENT DATE 01/03/18\n",
      "GT sentence: STATEMENT DATE  01/03/18\n",
      "Char Decoded sentence: STATEMENT DATE 01/0\n",
      "Word Decoded sentence: STATEMENT DATE 01/03/18 \n",
      "-Lenght =  50\n",
      "Input sentence: —ue DATE _1/13/18\n",
      "GT sentence: DUE DATE 01/13/18\n",
      "Char Decoded sentence: —KE DATE S1/13/18ReviewU\n",
      "Word Decoded sentence: due DATE _1/13/18 \n",
      "-Lenght =  50\n",
      "Input sentence: snow AMOUNT$ PNDHEHE\n",
      "GT sentence: SHOW AMOUNT PAID HERE $\n",
      "Char Decoded sentence: Coun AMOKNT$MANNEST NEME\n",
      "Word Decoded sentence: snow AMOUNT PNDHEHE \n",
      "-Lenght =  50\n",
      "Input sentence: PHONE: 414—423—4120 —ue\n",
      "GT sentence: PHONE: 414-423-4120\n",
      "Char Decoded sentence: PRONE:Y414—423—4120t—\n",
      "Word Decoded sentence: PHONE 414—423—4120 due \n",
      "-Lenght =  50\n",
      "Input sentence: PNDHEHE\n",
      "GT sentence: ADDRESSEE:\n",
      "Char Decoded sentence: PINDEE\n",
      "Word Decoded sentence: PNDHEHE \n",
      "-Lenght =  50\n",
      "Input sentence: - MAKE CHECKS PHASE “3' \"\n",
      "GT sentence: MAKE CHECKS PAYABLE TO:\n",
      "Char Decoded sentence: - MAKC CENCES PAYCN3\n",
      "Word Decoded sentence: - MAKE CHECKS PHASE “3' \" \n",
      "-Lenght =  50\n",
      "Input sentence: EMERGENCY MEDICAL ASSOCIATES\n",
      "GT sentence: EMERGENCY MEDICAL ASSOCIATES\n",
      "Char Decoded sentence: EMERGENCY MEDICAL ASSOCIATES\n",
      "Word Decoded sentence: EMERGENCY MEDICAL ASSOCIATES \n",
      "-Lenght =  50\n",
      "Input sentence: 64-00 INDUSTRIAL LOOP\n",
      "GT sentence: 6400 INDUSTRIAL LOOP\n",
      "Char Decoded sentence: 64-00NAL INDACY LOPECT qOOP\n",
      "Word Decoded sentence: 64-00 INDUSTRIAL LOOP \n",
      "-Lenght =  50\n",
      "Input sentence: GREENDALE, WI\n",
      "GT sentence: GREENDALE, WI\n",
      "Char Decoded sentence: GKERGEND ,AME \n",
      "Word Decoded sentence: GREENDALE WI \n",
      "-Lenght =  100\n",
      "Input sentence: III Please check box it above address is incorrect or insurance _Informatlon has changed. and Indlcate change(s) on reverse side.\n",
      "GT sentence: Please check box it above address is incorrect or insurance information has changed, and indicate change(s) on reverse side.\n",
      "Char Decoded sentence: Is Please check box insurance Insurance Information to Insurance Information hanged and Indinalone a\n",
      "Word Decoded sentence: III Please check box it above address is incorrect or insurance Information has changed and Indicate changes on reverse side \n",
      "-Lenght =  50\n",
      "Input sentence: STATEMENT\n",
      "GT sentence: STATEMENT\n",
      "Char Decoded sentence: STATEMENT\n",
      "Word Decoded sentence: STATEMENT \n",
      "-Lenght =  100\n",
      "Input sentence: PLEASE DETACH AND RETURN TOP PORTION WITH YOUR PAYMENT\n",
      "GT sentence: PLEASE DETACH AND RETURN TOP PORTION WITH YOUR PAYMENT\n",
      "Char Decoded sentence: PLEASE DETACH AND RETURN TOP PORTION WITH YOUR PAYMENT\n",
      "Word Decoded sentence: PLEASE DETACH AND RETURN TOP PORTION WITH YOUR PAYMENT \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Lenght =  100\n",
      "Input sentence: To pay your bill on line with a credit card, log on to www.ebixinc.comlpayonline.html.\n",
      "GT sentence: To pay your bill on line with a credit card, log on to www.ebixinc.com/payonline.html.\n",
      "Char Decoded sentence: To pay your bill on line with a credial car, log on to wwwent complayonlinehtmal\n",
      "Word Decoded sentence: To pay your bill on line with a credit card log on to www.ebixinc.comlpayonline.html. \n",
      "-Lenght =  50\n",
      "Input sentence: ACCOUNT# EMA297232\n",
      "GT sentence: ACCOUNT# EMA297232\n",
      "Char Decoded sentence: ACCOKNT# EMA297232\n",
      "Word Decoded sentence: ACCOUNT EMA297232 \n",
      "-Lenght =  100\n",
      "Input sentence: PLACE OF SERVICE 11 Office 21 Inpatient 22 Outpatient Hospital 23 Emergency Room-Hospital\n",
      "GT sentence: PLACE OF SERVICE 11 Office 21 Inpatient 22 Outpatient Hospital 23 Emergency Room-Hospital\n",
      "Char Decoded sentence: PLACE OF ORVERVIC11 Offic21 Oulpatie22 Hospital  Emergency R11m Hospit21  Emergen22\n",
      "Word Decoded sentence: PLACE OF SERVICE 11 Office 21 Inpatient 22 Outpatient Hospital 23 Emergency Room-Hospital \n",
      "-Lenght =  50\n",
      "Input sentence: PATIENT‘S NAME\n",
      "GT sentence: PATIENT'S NAME\n",
      "Char Decoded sentence: PATIENT'S NAME\n",
      "Word Decoded sentence: PATIENTS NAME \n",
      "-Lenght =  50\n",
      "Input sentence: CPT CODE\n",
      "GT sentence: CPT CODE\n",
      "Char Decoded sentence: CPT CODE\n",
      "Word Decoded sentence: CPT CODE \n",
      "-Lenght =  50\n",
      "Input sentence: SERVICE DESCRIPTION\n",
      "GT sentence: SERVICE DESCRIPTION\n",
      "Char Decoded sentence: SERVICE DESCRIPTION\n",
      "Word Decoded sentence: SERVICE DESCRIPTION \n",
      "-Lenght =  50\n",
      "Input sentence: AMOUNT\n",
      "GT sentence: AMOUNT\n",
      "Char Decoded sentence: AMOKNT\n",
      "Word Decoded sentence: AMOUNT \n",
      "-Lenght =  50\n",
      "Input sentence: UMR FISERV WI\n",
      "GT sentence: UMR FISERV WI BILLED ON 12/12/17\n",
      "Char Decoded sentence: EMRRESTION RECORD\n",
      "Word Decoded sentence: UMW MISERY WI \n",
      "-Lenght =  100\n",
      "Input sentence: YOUR INSURANCE HAS PAID THEIR PORTION OF THE ABOVE SERVICES. THE BALANCE DUE IS YOUR RESPONSIBILITY.\n",
      "GT sentence: YOUR INSURANCE HAS PAID THEIR PORTION OF THE ABOVE SERVICES. THE BALANCE DUE IS YOUR RESPONSIBILITY.\n",
      "Char Decoded sentence: OUR INSURANCE HAS PHE AHE AHE AHE AHE AHE AHE AHE AHE AHE AHE RESPONS ES OUR RESPONSICE DUE SOUNSICI\n",
      "Word Decoded sentence: YOUR INSURANCE HAS PAID THEIR PORTION OF THE ABOVE SERVICES THE BALANCE DUE IS YOUR RESPONSIBILITY \n",
      "-Lenght =  50\n",
      "Input sentence: CURRENT\n",
      "GT sentence: CURRENT\n",
      "Char Decoded sentence: COMRUNE\n",
      "Word Decoded sentence: CURRENT \n",
      "-Lenght =  50\n",
      "Input sentence: IOVER 3D DAYSI\n",
      "GT sentence: OVER 30 DAYS\n",
      "Char Decoded sentence: OVER 3AR EALT\n",
      "Word Decoded sentence: IOVER 3D DAYS \n",
      "-Lenght =  50\n",
      "Input sentence: OVER 60 DAYS\n",
      "GT sentence: OVER 60 DAYS\n",
      "Char Decoded sentence: OVER 60 DAYS\n",
      "Word Decoded sentence: OVER 60 DAYS \n",
      "-Lenght =  50\n",
      "Input sentence: OVER 30 DAYS\n",
      "GT sentence: OVER 90 DAYS\n",
      "Char Decoded sentence: OVER 30 DAYS\n",
      "Word Decoded sentence: OVER 30 DAYS \n",
      "-Lenght =  50\n",
      "Input sentence: IOVER 120 DAYS\n",
      "GT sentence: OVER 120 DAYS\n",
      "Char Decoded sentence: OVER 120DAYS\n",
      "Word Decoded sentence: IOVER 120 DAYS \n",
      "-Lenght =  50\n",
      "Input sentence: ILAST PAY DATEI\n",
      "GT sentence: LAST PAY DATE\n",
      "Char Decoded sentence: LAST PAY DATE DASTATE\n",
      "Word Decoded sentence: LAST PAY DATE \n",
      "-Lenght =  50\n",
      "Input sentence: STMT DATE\n",
      "GT sentence: STMT DATE\n",
      "Char Decoded sentence: STMT DATE\n",
      "Word Decoded sentence: STM DATE \n",
      "-Lenght =  50\n",
      "Input sentence: BALANCE DUE\n",
      "GT sentence: BALANCE DUE\n",
      "Char Decoded sentence: BALANCE DKE\n",
      "Word Decoded sentence: BALANCE DUE \n",
      "-Lenght =  50\n",
      "Input sentence: DOCTOR LEGEND\n",
      "GT sentence: DOCTOR LEGEND\n",
      "Char Decoded sentence: DOCTOR LEGEND\n",
      "Word Decoded sentence: DOCTOR LEGEND \n",
      "-Lenght =  50\n",
      "Input sentence: 1 NOLEN, CHRISTINE, M. D.\n",
      "GT sentence: 1 NOLEN, CHRISTINE, M. D.\n",
      "Char Decoded sentence: 1 NOLEN, CARIENCE,J .NC.E SIGNET\n",
      "Word Decoded sentence: 1 DOLENS CHRISTINE My Do \n",
      "-Lenght =  50\n",
      "Input sentence: COMMENTS\n",
      "GT sentence: COMMENTS\n",
      "Char Decoded sentence: COMMENTS\n",
      "Word Decoded sentence: COMMENTS \n",
      "-Lenght =  50\n",
      "Input sentence: PRIMARY INSUR: UMR FISERV WI\n",
      "GT sentence: PRIMARY INSUR: UMR FISERV WI\n",
      "Char Decoded sentence: IMPRESC INSKR: MI FISERV qI\n",
      "Word Decoded sentence: PRIMARY INSURE UMW MISERY WI \n",
      "-Lenght =  50\n",
      "Input sentence: SECONDARY INSUR:\n",
      "GT sentence: SECONDARY INSUR:\n",
      "Char Decoded sentence: SECONDARY INSKR: KN\n",
      "Word Decoded sentence: SECONDARY INSURE \n",
      "-Lenght =  50\n",
      "Input sentence: EMERGENCY MEDICAL ASSOCIATES\n",
      "GT sentence: EMERGENCY MEDICAL ASSOCIATES\n",
      "Char Decoded sentence: EMERGENCY MEDICAL ASSOCIATES\n",
      "Word Decoded sentence: EMERGENCY MEDICAL ASSOCIATES \n",
      "-Lenght =  50\n",
      "Input sentence: PHONE:\n",
      "GT sentence: PHONE:\n",
      "Char Decoded sentence: PONDE:TR\n",
      "Word Decoded sentence: PHONE \n",
      "-Lenght =  100\n",
      "Input sentence: Due to the HIPAA Regulations we cannot discuss this account with anyone except the patient without the patient's direct consent E\n",
      "GT sentence: Due to the HIPAA Regulations we cannot discuss this account with anyone except the patient without the patient's direct consent.\n",
      "Char Decoded sentence: Due to the Regulations wat ance is ancount dith any wat ance pange exce the patient whe patient with\n",
      "Word Decoded sentence: Due to the HIPAA Regulations we cannot discuss this account with anyone except the patient without the patients direct consent E \n",
      "-Lenght =  50\n",
      "Input sentence: Web user notes:\n",
      "GT sentence: Web user notes:\n",
      "Char Decoded sentence: Weep Coverages:\n",
      "Word Decoded sentence: Web user notes \n",
      "-Lenght =  50\n",
      "Input sentence: medical statements\n",
      "GT sentence: medical statements\n",
      "Char Decoded sentence: medical Patient Patelota\n",
      "Word Decoded sentence: medical statements \n",
      "-Lenght =  50\n",
      "Input sentence: unum‘D\n",
      "GT sentence: unum\n",
      "Char Decoded sentence: unum\n",
      "Word Decoded sentence: unum \n",
      "-Lenght =  50\n",
      "Input sentence: . . O The Benefits Center\n",
      "GT sentence: The Benefits Center\n",
      "Char Decoded sentence: .h. Be feheffics Center\n",
      "Word Decoded sentence: . . O The Benefits Center \n",
      "-Lenght =  100\n",
      "Input sentence: Call toll-free Monday through Friday, 8 am. to 8 pm. Eastern Time.\n",
      "GT sentence: Call toll-free Monday through Friday, 8 a.m. to 8 p.m. Eastern Time.\n",
      "Char Decoded sentence: Call toll-free Monday through Friday, 8 a. to8 pm Eas-ern Time\n",
      "Word Decoded sentence: Call toll-free Monday through Friday 8 am to 8 pm Eastern Time \n",
      "-Lenght =  100\n",
      "Input sentence: Please sign and return this authorization to The Benefits Center at the address above. You are entitled to receive a copy of this authorization. This authorization is designed to comply with the Health Insurance Portability and Accountability Act (HIPAA) Privacy Rule.\n",
      "GT sentence: Please sign and return this authorization to The Benefits Center at the address above. You are entitled to receive a copy of this authorization. This authorization is designed to comply with the Health Insurance Portability and Accountability Act (HIPAA) Privacy Rule.\n",
      "Char Decoded sentence: Please sign and return the Bentrization to The Benter at the Benter above Yos No Indress abde enttin\n",
      "Word Decoded sentence: Please sign and return this authorization to The Benefits Center at the address above You are entitled to receive a copy of this authorization This authorization is designed to comply with the Health Insurance Portability and Accountability Act (HIPAA) Privacy Rule \n",
      "-Lenght =  100\n",
      "Input sentence: Authorization to Collect and Disclose Information\n",
      "GT sentence: Authorization to Collect and Disclose Information\n",
      "Char Decoded sentence: Authorization to Collect and Disclose Information\n",
      "Word Decoded sentence: Authorization to Collect and Disclose Information \n",
      "-Lenght =  50\n",
      "Input sentence: (Not for FMLA Requests)\n",
      "GT sentence: (Not for FMLA Requests)\n",
      "Char Decoded sentence: (ot for FMLA Reuests)\n",
      "Word Decoded sentence: Not for FMLA Requests \n",
      "-Lenght =  100\n",
      "Input sentence: I authorize the followin persons: health care professionals, hospitals, clinics, laboratories, pharmacies and all other medical or me ically related providers, facilities or services, rehabilitation professionals, vocational evaluators, health plans, insurance companies, third party administrators, insurance producers, insurance service providers, consumer reporting agencies including credit bureaus, GENEX Services, Inc., The Advocator Group and other Social Security advocacy vendors, professional licensing bodies, employers, attorneys, financial institutions and/or banks, and governmental entities;\n",
      "GT sentence: I authorize the following persons: health care professionals, hospitals, clinics, laboratories, pharmacies and all other medical or medically related providers, facilities or services, rehabilitation professionals, vocational evaluators, health plans, insurance companies, third party administrators, insurance producers, insurance service providers, consumer reporting agencies including credit bureaus, GENEX Services, Inc., The Advocator Group and other Social Security advocacy vendors, professional licensing bodies, employers, attorneys, financial institutions and/or banks, and governmental entities;\n",
      "Char Decoded sentence: I authorize the following preson: hospital an pressional slinics clinics lab:oratorizes pharkes phar\n",
      "Word Decoded sentence: I authorize the following persons health care professionals hospitals clinics laboratories pharmacies and all other medical or me ically related providers facilities or services rehabilitation professionals vocational evaluators health plans insurance companies third party administrators insurance producers insurance service providers consumer reporting agencies including credit bureaus GENEX Services Inch The Advocator Group and other Social Security advocacy vendors professional licensing bodies employers attorneys financial institutions andfor banks and governmental entities \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-ec4367d43179>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#print(max_decoder_seq_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mdecoded_sentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen_range\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen_range\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_decoder_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen_range\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmax_decoder_seq_length\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen_range\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen_range\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_to_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen_range\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mcorrected_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_spell_correct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-Lenght = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input sentence:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-eb502bd5479d>\u001b[0m in \u001b[0;36mword_spell_correct\u001b[0;34m(decoded_sentence)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecoded_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\d+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspecial_chars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mcorrected_decoded_sentence\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mspell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mcorrected_decoded_sentence\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/cod/spell_corrector/autocorrect/__init__.py\u001b[0m in \u001b[0;36mspell\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     candidates = (common([word]) or exact([word]) or known([word]) or\n\u001b[0;32m---> 23\u001b[0;31m                   \u001b[0mknown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble_typos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                   [word])\n\u001b[1;32m     25\u001b[0m     \u001b[0mcorrection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNLP_COUNTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/cod/spell_corrector/autocorrect/word.py\u001b[0m in \u001b[0;36mdouble_typos\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdouble_typos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;34m\"\"\"letter combinations two typos away from word\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         return {e2 for e1 in self.typos()\n\u001b[0m\u001b[1;32m     72\u001b[0m                 for e2 in Word(e1).typos()}\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/cod/spell_corrector/autocorrect/word.py\u001b[0m in \u001b[0;36m<setcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;34m\"\"\"letter combinations two typos away from word\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         return {e2 for e1 in self.typos()\n\u001b[0;32m---> 72\u001b[0;31m                 for e2 in Word(e1).typos()}\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/cod/spell_corrector/autocorrect/word.py\u001b[0m in \u001b[0;36mtypos\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;34m\"\"\"letter combinations one typo away from word\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         return (self._deletes() | self._transposes() |\n\u001b[0;32m---> 67\u001b[0;31m                 self._replaces() | self._inserts())\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdouble_typos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/cod/spell_corrector/autocorrect/word.py\u001b[0m in \u001b[0;36m_inserts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;34m\"\"\"thwe\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         return {concat(a, c, b)\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                 for c in ALPHABET}\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/cod/spell_corrector/autocorrect/word.py\u001b[0m in \u001b[0;36m<setcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     60\u001b[0m         return {concat(a, c, b)\n\u001b[1;32m     61\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 for c in ALPHABET}\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtypos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "decoded_sentences = []\n",
    "corrected_sentences = []\n",
    "\n",
    "#for seq_index in range(len(input_texts)):\n",
    "results = open('RESULTS.md', 'w')\n",
    "results.write('|OCR sentence|GT sentence|Char decoded sentence|Word decoded sentence|Sentence length (chars)|\\n')\n",
    "results.write('---------------|-----------|----------------|----------------|----------------|\\n')\n",
    "     \n",
    "\n",
    "for i, input_text in enumerate(input_texts):\n",
    "    #print(input_text)\n",
    "    # Find the input length range to choose the proper model to use\n",
    "    len_range = max_sent_lengths[-1] # Take the longest range\n",
    "    for length in max_sent_lengths:\n",
    "        if(len(input_text) < length):\n",
    "            len_range = length\n",
    "            break\n",
    "    #print(len_range)\n",
    "    \n",
    "    input_text = clean_up_sentence(input_text, vocab_to_int[len_range])\n",
    "    encoder_input_data = vectorize_data(input_texts=[input_text], max_encoder_seq_length=max_encoder_seq_length[len_range], num_encoder_tokens=num_encoder_tokens[len_range], vocab_to_int=vocab_to_int[len_range])\n",
    "    \n",
    "    \n",
    "\n",
    "    target_text = gt_texts[i]\n",
    "    \n",
    "    input_seq = encoder_input_data\n",
    "    #print(input_seq.shape)\n",
    "    #print(max_decoder_seq_length[len_range])\n",
    "    #print(max_decoder_seq_length)\n",
    "    decoded_sentence,_  = decode_sequence(input_seq, encoder_model[len_range], decoder_model[len_range], num_decoder_tokens[len_range],  max_decoder_seq_length[len_range], vocab_to_int[len_range], int_to_vocab[len_range])\n",
    "    corrected_sentence = word_spell_correct(input_text)\n",
    "    print('-Lenght = ', len_range)\n",
    "    print('Input sentence:', input_text)\n",
    "    print('GT sentence:', target_text.strip())\n",
    "    print('Char Decoded sentence:', decoded_sentence)   \n",
    "    print('Word Decoded sentence:', corrected_sentence) \n",
    "    results.write(' | ' + input_text + ' | ' + target_text.strip() + ' | ' + decoded_sentence + ' | ' + corrected_sentence + ' | ' + str(len_range) + ' | \\n')\n",
    "    decoded_sentences.append(decoded_sentence)\n",
    "    corrected_sentences.append(corrected_sentence)\n",
    "results.close()    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = ['Unum Life Insurance Company of America 2211',               \n",
    "               'Congress Street Portland, Maine 04122',\n",
    "               'APPLICATION FOR GROUP CRITICAL LLNESS INSURANCE',\n",
    "               'I Evidence of Insurability',\n",
    "               '',\n",
    "               'Application Type: @ New Enrollee Change to',\n",
    "               'Existing Coverage  Reinstatement  Internal',\n",
    "               'Replacement  Late Applicant  Rehire SECTION 1:',\n",
    "               'Employee(Applicant) Information  Always',\n",
    "               'Complete Employee Name(First, Middle, Last)',\n",
    "               'Social Security Number Nikolas J Jones',\n",
    "               '123 - 456 - 7890 Home Address(Street/ PO Box)',\n",
    "               'Gender 1634 Stewert St  F  M City Date of Birth',\n",
    "               '(mm / dd / yyyy) Seattle 06 / 15 / 1991 State Zip',\n",
    "               'Code Home Phone # Washington 98101 854-555-1212',\n",
    "               'Are you Actively at Work? Employee ID / Payroll #',\n",
    "               ' Yes  No55624 a.Are you a U.S.Citizen or',\n",
    "               'Canadian Citizen working in the U.S.? b.Are you',\n",
    "               'legally authorized to work in  Yes  No(If No',\n",
    "               'reply to part b) the U.S.?  Yes  No Employer',\n",
    "               'Name Group Number Date of Hire(mm/ dd / yyyy)',\n",
    "               'Facebook 11 - 555566 11 / 30 / 2016 Occupation',\n",
    "               'Eligibility Class Software Engineer 7 Scheduled',\n",
    "               'Number of Work Hours per Week Work Phone # 35',\n",
    "               '854-555-6622 SECTION 2: Spouse Information ',\n",
    "               'Complete Only if applying for Spouse coverage Name',\n",
    "               '(First, Middle, Last) Social Security Number',\n",
    "               'Gender Date of Birth(mm / dd / yyyy) Does the',\n",
    "               '1019 - 07 - AZ 1',\n",
    "              'if claint is for a child, please state your relationship 10 the child',\n",
    "              'date of accident 3d _ time of accident ram. 0 p.m.',\n",
    "              'have you slopped working? (of yes [1 no if yes, what was the last day that you worked? (mm/ddryy)_| —3 | —{% cnslamegs bil =']\n",
    "               \n",
    "for input_text in input_texts:\n",
    "    len_range = max_sent_lengths[-1] # Take the longest range\n",
    "    for length in max_sent_lengths:\n",
    "        if(len(input_text) < length):\n",
    "            len_range = length\n",
    "            break\n",
    "    #print(len_range)\n",
    "    pre_corrected_sentence = word_spell_correct(input_text)\n",
    "    input_text = clean_up_sentence(input_text, vocab_to_int[len_range])\n",
    "    encoder_input_data = vectorize_data(input_texts=[input_text], max_encoder_seq_length=max_encoder_seq_length[len_range], num_encoder_tokens=num_encoder_tokens[len_range], vocab_to_int=vocab_to_int[len_range])\n",
    "\n",
    "\n",
    "\n",
    "    target_text = gt_texts[i]\n",
    "\n",
    "    input_seq = encoder_input_data\n",
    "    #print(input_seq.shape)\n",
    "    #print(max_decoder_seq_length[len_range])\n",
    "    #print(max_decoder_seq_length)\n",
    "\n",
    "    decoded_sentence,_  = decode_sequence(input_seq, encoder_model[len_range], decoder_model[len_range], num_decoder_tokens[len_range],  max_decoder_seq_length[len_range], vocab_to_int[len_range], int_to_vocab[len_range])\n",
    "    corrected_sentence = word_spell_correct(input_text)\n",
    "    #print('-Lenght = ', len_range)\n",
    "    print('Input sentence:', input_text)\n",
    "    #print('Spell Decoded sentence:', pre_corrected_sentence) \n",
    "    print('Char Decoded sentence:', decoded_sentence)   \n",
    "    print('Word Decoded sentence:', corrected_sentence) \n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WER_spell_correction = calculate_WER(gt_texts, decoded_sentences)\n",
    "print('WER_spell_correction |TEST= ', WER_spell_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WER_spell_word_correction = calculate_WER(gt_texts, corrected_sentences)\n",
    "print('WER_spell_word_correction |TEST= ', WER_spell_word_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WER_OCR = calculate_WER(gt_texts, input_texts)\n",
    "print('WER_OCR |TEST= ', WER_OCR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
