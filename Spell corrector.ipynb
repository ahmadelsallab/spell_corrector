{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We tackle the problem of OCR post processing. In OCR, we map the image form of the document into the text domain. This is done first using an CNN+LSTM+CTC model, in our case based on tesseract. Since this output maps only image to text, we need something on top to validate and correct language semantics.\n",
    "\n",
    "The idea is to build a language model, that takes the OCRed text and corrects it based on language knowledge. The langauge model could be:\n",
    "- Char level: the aim is to capture the word morphology. In which case it's like a spelling correction system.\n",
    "- Word level: the aim is to capture the sentence semnatics. But such systems suffer from the OOV problem.\n",
    "- Fusion: to capture semantics and morphology language rules. The output has to be at char level, to avoid the OOV. However, the input can be char, word or both.\n",
    "\n",
    "The fusion model target is to learn:\n",
    "\n",
    "    p(char | char_context, word_context)\n",
    "\n",
    "In this workbook we use seq2seq vanilla Keras implementation, adapted from the lstm_seq2seq example on Eng-Fra translation task. The adaptation involves:\n",
    "\n",
    "- Adapt to spelling correction, on char level\n",
    "- Pre-train on a noisy, medical sentences\n",
    "- Fine tune a residual, to correct the mistakes of tesseract \n",
    "- Limit the input and output sequence lengths\n",
    "- Enusre teacher forcing auto regressive model in the decoder\n",
    "- Limit the padding per batch (TODO)\n",
    "- Learning rate schedule (TODO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, LearningRateScheduler\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit gpu allocation. allow_growth, or gpu_fraction\n",
    "def gpu_alloc():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_alloc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_WER_sent(gt, pred):\n",
    "    '''\n",
    "    calculate_WER('calculating wer between two sentences', 'calculate wer between two sentences')\n",
    "    '''\n",
    "    gt_words = gt.lower().split(' ')\n",
    "    pred_words = pred.lower().split(' ')\n",
    "    d = np.zeros(((len(gt_words) + 1), (len(pred_words) + 1)), dtype=np.uint8)\n",
    "    # d = d.reshape((len(gt_words)+1, len(pred_words)+1))\n",
    "\n",
    "    # Initializing error matrix\n",
    "    for i in range(len(gt_words) + 1):\n",
    "        for j in range(len(pred_words) + 1):\n",
    "            if i == 0:\n",
    "                d[0][j] = j\n",
    "            elif j == 0:\n",
    "                d[i][0] = i\n",
    "\n",
    "    # computation\n",
    "    for i in range(1, len(gt_words) + 1):\n",
    "        for j in range(1, len(pred_words) + 1):\n",
    "            if gt_words[i - 1] == pred_words[j - 1]:\n",
    "                d[i][j] = d[i - 1][j - 1]\n",
    "            else:\n",
    "                substitution = d[i - 1][j - 1] + 1\n",
    "                insertion = d[i][j - 1] + 1\n",
    "                deletion = d[i - 1][j] + 1\n",
    "                d[i][j] = min(substitution, insertion, deletion)\n",
    "    return d[len(gt_words)][len(pred_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_WER(gt, pred):\n",
    "    '''\n",
    "\n",
    "    :param gt: list of sentences of the ground truth\n",
    "    :param pred: list of sentences of the predictions\n",
    "    both lists must have the same length\n",
    "    :return: accumulated WER\n",
    "    '''\n",
    "#    assert len(gt) == len(pred)\n",
    "    WER = 0\n",
    "    nb_w = 0\n",
    "    for i in range(len(gt)):\n",
    "        #print(gt[i])\n",
    "        #print(pred[i])\n",
    "        WER += calculate_WER_sent(gt[i], pred[i])\n",
    "        nb_w += len(gt[i])\n",
    "\n",
    "    return WER / nb_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artificial noisy spelling mistakes\n",
    "def noise_maker(sentence, threshold):\n",
    "    '''Relocate, remove, or add characters to create spelling mistakes'''\n",
    "    letters = ['a','b','c','d','e','f','g','h','i','j','k','l','m',\n",
    "           'n','o','p','q','r','s','t','u','v','w','x','y','z',]\n",
    "    noisy_sentence = []\n",
    "    i = 0\n",
    "    while i < len(sentence):\n",
    "        random = np.random.uniform(0, 1, 1)\n",
    "        # Most characters will be correct since the threshold value is high\n",
    "        if random < threshold:\n",
    "            noisy_sentence.append(sentence[i])\n",
    "        else:\n",
    "            new_random = np.random.uniform(0, 1, 1)\n",
    "            # ~33% chance characters will swap locations\n",
    "            if new_random > 0.67:\n",
    "                if i == (len(sentence) - 1):\n",
    "                    # If last character in sentence, it will not be typed\n",
    "                    continue\n",
    "                else:\n",
    "                    # if any other character, swap order with following character\n",
    "                    noisy_sentence.append(sentence[i + 1])\n",
    "                    noisy_sentence.append(sentence[i])\n",
    "                    i += 1\n",
    "            # ~33% chance an extra lower case letter will be added to the sentence\n",
    "            elif new_random < 0.33:\n",
    "                random_letter = np.random.choice(letters, 1)[0]\n",
    "                noisy_sentence.append(random_letter)\n",
    "                noisy_sentence.append(sentence[i])\n",
    "            # ~33% chance a character will not be typed\n",
    "            else:\n",
    "                pass\n",
    "        i += 1\n",
    "\n",
    "    return ''.join(noisy_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_with_gt(file_name, num_samples, max_sent_len, min_sent_len):\n",
    "    '''Load data from txt file, with each line has: <TXT><TAB><GT>. The  target to the decoder muxt have \\t as the start trigger and \\n as the stop trigger.'''\n",
    "    cnt = 0  \n",
    "    input_texts = []\n",
    "    gt_texts = []\n",
    "    target_texts = []\n",
    "    for row in open(file_name):\n",
    "        if cnt < num_samples :\n",
    "            sents = row.split(\"\\t\")\n",
    "            input_text = sents[0]\n",
    "            \n",
    "            target_text = '\\t' + sents[1] + '\\n'\n",
    "            if len(input_text) > min_sent_len and len(input_text) < max_sent_len and len(target_text) > min_sent_len and len(target_text) < max_sent_len:\n",
    "                cnt += 1\n",
    "                \n",
    "                input_texts.append(input_text)\n",
    "                target_texts.append(target_text)\n",
    "                gt_texts.append(sents[1])\n",
    "    return input_texts, target_texts, gt_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_with_noise(file_name, num_samples, noise_threshold, max_sent_len, min_sent_len):\n",
    "    '''Load data from txt file, with each line has: <TXT>. The GT is just a noisy version of TXT. The  target to the decoder muxt have \\t as the start trigger and \\n as the stop trigger.'''\n",
    "    cnt = 0  \n",
    "    input_texts = []\n",
    "    gt_texts = []\n",
    "    target_texts = []\n",
    "    while cnt < num_samples :\n",
    "        for row in open(file_name):\n",
    "            input_text = noise_maker(row, noise_threshold)\n",
    "            input_text = input_text[:-1]\n",
    "            \n",
    "            target_text = '\\t' + row + '\\n'            \n",
    "            if len(input_text) > min_sent_len and len(input_text) < max_sent_len and len(target_text) > min_sent_len and len(target_text) < max_sent_len:\n",
    "                cnt += 1\n",
    "                input_texts.append(input_text)\n",
    "                target_texts.append(target_text)\n",
    "                gt_texts.append(row)\n",
    "    return input_texts, target_texts, gt_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(all_texts):\n",
    "    '''Build vocab dictionary to victorize chars into ints'''\n",
    "    vocab_to_int = {}\n",
    "    count = 0\n",
    "    \n",
    "    for sentence in all_texts:\n",
    "        for char in sentence:\n",
    "            if char not in vocab_to_int:\n",
    "                vocab_to_int[char] = count\n",
    "                count += 1\n",
    "    # Add special tokens to vocab_to_int\n",
    "    codes = ['\\t','\\n']\n",
    "    for code in codes:\n",
    "        if code not in vocab_to_int:\n",
    "            vocab_to_int[code] = count\n",
    "            count += 1\n",
    "    '''''Build inverse translation from int to char'''\n",
    "    int_to_vocab = {}\n",
    "    for character, value in vocab_to_int.items():\n",
    "        int_to_vocab[value] = character\n",
    "        \n",
    "    return vocab_to_int, int_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_data(input_texts, target_texts, max_encoder_seq_length, num_encoder_tokens, vocab_to_int):\n",
    "    '''Prepares the input text and targets into the proper seq2seq numpy arrays'''\n",
    "    encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "    decoder_input_data = np.zeros(\n",
    "        (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "        dtype='float32')\n",
    "    decoder_target_data = np.zeros(\n",
    "        (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "        dtype='float32')\n",
    "\n",
    "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "        for t, char in enumerate(input_text):\n",
    "            # c0..cn\n",
    "            encoder_input_data[i, t, vocab_to_int[char]] = 1.\n",
    "        for t, char in enumerate(target_text):\n",
    "            # c0'..cm'\n",
    "            # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "            decoder_input_data[i, t, vocab_to_int[char]] = 1.\n",
    "            if t > 0:\n",
    "                # decoder_target_data will be ahead by one timestep\n",
    "                # and will not include the start character.\n",
    "                decoder_target_data[i, t - 1, vocab_to_int[char]] = 1.\n",
    "                \n",
    "    return encoder_input_data, decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, encoder_model, decoder_model, num_decoder_tokens, int_to_vocab):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, vocab_to_int['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = int_to_vocab[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../dat/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sent_len = 40\n",
    "min_sent_len = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results on tesseract correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "tess_correction_data = os.path.join(data_path, 'new_trained_data.txt')\n",
    "input_texts_OCR, target_texts_OCR, gt_OCR = load_data_with_gt(tess_correction_data, num_samples, max_sent_len, min_sent_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = input_texts_OCR\n",
    "target_texts = target_texts_OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results of pre-training on generic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnum_samples = 0\\nbig_data = os.path.join(data_path, 'big.txt')\\nthreshold = 0.9\\ninput_texts_gen, target_texts_gen, gt_gen = load_data_with_noise(file_name=big_data, \\n                                                                 num_samples=num_samples, \\n                                                                 noise_threshold=threshold, \\n                                                                 max_sent_len=max_sent_len, \\n                                                                 min_sent_len=min_sent_len)\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "num_samples = 0\n",
    "big_data = os.path.join(data_path, 'big.txt')\n",
    "threshold = 0.9\n",
    "input_texts_gen, target_texts_gen, gt_gen = load_data_with_noise(file_name=big_data, \n",
    "                                                                 num_samples=num_samples, \n",
    "                                                                 noise_threshold=threshold, \n",
    "                                                                 max_sent_len=max_sent_len, \n",
    "                                                                 min_sent_len=min_sent_len)\n",
    "'''                                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_texts = input_texs_gen\n",
    "#target_texts = target_texts_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results on noisy tesseract corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100000\n",
    "tess_correction_data = os.path.join(data_path, 'new_trained_data.txt')\n",
    "threshold = 0.9\n",
    "input_texts_noisy_OCR, target_texts_noisy_OCR, gt_noisy_OCR = load_data_with_noise(file_name=tess_correction_data, \n",
    "                                                                 num_samples=num_samples, \n",
    "                                                                 noise_threshold=threshold, \n",
    "                                                                 max_sent_len=max_sent_len, \n",
    "                                                                 min_sent_len=min_sent_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninput_texts = input_texts_noisy_OCR\\ntarget_texts = target_texts_noisy_OCR\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "input_texts = input_texts_noisy_OCR\n",
    "target_texts = target_texts_noisy_OCR\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results on merge of tesseract correction + generic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninput_texts = input_texts_OCR + input_texts_gen\\ntarget_texts = input_texts_OCR + target_texts_gen\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "input_texts = input_texts_OCR + input_texts_gen\n",
    "target_texts = input_texts_OCR + target_texts_gen\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results noisy tesseract correction + generic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninput_texts = input_texts_noisy_OCR + input_texts_gen\\ntarget_texts = input_texts_noisy_OCR + target_texts_gen\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "input_texts = input_texts_noisy_OCR + input_texts_gen\n",
    "target_texts = input_texts_noisy_OCR + target_texts_gen\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results noisy tesseract noisy + correction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = input_texts_noisy_OCR + input_texts_OCR\n",
    "target_texts = input_texts_noisy_OCR + target_texts_OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results of pre-training on generic and fine tuning on tesseract correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101525\n",
      "City. W’aukeshaa\tCiyt: wWaukesha \n",
      " City. W’aukeshaa\tCiyt: wWaukesha\n",
      "Country\". U S\tCountry:  US \n",
      " Country\". U S\tCountry:  US\n",
      "City. ‘Waukesha \ttCity:Waukesha \n",
      " City. ‘Waukesha \ttCity:Waukesha\n",
      "Country. US \tCountry: U \n",
      " Country. US \tCountry: U\n",
      "First Name \txFirst Name: \n",
      " First Name \txFirst Name:\n",
      "Last Name: Last Name: \n",
      " Last Name: Last Name:\n",
      "Birthj Date: B\tirth atee:l \n",
      " Birthj Date: B\tirth atee:l\n",
      "Genmder: \tGneder: \n",
      " Genmder: \tGneder:\n",
      "Address Line 1: \tAdrevssL ine 1: \n",
      " Address Line 1: \tAdrevssL ine 1:\n",
      "CWy- \tCity: \n",
      " CWy- \tCity:\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "print(len(input_texts))\n",
    "for i in range(10):\n",
    "    print(input_texts[i], '\\n', target_texts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = target_texts + input_texts\n",
    "vocab_to_int, int_to_vocab = build_vocab(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = sorted(list(vocab_to_int))\n",
    "target_characters = sorted(list(vocab_to_int))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 101525\n",
      "Number of unique input tokens: 105\n",
      "Number of unique output tokens: 105\n",
      "Max sequence length for inputs: 39\n",
      "Max sequence length for outputs: 39\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sentences\n",
    "input_texts, test_input_texts, target_texts, test_target_texts  = train_test_split(input_texts, target_texts, test_size = 0.15, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data, decoder_input_data, decoder_target_data = vectorize_data(input_texts=input_texts,\n",
    "                                                                             target_texts=target_texts, \n",
    "                                                                             max_encoder_seq_length=max_encoder_seq_length, \n",
    "                                                                             num_encoder_tokens=num_encoder_tokens, \n",
    "                                                                             vocab_to_int=vocab_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoder_input_data, test_decoder_input_data, test_decoder_target_data = vectorize_data(input_texts=test_input_texts,\n",
    "                                                                                            target_texts=test_target_texts, \n",
    "                                                                                            max_encoder_seq_length=max_encoder_seq_length, \n",
    "                                                                                            num_encoder_tokens=num_encoder_tokens, \n",
    "                                                                                            vocab_to_int=vocab_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 200  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 105)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 105)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 256), (None, 370688      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 256),  370688      input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 105)    26985       lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 768,361\n",
      "Trainable params: 768,361\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "# TODO: Add Embedding for chars\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam(lr=lr), loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath=\"weights-improvement-{epoch:02d}-{val_categorical_accuracy:.2f}.hdf5\"\n",
    "filepath=\"best_model.hdf5\" # Save only the best model for inference step, as saving the epoch and metric might confuse the inference function which model to use\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "tbCallBack = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "callbacks_list = [checkpoint, tbCallBack]\n",
    "#callbacks_list = [checkpoint, tbCallBack, lrate]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_decay(epoch):\n",
    "    initial_lrate = 0.1\n",
    "    k = 0.1\n",
    "    lrate = initial_lrate * np.exp(-k*epoch)\n",
    "    return lrate\n",
    "lrate = LearningRateScheduler(exp_decay)\n",
    "#lr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.1\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "#lr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks_list.append(lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 86296 samples, validate on 15229 samples\n",
      "Epoch 1/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.6793 - categorical_accuracy: 0.4373 - val_loss: 0.4176 - val_categorical_accuracy: 0.5009\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.50089, saving model to best_model.hdf5\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/network.py:888: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.3782 - categorical_accuracy: 0.5120 - val_loss: 0.3494 - val_categorical_accuracy: 0.5163\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.50089 to 0.51632, saving model to best_model.hdf5\n",
      "Epoch 3/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.3185 - categorical_accuracy: 0.5265 - val_loss: 0.3015 - val_categorical_accuracy: 0.5282\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.51632 to 0.52817, saving model to best_model.hdf5\n",
      "Epoch 4/200\n",
      "86296/86296 [==============================] - 157s 2ms/step - loss: 0.2757 - categorical_accuracy: 0.5340 - val_loss: 0.2690 - val_categorical_accuracy: 0.5335\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy improved from 0.52817 to 0.53354, saving model to best_model.hdf5\n",
      "Epoch 5/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.2439 - categorical_accuracy: 0.5407 - val_loss: 0.2403 - val_categorical_accuracy: 0.5389\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.53354 to 0.53887, saving model to best_model.hdf5\n",
      "Epoch 6/200\n",
      "86296/86296 [==============================] - 157s 2ms/step - loss: 0.2155 - categorical_accuracy: 0.5459 - val_loss: 0.2187 - val_categorical_accuracy: 0.5436\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy improved from 0.53887 to 0.54365, saving model to best_model.hdf5\n",
      "Epoch 7/200\n",
      "86296/86296 [==============================] - 157s 2ms/step - loss: 0.1936 - categorical_accuracy: 0.5510 - val_loss: 0.2000 - val_categorical_accuracy: 0.5470\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.54365 to 0.54698, saving model to best_model.hdf5\n",
      "Epoch 8/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.1758 - categorical_accuracy: 0.5548 - val_loss: 0.1854 - val_categorical_accuracy: 0.5486\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy improved from 0.54698 to 0.54864, saving model to best_model.hdf5\n",
      "Epoch 9/200\n",
      "86296/86296 [==============================] - 157s 2ms/step - loss: 0.1596 - categorical_accuracy: 0.5569 - val_loss: 0.1721 - val_categorical_accuracy: 0.5515\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy improved from 0.54864 to 0.55151, saving model to best_model.hdf5\n",
      "Epoch 10/200\n",
      "86296/86296 [==============================] - 157s 2ms/step - loss: 0.1447 - categorical_accuracy: 0.5592 - val_loss: 0.1586 - val_categorical_accuracy: 0.5532\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy improved from 0.55151 to 0.55325, saving model to best_model.hdf5\n",
      "Epoch 11/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.1334 - categorical_accuracy: 0.5603 - val_loss: 0.1519 - val_categorical_accuracy: 0.5546\n",
      "\n",
      "Epoch 00011: val_categorical_accuracy improved from 0.55325 to 0.55460, saving model to best_model.hdf5\n",
      "Epoch 12/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.1241 - categorical_accuracy: 0.5627 - val_loss: 0.1433 - val_categorical_accuracy: 0.5578\n",
      "\n",
      "Epoch 00012: val_categorical_accuracy improved from 0.55460 to 0.55780, saving model to best_model.hdf5\n",
      "Epoch 13/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.1152 - categorical_accuracy: 0.5645 - val_loss: 0.1393 - val_categorical_accuracy: 0.5572\n",
      "\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.55780\n",
      "Epoch 14/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.1091 - categorical_accuracy: 0.5656 - val_loss: 0.1305 - val_categorical_accuracy: 0.5599\n",
      "\n",
      "Epoch 00014: val_categorical_accuracy improved from 0.55780 to 0.55989, saving model to best_model.hdf5\n",
      "Epoch 15/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.1030 - categorical_accuracy: 0.5667 - val_loss: 0.1284 - val_categorical_accuracy: 0.5590\n",
      "\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.55989\n",
      "Epoch 16/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.0982 - categorical_accuracy: 0.5674 - val_loss: 0.1263 - val_categorical_accuracy: 0.5593\n",
      "\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.55989\n",
      "Epoch 17/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.0931 - categorical_accuracy: 0.5683 - val_loss: 0.1245 - val_categorical_accuracy: 0.5597\n",
      "\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.55989\n",
      "Epoch 18/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.0895 - categorical_accuracy: 0.5693 - val_loss: 0.1186 - val_categorical_accuracy: 0.5607\n",
      "\n",
      "Epoch 00018: val_categorical_accuracy improved from 0.55989 to 0.56072, saving model to best_model.hdf5\n",
      "Epoch 19/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.0862 - categorical_accuracy: 0.5699 - val_loss: 0.1155 - val_categorical_accuracy: 0.5614\n",
      "\n",
      "Epoch 00019: val_categorical_accuracy improved from 0.56072 to 0.56144, saving model to best_model.hdf5\n",
      "Epoch 20/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.0827 - categorical_accuracy: 0.5706 - val_loss: 0.1172 - val_categorical_accuracy: 0.5612\n",
      "\n",
      "Epoch 00020: val_categorical_accuracy did not improve from 0.56144\n",
      "Epoch 21/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.0802 - categorical_accuracy: 0.5712 - val_loss: 0.1160 - val_categorical_accuracy: 0.5622\n",
      "\n",
      "Epoch 00021: val_categorical_accuracy improved from 0.56144 to 0.56220, saving model to best_model.hdf5\n",
      "Epoch 22/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.0774 - categorical_accuracy: 0.5718 - val_loss: 0.1123 - val_categorical_accuracy: 0.5624\n",
      "\n",
      "Epoch 00022: val_categorical_accuracy improved from 0.56220 to 0.56235, saving model to best_model.hdf5\n",
      "Epoch 23/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.0760 - categorical_accuracy: 0.5721 - val_loss: 0.1082 - val_categorical_accuracy: 0.5636\n",
      "\n",
      "Epoch 00023: val_categorical_accuracy improved from 0.56235 to 0.56356, saving model to best_model.hdf5\n",
      "Epoch 24/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.0730 - categorical_accuracy: 0.5725 - val_loss: 0.1080 - val_categorical_accuracy: 0.5634\n",
      "\n",
      "Epoch 00024: val_categorical_accuracy did not improve from 0.56356\n",
      "Epoch 25/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.0714 - categorical_accuracy: 0.5729 - val_loss: 0.1101 - val_categorical_accuracy: 0.5627\n",
      "\n",
      "Epoch 00025: val_categorical_accuracy did not improve from 0.56356\n",
      "Epoch 26/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.0695 - categorical_accuracy: 0.5733 - val_loss: 0.1080 - val_categorical_accuracy: 0.5633\n",
      "\n",
      "Epoch 00026: val_categorical_accuracy did not improve from 0.56356\n",
      "Epoch 27/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.0681 - categorical_accuracy: 0.5737 - val_loss: 0.1081 - val_categorical_accuracy: 0.5634\n",
      "\n",
      "Epoch 00027: val_categorical_accuracy did not improve from 0.56356\n",
      "Epoch 28/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.0666 - categorical_accuracy: 0.5742 - val_loss: 0.1085 - val_categorical_accuracy: 0.5634\n",
      "\n",
      "Epoch 00028: val_categorical_accuracy did not improve from 0.56356\n",
      "Epoch 29/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.0653 - categorical_accuracy: 0.5746 - val_loss: 0.1056 - val_categorical_accuracy: 0.5645\n",
      "\n",
      "Epoch 00029: val_categorical_accuracy improved from 0.56356 to 0.56451, saving model to best_model.hdf5\n",
      "Epoch 30/200\n",
      "86296/86296 [==============================] - 157s 2ms/step - loss: 0.0635 - categorical_accuracy: 0.5749 - val_loss: 0.1022 - val_categorical_accuracy: 0.5654\n",
      "\n",
      "Epoch 00030: val_categorical_accuracy improved from 0.56451 to 0.56543, saving model to best_model.hdf5\n",
      "Epoch 31/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.0628 - categorical_accuracy: 0.5753 - val_loss: 0.1004 - val_categorical_accuracy: 0.5657\n",
      "\n",
      "Epoch 00031: val_categorical_accuracy improved from 0.56543 to 0.56571, saving model to best_model.hdf5\n",
      "Epoch 32/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.0609 - categorical_accuracy: 0.5759 - val_loss: 0.1032 - val_categorical_accuracy: 0.5651\n",
      "\n",
      "Epoch 00032: val_categorical_accuracy did not improve from 0.56571\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.0604 - categorical_accuracy: 0.5758 - val_loss: 0.1027 - val_categorical_accuracy: 0.5651\n",
      "\n",
      "Epoch 00033: val_categorical_accuracy did not improve from 0.56571\n",
      "Epoch 34/200\n",
      "86296/86296 [==============================] - 157s 2ms/step - loss: 0.0591 - categorical_accuracy: 0.5762 - val_loss: 0.1044 - val_categorical_accuracy: 0.5645\n",
      "\n",
      "Epoch 00034: val_categorical_accuracy did not improve from 0.56571\n",
      "Epoch 35/200\n",
      "86296/86296 [==============================] - 157s 2ms/step - loss: 0.0585 - categorical_accuracy: 0.5761 - val_loss: 0.1035 - val_categorical_accuracy: 0.5648\n",
      "\n",
      "Epoch 00035: val_categorical_accuracy did not improve from 0.56571\n",
      "Epoch 36/200\n",
      "86296/86296 [==============================] - 157s 2ms/step - loss: 0.0561 - categorical_accuracy: 0.5768 - val_loss: 0.0998 - val_categorical_accuracy: 0.5657\n",
      "\n",
      "Epoch 00037: val_categorical_accuracy did not improve from 0.56604\n",
      "Epoch 38/200\n",
      "86296/86296 [==============================] - 157s 2ms/step - loss: 0.0561 - categorical_accuracy: 0.5768 - val_loss: 0.0995 - val_categorical_accuracy: 0.5661\n",
      "\n",
      "Epoch 00038: val_categorical_accuracy improved from 0.56604 to 0.56613, saving model to best_model.hdf5\n",
      "Epoch 39/200\n",
      "73280/86296 [========================>.....] - ETA: 22s - loss: 0.0536 - categorical_accuracy: 0.5780"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86296/86296 [==============================] - 157s 2ms/step - loss: 0.0534 - categorical_accuracy: 0.5774 - val_loss: 0.0982 - val_categorical_accuracy: 0.5660\n",
      "\n",
      "Epoch 00042: val_categorical_accuracy did not improve from 0.56622\n",
      "Epoch 43/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.0522 - categorical_accuracy: 0.5778 - val_loss: 0.0984 - val_categorical_accuracy: 0.5665\n",
      "\n",
      "Epoch 00043: val_categorical_accuracy improved from 0.56622 to 0.56646, saving model to best_model.hdf5\n",
      "Epoch 44/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.0510 - categorical_accuracy: 0.5781 - val_loss: 0.1017 - val_categorical_accuracy: 0.5659\n",
      "\n",
      "Epoch 00044: val_categorical_accuracy did not improve from 0.56646\n",
      "Epoch 45/200\n",
      " 6720/86296 [=>............................] - ETA: 2:17 - loss: 0.0462 - categorical_accuracy: 0.5816"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86296/86296 [==============================] - 157s 2ms/step - loss: 0.0511 - categorical_accuracy: 0.5780 - val_loss: 0.1025 - val_categorical_accuracy: 0.5654\n",
      "\n",
      "Epoch 00047: val_categorical_accuracy did not improve from 0.56666\n",
      "Epoch 48/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.0510 - categorical_accuracy: 0.5780 - val_loss: 0.0964 - val_categorical_accuracy: 0.5669\n",
      "\n",
      "Epoch 00048: val_categorical_accuracy improved from 0.56666 to 0.56692, saving model to best_model.hdf5\n",
      "Epoch 49/200\n",
      "71936/86296 [========================>.....] - ETA: 24s - loss: 0.0498 - categorical_accuracy: 0.5782"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86296/86296 [==============================] - 157s 2ms/step - loss: 0.0525 - categorical_accuracy: 0.5775 - val_loss: 0.1040 - val_categorical_accuracy: 0.5654\n",
      "\n",
      "Epoch 00052: val_categorical_accuracy did not improve from 0.56692\n",
      "Epoch 53/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.0554 - categorical_accuracy: 0.5767 - val_loss: 0.1402 - val_categorical_accuracy: 0.5553\n",
      "\n",
      "Epoch 00053: val_categorical_accuracy did not improve from 0.56692\n",
      "Epoch 54/200\n",
      "86296/86296 [==============================] - 158s 2ms/step - loss: 0.0747 - categorical_accuracy: 0.5716 - val_loss: 0.7280 - val_categorical_accuracy: 0.4524\n",
      "\n",
      "Epoch 00054: val_categorical_accuracy did not improve from 0.56692\n",
      "Epoch 55/200\n",
      "14080/86296 [===>..........................] - ETA: 2:04 - loss: 1.0658 - categorical_accuracy: 0.3850"
     ]
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          validation_data = ([test_encoder_input_data, test_decoder_input_data], test_decoder_target_data),\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=callbacks_list,\n",
    "          #validation_split=0.2,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample output from train data\n",
    "decoded_sentences = []\n",
    "target_texts_ =  []\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    \n",
    "    decoded_sentence = decode_sequence(input_seq, encoder_model, decoder_model, num_decoder_tokens, int_to_vocab)\n",
    "    target_text = target_texts[seq_index][1:-1]\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('GT sentence:', target_text)\n",
    "    print('Decoded sentence:', decoded_sentence)   \n",
    "    decoded_sentences.append(decoded_sentence)\n",
    "    target_texts_.append(target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WER_spell_correction = calculate_WER(target_texts_, decoded_sentences)\n",
    "#print('WER_spell_correction |TRAIN= ', WER_spell_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample output from test data\n",
    "# Sample output from train data\n",
    "decoded_sentences = []\n",
    "target_texts_ =  []\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "\n",
    "    input_seq = test_encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq, encoder_model, decoder_model, num_decoder_tokens, int_to_vocab)\n",
    "    target_text = test_target_texts[seq_index][1:-1]\n",
    "    print('-')\n",
    "    print('Input sentence:', test_input_texts[seq_index])\n",
    "    print('GT sentence:', target_text)\n",
    "    print('Decoded sentence:', decoded_sentence)   \n",
    "    decoded_sentences.append(decoded_sentence)\n",
    "    target_texts_.append(target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WER_spell_correction = calculate_WER(target_texts_, decoded_sentences)\n",
    "print('WER_spell_correction |TEST= ', WER_spell_correction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "- Add attention\n",
    "- Full attention\n",
    "- Condition the Encoder on word embeddings of the context (Bi-directional LSTM)\n",
    "- Condition the Decoder on word embeddings of the context (Bi-directional LSTM) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- Sequence to Sequence Learning with Neural Networks\n",
    "    https://arxiv.org/abs/1409.3215\n",
    "- Learning Phrase Representations using\n",
    "    RNN Encoder-Decoder for Statistical Machine Translation\n",
    "    https://arxiv.org/abs/1406.107"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
