{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Bidirectional, Concatenate, GRU, Dot, TimeDistributed, Activation, Embedding, Lambda, Concatenate, Reshape\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, LearningRateScheduler\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from keras.models import load_model\n",
    "from nltk.tokenize import word_tokenize\n",
    "from autocorrect import spell\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit gpu allocation. allow_growth, or gpu_fraction\n",
    "def gpu_alloc():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_alloc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_WER_sent(gt, pred):\n",
    "    '''\n",
    "    calculate_WER('calculating wer between two sentences', 'calculate wer between two sentences')\n",
    "    '''\n",
    "    gt_words = gt.lower().split(' ')\n",
    "    pred_words = pred.lower().split(' ')\n",
    "    d = np.zeros(((len(gt_words) + 1), (len(pred_words) + 1)), dtype=np.uint8)\n",
    "    # d = d.reshape((len(gt_words)+1, len(pred_words)+1))\n",
    "\n",
    "    # Initializing error matrix\n",
    "    for i in range(len(gt_words) + 1):\n",
    "        for j in range(len(pred_words) + 1):\n",
    "            if i == 0:\n",
    "                d[0][j] = j\n",
    "            elif j == 0:\n",
    "                d[i][0] = i\n",
    "\n",
    "    # computation\n",
    "    for i in range(1, len(gt_words) + 1):\n",
    "        for j in range(1, len(pred_words) + 1):\n",
    "            if gt_words[i - 1] == pred_words[j - 1]:\n",
    "                d[i][j] = d[i - 1][j - 1]\n",
    "            else:\n",
    "                substitution = d[i - 1][j - 1] + 1\n",
    "                insertion = d[i][j - 1] + 1\n",
    "                deletion = d[i - 1][j] + 1\n",
    "                d[i][j] = min(substitution, insertion, deletion)\n",
    "    return d[len(gt_words)][len(pred_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_WER(gt, pred):\n",
    "    '''\n",
    "\n",
    "    :param gt: list of sentences of the ground truth\n",
    "    :param pred: list of sentences of the predictions\n",
    "    both lists must have the same length\n",
    "    :return: accumulated WER\n",
    "    '''\n",
    "#    assert len(gt) == len(pred)\n",
    "    WER = 0\n",
    "    nb_w = 0\n",
    "    for i in range(len(gt)):\n",
    "        #print(gt[i])\n",
    "        #print(pred[i])\n",
    "        WER += calculate_WER_sent(gt[i], pred[i])\n",
    "        nb_w += len(gt[i])\n",
    "\n",
    "    return WER / nb_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artificial noisy spelling mistakes\n",
    "def noise_maker(sentence, threshold):\n",
    "    '''Relocate, remove, or add characters to create spelling mistakes'''\n",
    "    letters = ['a','b','c','d','e','f','g','h','i','j','k','l','m',\n",
    "           'n','o','p','q','r','s','t','u','v','w','x','y','z',]\n",
    "    noisy_sentence = []\n",
    "    i = 0\n",
    "    while i < len(sentence):\n",
    "        random = np.random.uniform(0, 1, 1)\n",
    "        # Most characters will be correct since the threshold value is high\n",
    "        if random < threshold:\n",
    "            noisy_sentence.append(sentence[i])\n",
    "        else:\n",
    "            new_random = np.random.uniform(0, 1, 1)\n",
    "            # ~33% chance characters will swap locations\n",
    "            if new_random > 0.67:\n",
    "                if i == (len(sentence) - 1):\n",
    "                    # If last character in sentence, it will not be typed\n",
    "                    continue\n",
    "                else:\n",
    "                    # if any other character, swap order with following character\n",
    "                    noisy_sentence.append(sentence[i + 1])\n",
    "                    noisy_sentence.append(sentence[i])\n",
    "                    i += 1\n",
    "            # ~33% chance an extra lower case letter will be added to the sentence\n",
    "            elif new_random < 0.33:\n",
    "                random_letter = np.random.choice(letters, 1)[0]\n",
    "                noisy_sentence.append(random_letter)\n",
    "                noisy_sentence.append(sentence[i])\n",
    "            # ~33% chance a character will not be typed\n",
    "            else:\n",
    "                pass\n",
    "        i += 1\n",
    "\n",
    "    return ''.join(noisy_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_with_gt(file_name, num_samples, max_sent_len, min_sent_len, delimiter='\\t', gt_index=1, prediction_index=0):\n",
    "    '''Load data from txt file, with each line has: <TXT><TAB><GT>. The  target to the decoder muxt have \\t as the start trigger and \\n as the stop trigger.'''\n",
    "    cnt = 0  \n",
    "    input_texts = []\n",
    "    gt_texts = []\n",
    "    target_texts = []\n",
    "    for row in open(file_name, encoding='utf8'):\n",
    "        if cnt < num_samples :\n",
    "            #print(row)\n",
    "            sents = row.split(delimiter)\n",
    "            if (len(sents) < 2):\n",
    "                continue             \n",
    "            input_text = sents[prediction_index]\n",
    "            \n",
    "            target_text = '\\t' + sents[gt_index] + '\\n'\n",
    "            if len(input_text) > min_sent_len and len(input_text) < max_sent_len and len(target_text) > min_sent_len and len(target_text) < max_sent_len:\n",
    "                cnt += 1\n",
    "                \n",
    "                input_texts.append(input_text)\n",
    "                target_texts.append(target_text)\n",
    "                gt_texts.append(sents[gt_index])\n",
    "    return input_texts, target_texts, gt_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_with_noise(file_name, num_samples, noise_threshold, max_sent_len, min_sent_len):\n",
    "    '''Load data from txt file, with each line has: <TXT>. The GT is just a noisy version of TXT. The  target to the decoder muxt have \\t as the start trigger and \\n as the stop trigger.'''\n",
    "    cnt = 0  \n",
    "    input_texts = []\n",
    "    gt_texts = []\n",
    "    target_texts = []\n",
    "    while cnt < num_samples :\n",
    "        for row in open(file_name, encoding='utf8'):\n",
    "        #for row in open(file_name):\n",
    "            if cnt < num_samples :\n",
    "                sents = row.split(\"\\t\")\n",
    "                if (len(sents) < 2):\n",
    "                    continue                 \n",
    "                input_text = noise_maker(sents[1], noise_threshold)\n",
    "                input_text = input_text[:-1]\n",
    "\n",
    "                target_text = '\\t' + sents[1] + '\\n'            \n",
    "                if len(input_text) > min_sent_len and len(input_text) < max_sent_len and len(target_text) > min_sent_len and len(target_text) < max_sent_len:\n",
    "                    cnt += 1\n",
    "                    input_texts.append(input_text)\n",
    "                    target_texts.append(target_text)\n",
    "                    gt_texts.append(target_text[1:-1])\n",
    "                    \n",
    "    return input_texts, target_texts, gt_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_medical_terms_with_noise(json_file, num_samples, noise_threshold):\n",
    "    with open(json_file) as f:\n",
    "        med_terms_dict = json.load(f)\n",
    "    med_terms = list(med_terms_dict.keys())\n",
    "    input_texts = []\n",
    "    gt_texts = []\n",
    "    target_texts = []\n",
    "    cnt = 0\n",
    "    while cnt < num_samples:\n",
    "        for term in med_terms:\n",
    "            if cnt < num_samples :\n",
    "                input_text = noise_maker(term, noise_threshold)\n",
    "                input_text = input_text[:-1]   \n",
    "\n",
    "                target_text = '\\t' + term + '\\n'\n",
    "\n",
    "                input_texts.append(input_text)\n",
    "                target_texts.append(target_text)\n",
    "                gt_texts.append(target_text[1:-1])        \n",
    "                cnt += 1\n",
    "    return input_texts, target_texts, gt_texts, med_terms_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_accidents_terms_with_noise(file_name, limit, num_samples, noise_threshold):\n",
    "\n",
    "    f = open(file_name, encoding='utf8')\n",
    "    line = 0    \n",
    "    med_terms = []\n",
    "    try:\n",
    "        for r in f:\n",
    "            if(line < limit):\n",
    "\n",
    "                med_terms.extend(r.split('|'))\n",
    "                line += 1\n",
    "    except:\n",
    "        print('finished')\n",
    "    input_texts = []\n",
    "    gt_texts = []\n",
    "    target_texts = []\n",
    "    cnt = 0\n",
    "    while cnt < num_samples:\n",
    "        for term in med_terms:\n",
    "            if cnt < num_samples :\n",
    "                input_text = noise_maker(term, noise_threshold)\n",
    "                input_text = input_text[:-1]   \n",
    "\n",
    "                target_text = '\\t' + term + '\\n'\n",
    "\n",
    "                input_texts.append(input_text)\n",
    "                target_texts.append(target_text)\n",
    "                gt_texts.append(target_text[1:-1])        \n",
    "                cnt += 1\n",
    "                \n",
    "    return input_texts, target_texts, gt_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_procedures_tests_with_noise(file_name, num_samples, noise_threshold):\n",
    "    '''Load data from txt file, with each line has: <TXT>. The GT is just a noisy version of TXT. The  target to the decoder muxt have \\t as the start trigger and \\n as the stop trigger.'''\n",
    "    cnt = 0  \n",
    "    input_texts = []\n",
    "    gt_texts = []\n",
    "    target_texts = []\n",
    "    while cnt < num_samples :\n",
    "        for row in open(file_name, encoding='utf8'):\n",
    "        #for row in open(file_name):\n",
    "            if cnt < num_samples :\n",
    "                \n",
    "                input_text = noise_maker(row, noise_threshold)\n",
    "                input_text = input_text[:-1]\n",
    "\n",
    "                target_text = '\\t' + row + '\\n'            \n",
    "\n",
    "                cnt += 1\n",
    "                input_texts.append(input_text)\n",
    "                target_texts.append(target_text)\n",
    "                gt_texts.append(target_text[1:-1])\n",
    "                    \n",
    "    return input_texts, target_texts, gt_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_words_vocab(all_texts):\n",
    "    '''Build vocab dictionary to victorize chars into ints'''\n",
    "    vocab_to_int = {}\n",
    "    count = 0 # Start index for any char will be 1, as 0 is masked by the Embedding/Masking layer\n",
    "    codes = ['UNK', ' ', '\\t','\\n']# Start 'UNK' at the first entry, to keep its index=0 to be masked\n",
    "    for code in codes:\n",
    "        if code not in vocab_to_int:\n",
    "            vocab_to_int[code] = count\n",
    "            count += 1    \n",
    "    \n",
    "    for sentence in all_texts:       \n",
    "        for word in word_tokenize(sentence):\n",
    "            word = process_word(word)\n",
    "            if word not in vocab_to_int:\n",
    "                vocab_to_int[word] = count\n",
    "                count += 1\n",
    "\n",
    "\n",
    "    '''''Build inverse translation from int to word'''\n",
    "    int_to_vocab = {}\n",
    "    for word, value in vocab_to_int.items():\n",
    "        int_to_vocab[value] = word\n",
    "        \n",
    "    return vocab_to_int, int_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chars_vocab(all_texts):\n",
    "    '''Build vocab dictionary to victorize chars into ints'''\n",
    "    vocab_to_int = {}\n",
    "    count = 0 # Start index for any char will be 1, as 0 is masked by the Embedding/Masking layer\n",
    "    codes = ['UNK', ' ', '\\t','\\n']# Start 'UNK' at the first entry, to keep its index=0 to be masked\n",
    "    for code in codes:\n",
    "        if code not in vocab_to_int:\n",
    "            vocab_to_int[code] = count\n",
    "            count += 1    \n",
    "    \n",
    "    for sentence in all_texts:\n",
    "        for char in sentence:\n",
    "            if char not in vocab_to_int:\n",
    "                vocab_to_int[char] = count\n",
    "                count += 1\n",
    "\n",
    "\n",
    "    '''''Build inverse translation from int to char'''\n",
    "    int_to_vocab = {}\n",
    "    for character, value in vocab_to_int.items():\n",
    "        int_to_vocab[value] = character\n",
    "        \n",
    "    return vocab_to_int, int_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_char_data(input_texts, target_texts, max_encoder_seq_length, num_encoder_tokens, vocab_to_int):\n",
    "    '''Prepares the input text and targets into the proper seq2seq numpy arrays'''\n",
    "    encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length),\n",
    "    dtype='float32')\n",
    "    decoder_input_data = np.zeros(\n",
    "        (len(input_texts), max_decoder_seq_length),\n",
    "        dtype='float32')\n",
    "    decoder_target_data = np.zeros(\n",
    "        (len(input_texts), max_decoder_seq_length, num_encoder_tokens),\n",
    "        dtype='float32')\n",
    "\n",
    "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "        for t, char in enumerate(input_text):\n",
    "            # c0..cn\n",
    "            encoder_input_data[i, t] = vocab_to_int[char]\n",
    "        for t, char in enumerate(target_text):\n",
    "            # c0'..cm'\n",
    "            # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "            decoder_input_data[i, t] = vocab_to_int[char]\n",
    "            if t > 0:\n",
    "                # decoder_target_data will be ahead by one timestep\n",
    "                # and will not include the start character.\n",
    "                decoder_target_data[i, t - 1, vocab_to_int[char]] = 1.\n",
    "                \n",
    "    return encoder_input_data, decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_hier_data(input_texts, target_texts, max_words_seq_length, max_chars_seq_length, num_char_tokens, num_word_tokens, word2int, char2int):\n",
    "\n",
    "    '''Prepares the input text and targets into the proper seq2seq numpy arrays'''\n",
    "    # \n",
    "    encoder_char_input_data = np.zeros(\n",
    "    (len(input_texts), max_words_seq_length, max_chars_seq_length),\n",
    "    dtype='float32')\n",
    "    \n",
    "    decoder_word_input_data = np.zeros(\n",
    "        (len(input_texts), max_words_seq_length),\n",
    "        dtype='float32')\n",
    "    \n",
    "    decoder_word_target_data = np.zeros(\n",
    "        (len(input_texts), max_words_seq_length, num_word_tokens),\n",
    "        dtype='float32')\n",
    "\n",
    "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "        words_lst = word_tokenize(input_text)\n",
    "        if(len(words_lst) > max_words_seq_length):\n",
    "            continue\n",
    "        for j, word in enumerate(words_lst):\n",
    "            if(len(word) > max_chars_seq_length):\n",
    "                continue\n",
    "            for k, char in enumerate(word):\n",
    "                # c0..cn\n",
    "                if(char in char2int):\n",
    "                    encoder_char_input_data[i, j, k] = char2int[char]\n",
    "                    \n",
    "        words_lst = word_tokenize(target_text)\n",
    "        if(len(words_lst) > max_words_seq_length):\n",
    "            continue                \n",
    "        for j, word in enumerate(words_lst):\n",
    "            processed_word = process_word(word)\n",
    "            if not processed_word in word2int:\n",
    "                continue\n",
    "            # c0'..cm'\n",
    "            # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "            decoder_word_input_data[i, j] = word2int[processed_word]\n",
    "            if j > 0:\n",
    "                # decoder_target_data will be ahead by one timestep\n",
    "                # and will not include the start character.\n",
    "                decoder_word_target_data[i, j - 1, word2int[processed_word]] = 1.\n",
    "                \n",
    "    return encoder_char_input_data, decoder_word_input_data, decoder_word_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, encoder_model, decoder_model, max_words_seq_len, num_decoder_tokens, int_to_vocab):\n",
    "    # Encode the input as state vectors.\n",
    "    encoder_outputs, h, c  = encoder_model.predict(input_seq)\n",
    "    states_value = [h,c]\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, max_words_seq_len))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = vocab_to_int['\\t']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    #print(input_seq)\n",
    "    attention_density = []\n",
    "\n",
    "    special_chars = ['\\\\', '/', '-', '—' , ':', '[', ']', ',', '.', '\"', ';', '%', '~', '(', ')', '{', '}', '$']\n",
    "    i = 0\n",
    "    while not stop_condition:\n",
    "        #print(target_seq)\n",
    "        output_tokens, attention, h, c  = decoder_model.predict(\n",
    "            [target_seq, encoder_outputs] + states_value)\n",
    "        #print(attention.shape)\n",
    "        attention_density.append(attention[0][0])# attention is max_sent_len x 1 since we have num_time_steps = 1 for the output\n",
    "        # Sample a token\n",
    "        #print(output_tokens.shape)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        \n",
    "        #print(sampled_token_index)\n",
    "        sampled_char = int_to_vocab[sampled_token_index]\n",
    "       \n",
    "        \n",
    "        #orig_char = int_to_vocab[int(input_seq[:,i][0])]\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(word_tokenize(decoded_sentence)) > max_words_seq_len):\n",
    "            stop_condition = True\n",
    "            sampled_char = ''\n",
    "\n",
    "        # Copy digits as it, since the spelling corrector is not good at digit corrections\n",
    "        '''\n",
    "        if(orig_char.isdigit() or orig_char in special_chars):\n",
    "            decoded_sentence += orig_char            \n",
    "        else:\n",
    "            if(sampled_char.isdigit() or sampled_char in special_chars):\n",
    "                decoded_sentence += ''\n",
    "            else:\n",
    "                decoded_sentence += sampled_char\n",
    "        '''\n",
    "        decoded_sentence += sampled_char + ' '\n",
    "\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, max_words_seq_len))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "        i += 1\n",
    "        if i > 48:\n",
    "            i = 0\n",
    "        \n",
    "\n",
    "    attention_density = np.array(attention_density)\n",
    "    return decoded_sentence, attention_density\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_char_sequence(input_seq, encoder_model, decoder_model, num_decoder_tokens, int_to_vocab):\n",
    "    # Encode the input as state vectors.\n",
    "    encoder_outputs, h, c  = encoder_model.predict(input_seq)\n",
    "    states_value = [h,c]\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = vocab_to_int['\\t']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    #print(input_seq)\n",
    "    attention_density = []\n",
    "    i = 0\n",
    "    special_chars = ['\\\\', '/', '-', '—' , ':', '[', ']', ',', '.', '\"', ';', '%', '~', '(', ')', '{', '}', '$']\n",
    "    while not stop_condition:\n",
    "        #print(target_seq)\n",
    "        output_tokens, attention, h, c  = decoder_model.predict(\n",
    "            [target_seq, encoder_outputs] + states_value)\n",
    "        #print(attention.shape)\n",
    "        attention_density.append(attention[0][0])# attention is max_sent_len x 1 since we have num_time_steps = 1 for the output\n",
    "        # Sample a token\n",
    "        #print(output_tokens.shape)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        \n",
    "        #print(sampled_token_index)\n",
    "        sampled_char = int_to_vocab[sampled_token_index]\n",
    "        orig_char = int_to_vocab[int(input_seq[:,i][0])]\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "            sampled_char = ''\n",
    "\n",
    "        # Copy digits as it, since the spelling corrector is not good at digit corrections\n",
    "        if(orig_char.isdigit() or orig_char in special_chars):\n",
    "            decoded_sentence += orig_char            \n",
    "        else:\n",
    "            if(sampled_char.isdigit() or sampled_char in special_chars):\n",
    "                decoded_sentence += ''\n",
    "            else:\n",
    "                decoded_sentence += sampled_char\n",
    "        \n",
    "\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "        \n",
    "        i += 1\n",
    "        if(i > 48):\n",
    "            i = 0\n",
    "    attention_density = np.array(attention_density)\n",
    "    return decoded_sentence, attention_density\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_char_model(num_encoder_tokens, latent_dim):\n",
    "    # Define an input sequence and process it.\n",
    "    encoder_inputs = Input(shape=(None,), dtype='float32')\n",
    "    encoder_inputs_ = Embedding(num_encoder_tokens, num_encoder_tokens,                           \n",
    "                            weights=[np.eye(num_encoder_tokens)],\n",
    "                            mask_zero=True, trainable=False)(encoder_inputs)    \n",
    "    #encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "    encoder = Bidirectional(LSTM(latent_dim, return_state=True, return_sequences=True)) # Bi LSTM\n",
    "    encoder_outputs, state_f_h, state_f_c, state_b_h, state_b_c = encoder(encoder_inputs_)# Bi LSTM\n",
    "    state_h = Concatenate()([state_f_h, state_b_h])# Bi LSTM\n",
    "    state_c = Concatenate()([state_f_c, state_b_c])# Bi LSTM\n",
    "\n",
    "    # We discard `encoder_outputs` and only keep the states.\n",
    "    encoder_states = [state_h, state_c]# Bi GRU, LSTM, BHi LSTM\n",
    "    #print(encoder_states)\n",
    "    \n",
    "    decoder_inputs = Input(shape=(None,))\n",
    "    decoder_inputs_ = Embedding(num_encoder_tokens, num_encoder_tokens,                           \n",
    "                            weights=[np.eye(num_encoder_tokens)],\n",
    "                            mask_zero=True, trainable=False)(decoder_inputs)    \n",
    "    # We set up our decoder to return full output sequences,\n",
    "    # and to return internal states as well. We don't use the\n",
    "    # return states in the training model, but we will use them in inference.\n",
    "    decoder_lstm = LSTM(latent_dim*2, return_sequences=True, return_state=True)# Bi LSTM\n",
    "    \n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs_, initial_state=encoder_states)\n",
    "\n",
    "    # Equation (7) with 'dot' score from Section 3.1 in the paper.\n",
    "    # Note that we reuse Softmax-activation layer instead of writing tensor calculation\n",
    "    #print(decoder_outputs)\n",
    "    #print(encoder_outputs)\n",
    "    att_dot = Dot(axes=[2, 2])\n",
    "    attention = att_dot([decoder_outputs, encoder_outputs])\n",
    "    att_activation = Activation('softmax', name='attention')\n",
    "    attention = att_activation(attention)\n",
    "    #print('attention', attention)\n",
    "    context_dot = Dot(axes=[2,1])\n",
    "    context = context_dot([attention, encoder_outputs])\n",
    "    #print('context', context)\n",
    "    att_context_concat = Concatenate()\n",
    "    decoder_combined_context = att_context_concat([context, decoder_outputs])\n",
    "    #print('decoder_combined_context', decoder_combined_context)\n",
    "\n",
    "    # Has another weight + tanh layer as described in equation (5) of the paper\n",
    "    #decoder_outputs = TimeDistributed(Dense(64, activation=\"tanh\"))(decoder_combined_context)\n",
    "    #decoder_outputs = TimeDistributed(Dense(num_encoder_tokens, activation=\"softmax\"))(decoder_outputs)\n",
    "\n",
    "    decoder_dense = Dense(num_encoder_tokens, activation='softmax')\n",
    "    #decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_outputs = decoder_dense(decoder_combined_context)\n",
    "\n",
    "    # Define the model that will turn\n",
    "    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    #model = Model(decoder_inputs, decoder_outputs)\n",
    "    #print('encoder-decoder  model:')\n",
    "    print(model.summary()) \n",
    "    \n",
    "    #print(encoder_inputs)\n",
    "    #print(encoder_outputs)\n",
    "    #print(encoder_states)\n",
    "    #encoder_model = Model(encoder_inputs, [encoder_outputs, encoder_states])\n",
    "    encoder_model = Model(input=encoder_inputs, output=[encoder_outputs] + encoder_states)\n",
    "\n",
    "    #decoder_state_input_h = Input(shape=(latent_dim,))# LSTM\n",
    "    #decoder_state_input_c = Input(shape=(latent_dim,))# LSTM\n",
    "    decoder_encoder_inputs = Input(shape=(None, latent_dim*2,))\n",
    "    decoder_state_input_h = Input(shape=(latent_dim*2,))# Bi LSTM\n",
    "    decoder_state_input_c = Input(shape=(latent_dim*2,)) # Bi LSTM\n",
    "    #decoder_state_input = Input(shape=(latent_dim*2,)) # Bi GRU\n",
    "\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    #decoder_states_inputs = [decoder_state_input] # Bi GRU\n",
    "\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs_, initial_state=decoder_states_inputs)\n",
    "\n",
    "    #decoder_outputs, state = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "\n",
    "    decoder_states = [state_h, state_c]\n",
    "    \n",
    "    # Equation (7) with 'dot' score from Section 3.1 in the paper.\n",
    "    # Note that we reuse Softmax-activation layer instead of writing tensor calculation\n",
    "    \n",
    "    attention = att_dot([decoder_outputs, decoder_encoder_inputs])\n",
    "    \n",
    "    attention = att_activation(attention)\n",
    "    #print('attention', attention)\n",
    "    \n",
    "    context = context_dot([attention, decoder_encoder_inputs])\n",
    "    #print('context', context)\n",
    "    \n",
    "    \n",
    "    \n",
    "    decoder_combined_context = att_context_concat([context, decoder_outputs])\n",
    "    #print('decoder_combined_context', decoder_combined_context)\n",
    "\n",
    "    # Has another weight + tanh layer as described in equation (5) of the paper\n",
    "    #decoder_outputs = TimeDistributed(Dense(64, activation=\"tanh\"))(decoder_combined_context)\n",
    "    #decoder_outputs = TimeDistributed(Dense(num_encoder_tokens, activation=\"softmax\"))(decoder_outputs)\n",
    "    \n",
    "    #decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "    #decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_outputs = decoder_dense(decoder_combined_context)\n",
    "    \n",
    "    decoder_model = Model(\n",
    "        [decoder_inputs, decoder_encoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs, attention] + decoder_states)\n",
    "    \n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hier_model(encoder_char_model, max_words_seq_len, max_char_seq_len, num_word_tokens, num_char_tokens, latent_dim):\n",
    "    # Define an input sequence and process it.\n",
    "\n",
    "    inputs = Input(shape=(max_words_seq_len, max_char_seq_len,), dtype='float32')\n",
    "    decoder_inputs_words = Input(shape=(max_words_seq_len,), dtype='float32')\n",
    "    words_states = []\n",
    "    \n",
    "    for w in range(max_words_seq_len):\n",
    "        \n",
    "        encoder_char_inputs = Lambda(lambda x: x[:,w,:])(inputs)\n",
    "        _, h, c = encoder_char_model(encoder_char_inputs)\n",
    "        encoder_chars_states = Concatenate()([h,c])\n",
    "        #print(encoder_chars_states)\n",
    "        encoder_chars_states = Reshape((1,latent_dim*4))(encoder_chars_states)\n",
    "        words_states.append(encoder_chars_states)\n",
    "    \n",
    "    input_words = Concatenate(axis=-2)(words_states)\n",
    "\n",
    "\n",
    "    \n",
    "    encoder_inputs_ = input_words   \n",
    "    #encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "    encoder = Bidirectional(LSTM(latent_dim, return_state=True, return_sequences=True)) # Bi LSTM\n",
    "    encoder_outputs, state_f_h, state_f_c, state_b_h, state_b_c = encoder(encoder_inputs_)# Bi LSTM\n",
    "    state_h = Concatenate()([state_f_h, state_b_h])# Bi LSTM\n",
    "    state_c = Concatenate()([state_f_c, state_b_c])# Bi LSTM\n",
    "\n",
    "    # We discard `encoder_outputs` and only keep the states.\n",
    "    encoder_states = [state_h, state_c]# Bi GRU, LSTM, BHi LSTM\n",
    "    \n",
    "    decoder_inputs = decoder_inputs_words\n",
    "    decoder_inputs_ = Embedding(num_word_tokens, latent_dim*4,                           \n",
    "                            #weights=[np.eye(num_word_tokens)],\n",
    "                            mask_zero=True, trainable=True)(decoder_inputs)    \n",
    "    # We set up our decoder to return full output sequences,\n",
    "    # and to return internal states as well. We don't use the\n",
    "    # return states in the training model, but we will use them in inference.\n",
    "    decoder_lstm = LSTM(latent_dim*2, return_sequences=True, return_state=True)# Bi LSTM\n",
    "    \n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs_, initial_state=encoder_states)\n",
    "\n",
    "    att_dot = Dot(axes=[2, 2])\n",
    "    attention = att_dot([decoder_outputs, encoder_outputs])\n",
    "    att_activation = Activation('softmax')\n",
    "    attention = att_activation(attention)\n",
    "    #print('attention', attention)\n",
    "    context_dot = Dot(axes=[2,1])\n",
    "    context = context_dot([attention, encoder_outputs])\n",
    "    #print('context', context)\n",
    "    att_context_concat = Concatenate()\n",
    "    decoder_combined_context = att_context_concat([context, decoder_outputs])\n",
    "    #print('decoder_combined_context', decoder_combined_context)\n",
    "\n",
    "    # Has another weight + tanh layer as described in equation (5) of the paper\n",
    "    #decoder_outputs = TimeDistributed(Dense(64, activation=\"tanh\"))(decoder_combined_context)\n",
    "    #decoder_outputs = TimeDistributed(Dense(num_encoder_tokens, activation=\"softmax\"))(decoder_outputs)\n",
    "\n",
    "    decoder_dense = Dense(num_word_tokens, activation='softmax')\n",
    "    #decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_outputs = decoder_dense(decoder_combined_context)\n",
    "\n",
    "    # Define the model that will turn\n",
    "    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "    model = Model([inputs, decoder_inputs_words], decoder_outputs)\n",
    "    #model = Model(decoder_inputs, decoder_outputs)\n",
    "    print('encoder-decoder  model:')\n",
    "    print(model.summary()) \n",
    "    \n",
    "    #encoder_model = Model(encoder_inputs, [encoder_outputs, encoder_states])\n",
    "    encoder_model = Model(input=inputs, output=[encoder_outputs] + encoder_states)\n",
    "\n",
    "    #decoder_state_input_h = Input(shape=(latent_dim,))# LSTM\n",
    "    #decoder_state_input_c = Input(shape=(latent_dim,))# LSTM\n",
    "    decoder_encoder_inputs = Input(shape=(max_words_seq_len, latent_dim*2,))\n",
    "    decoder_state_input_h = Input(shape=(latent_dim*2,))# Bi LSTM\n",
    "    decoder_state_input_c = Input(shape=(latent_dim*2,)) # Bi LSTM\n",
    "    #decoder_state_input = Input(shape=(latent_dim*2,)) # Bi GRU\n",
    "\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    #decoder_states_inputs = [decoder_state_input] # Bi GRU\n",
    "\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs_, initial_state=decoder_states_inputs)\n",
    "\n",
    "    #decoder_outputs, state = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "\n",
    "    decoder_states = [state_h, state_c]\n",
    "    \n",
    "    # Equation (7) with 'dot' score from Section 3.1 in the paper.\n",
    "    # Note that we reuse Softmax-activation layer instead of writing tensor calculation\n",
    "    \n",
    "    attention = att_dot([decoder_outputs, decoder_encoder_inputs])\n",
    "    \n",
    "    attention = att_activation(attention)\n",
    "    #print('attention', attention)\n",
    "    \n",
    "    context = context_dot([attention, decoder_encoder_inputs])\n",
    "    #print('context', context)\n",
    "    \n",
    "    \n",
    "    \n",
    "    decoder_combined_context = att_context_concat([context, decoder_outputs])\n",
    "    #print('decoder_combined_context', decoder_combined_context)\n",
    "\n",
    "    # Has another weight + tanh layer as described in equation (5) of the paper\n",
    "    #decoder_outputs = TimeDistributed(Dense(64, activation=\"tanh\"))(decoder_combined_context)\n",
    "    #decoder_outputs = TimeDistributed(Dense(num_encoder_tokens, activation=\"softmax\"))(decoder_outputs)\n",
    "    \n",
    "    #decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "    #decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_outputs = decoder_dense(decoder_combined_context)\n",
    "    \n",
    "    decoder_model = Model(\n",
    "        [decoder_inputs_words, decoder_encoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs, attention] + decoder_states)\n",
    "    \n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n_, encoder_char_model, _ = build_char_model(num_encoder_tokens=28, latent_dim=256)\\nhier_model = build_hier_model(encoder_char_model=encoder_char_model, max_words_seq_len=40, max_char_seq_len=20, num_word_tokens=1000, num_char_tokens=28, latent_dim=256)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "_, encoder_char_model, _ = build_char_model(num_encoder_tokens=28, latent_dim=256)\n",
    "hier_model = build_hier_model(encoder_char_model=encoder_char_model, max_words_seq_len=40, max_char_seq_len=20, num_word_tokens=1000, num_char_tokens=28, latent_dim=256)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nx = Input(shape=(50,))\\nx = Reshape((1,50))(x)\\nprint(x)\\nl = []\\nl.append(x)\\nl.append(x)\\nprint(l)\\ny = Concatenate(axis=-2)(l)\\nprint(y)\\nz = Reshape((-1,2,50))(y)\\nprint(z)\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "x = Input(shape=(50,))\n",
    "x = Reshape((1,50))(x)\n",
    "print(x)\n",
    "l = []\n",
    "l.append(x)\n",
    "l.append(x)\n",
    "print(l)\n",
    "y = Concatenate(axis=-2)(l)\n",
    "print(y)\n",
    "z = Reshape((-1,2,50))(y)\n",
    "print(z)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_attention(text, encoder_model, decoder_model, max_encoder_seq_length, num_decoder_tokens, vocab_to_int, int_to_vocab):\n",
    "\n",
    "    encoder_input_data = np.zeros((1, max_encoder_seq_length), dtype='float32')\n",
    "    \n",
    "    for t, char in enumerate(text):\n",
    "        # c0..cn\n",
    "        encoder_input_data[0, t] = vocab_to_int[char]\n",
    "\n",
    "    input_seq = encoder_input_data[0:1]\n",
    "\n",
    "    decoded_sentence, attention_density = decode_sequence(input_seq, encoder_model, decoder_model, num_decoder_tokens, int_to_vocab)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(28,12))\n",
    "    \n",
    "    ax = sns.heatmap(attention_density[:, : len(text) + 2],\n",
    "        xticklabels=[w for w in text],\n",
    "        yticklabels=[w for w in decoded_sentence])\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "    plt.show()\n",
    "    \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_word(word):\n",
    "    # Try to correct the word from known dict\n",
    "    #word = spell(word)\n",
    "    # Option 1: Replace special chars and digits\n",
    "    #processed_word = re.sub(r'[\\\\\\/\\-\\—\\:\\[\\]\\,\\.\\\"\\;\\%\\~\\(\\)\\{\\}\\$\\#\\?\\●\\@\\+\\-\\*\\d]', r'', w.lower())\n",
    "    \n",
    "    # Option 2: skip all words with special chars or digits\n",
    "    if(len(re.findall(r'[\\\\\\/\\-\\—\\:\\[\\]\\,\\.\\\"\\;\\%\\~\\(\\)\\{\\}\\$\\#\\?\\●\\@\\+\\-\\*\\d]', word.lower())) == 0):\n",
    "        processed_word = word.lower()\n",
    "    else:\n",
    "        processed_word = 'UNK'\n",
    "\n",
    "    # Skip stop words\n",
    "    stop_words = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]        \n",
    "    if processed_word in stop_words:\n",
    "        processed_word = 'UNK'\n",
    "        \n",
    "    return processed_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-train char model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../dat/'\n",
    "max_sent_len = 50\n",
    "min_sent_len = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "files_list = ['all_ocr_data_2.txt', 'field_class_21.txt', 'field_class_32.txt', 'field_class_30.txt']\n",
    "desired_file_sizes = [num_samples, num_samples, num_samples, num_samples]\n",
    "noise_threshold = 0.9\n",
    "\n",
    "for file_name, num_file_samples in zip(files_list, desired_file_sizes):\n",
    "    tess_correction_data = os.path.join(data_path, file_name)\n",
    "    input_texts_OCR, target_texts_OCR, gt_OCR = load_data_with_noise(tess_correction_data, num_file_samples, noise_threshold, max_sent_len, min_sent_len)\n",
    "\n",
    "    input_texts += input_texts_OCR\n",
    "    target_texts += target_texts_OCR\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chars_per_words_lengths = []\n",
    "words_per_sents_lengths = []\n",
    "\n",
    "# Chars per word should be on all text\n",
    "for text in (input_texts_OCR+target_texts_OCR):\n",
    "    words = word_tokenize(text)\n",
    "    #words_per_sents_lengths.append(len(words))\n",
    "    for word in words:\n",
    "        chars_per_words_lengths.append(len(word))\n",
    "\n",
    "# Words in sent should be on target only        \n",
    "for text in target_texts_OCR:\n",
    "    words = word_tokenize(text)\n",
    "    words_per_sents_lengths.append(len(words))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f565984d358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h_w = plt.hist(words_per_sents_lengths, bins=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5658f82ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h_c = plt.hist(chars_per_words_lengths, bins=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build char vocab (all text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = target_texts + input_texts\n",
    "vocab_to_int, int_to_vocab = build_chars_vocab(all_texts)\n",
    "np.savez('vocab_char-{}'.format(max_sent_len), vocab_to_int=vocab_to_int, int_to_vocab=int_to_vocab, max_sent_len=max_sent_len, min_sent_len=min_sent_len )\n",
    "char2int = vocab_to_int\n",
    "int2char = int_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = sorted(list(vocab_to_int))\n",
    "target_characters = sorted(list(vocab_to_int))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 4000\n",
      "Number of unique input tokens: 91\n",
      "Number of unique output tokens: 91\n",
      "Max sequence length for inputs: 49\n",
      "Max sequence length for outputs: 49\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t': 2,\n",
       " '\\n': 3,\n",
       " ' ': 1,\n",
       " '#': 67,\n",
       " '$': 80,\n",
       " '%': 85,\n",
       " '&': 73,\n",
       " \"'\": 83,\n",
       " '(': 64,\n",
       " ')': 65,\n",
       " '*': 77,\n",
       " '+': 76,\n",
       " ',': 69,\n",
       " '-': 21,\n",
       " '.': 48,\n",
       " '/': 29,\n",
       " '0': 54,\n",
       " '1': 43,\n",
       " '2': 53,\n",
       " '3': 57,\n",
       " '4': 56,\n",
       " '5': 74,\n",
       " '6': 55,\n",
       " '7': 70,\n",
       " '8': 61,\n",
       " '9': 72,\n",
       " ':': 13,\n",
       " ';': 75,\n",
       " '=': 89,\n",
       " '?': 60,\n",
       " '@': 81,\n",
       " 'A': 16,\n",
       " 'B': 15,\n",
       " 'C': 4,\n",
       " 'D': 40,\n",
       " 'E': 45,\n",
       " 'F': 33,\n",
       " 'G': 41,\n",
       " 'H': 52,\n",
       " 'I': 22,\n",
       " 'J': 68,\n",
       " 'K': 50,\n",
       " 'L': 37,\n",
       " 'M': 36,\n",
       " 'N': 35,\n",
       " 'O': 30,\n",
       " 'P': 26,\n",
       " 'Q': 78,\n",
       " 'R': 46,\n",
       " 'S': 38,\n",
       " 'T': 9,\n",
       " 'U': 49,\n",
       " 'UNK': 0,\n",
       " 'V': 14,\n",
       " 'W': 51,\n",
       " 'X': 79,\n",
       " 'Y': 47,\n",
       " 'Z': 71,\n",
       " '^': 86,\n",
       " '_': 90,\n",
       " 'a': 6,\n",
       " 'b': 39,\n",
       " 'c': 17,\n",
       " 'd': 18,\n",
       " 'e': 12,\n",
       " 'f': 32,\n",
       " 'g': 42,\n",
       " 'h': 28,\n",
       " 'i': 7,\n",
       " 'j': 23,\n",
       " 'k': 59,\n",
       " 'l': 5,\n",
       " 'm': 8,\n",
       " 'n': 19,\n",
       " 'o': 27,\n",
       " 'p': 11,\n",
       " 'q': 58,\n",
       " 'r': 25,\n",
       " 's': 34,\n",
       " 't': 20,\n",
       " 'u': 24,\n",
       " 'v': 44,\n",
       " 'w': 31,\n",
       " 'x': 62,\n",
       " 'y': 10,\n",
       " 'z': 63,\n",
       " '|': 82,\n",
       " '’': 66,\n",
       " '•': 84,\n",
       " '●': 87,\n",
       " 'ﬁ': 88}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'UNK',\n",
       " 1: ' ',\n",
       " 2: '\\t',\n",
       " 3: '\\n',\n",
       " 4: 'C',\n",
       " 5: 'l',\n",
       " 6: 'a',\n",
       " 7: 'i',\n",
       " 8: 'm',\n",
       " 9: 'T',\n",
       " 10: 'y',\n",
       " 11: 'p',\n",
       " 12: 'e',\n",
       " 13: ':',\n",
       " 14: 'V',\n",
       " 15: 'B',\n",
       " 16: 'A',\n",
       " 17: 'c',\n",
       " 18: 'd',\n",
       " 19: 'n',\n",
       " 20: 't',\n",
       " 21: '-',\n",
       " 22: 'I',\n",
       " 23: 'j',\n",
       " 24: 'u',\n",
       " 25: 'r',\n",
       " 26: 'P',\n",
       " 27: 'o',\n",
       " 28: 'h',\n",
       " 29: '/',\n",
       " 30: 'O',\n",
       " 31: 'w',\n",
       " 32: 'f',\n",
       " 33: 'F',\n",
       " 34: 's',\n",
       " 35: 'N',\n",
       " 36: 'M',\n",
       " 37: 'L',\n",
       " 38: 'S',\n",
       " 39: 'b',\n",
       " 40: 'D',\n",
       " 41: 'G',\n",
       " 42: 'g',\n",
       " 43: '1',\n",
       " 44: 'v',\n",
       " 45: 'E',\n",
       " 46: 'R',\n",
       " 47: 'Y',\n",
       " 48: '.',\n",
       " 49: 'U',\n",
       " 50: 'K',\n",
       " 51: 'W',\n",
       " 52: 'H',\n",
       " 53: '2',\n",
       " 54: '0',\n",
       " 55: '6',\n",
       " 56: '4',\n",
       " 57: '3',\n",
       " 58: 'q',\n",
       " 59: 'k',\n",
       " 60: '?',\n",
       " 61: '8',\n",
       " 62: 'x',\n",
       " 63: 'z',\n",
       " 64: '(',\n",
       " 65: ')',\n",
       " 66: '’',\n",
       " 67: '#',\n",
       " 68: 'J',\n",
       " 69: ',',\n",
       " 70: '7',\n",
       " 71: 'Z',\n",
       " 72: '9',\n",
       " 73: '&',\n",
       " 74: '5',\n",
       " 75: ';',\n",
       " 76: '+',\n",
       " 77: '*',\n",
       " 78: 'Q',\n",
       " 79: 'X',\n",
       " 80: '$',\n",
       " 81: '@',\n",
       " 82: '|',\n",
       " 83: \"'\",\n",
       " 84: '•',\n",
       " 85: '%',\n",
       " 86: '^',\n",
       " 87: '●',\n",
       " 88: 'ﬁ',\n",
       " 89: '=',\n",
       " 90: '_'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(int_to_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize char data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data, decoder_input_data, decoder_target_data = vectorize_char_data(input_texts=input_texts,\n",
    "                                                                             target_texts=target_texts, \n",
    "                                                                             max_encoder_seq_length=max_encoder_seq_length, \n",
    "                                                                             num_encoder_tokens=num_encoder_tokens, \n",
    "                                                                             vocab_to_int=vocab_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build char model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 91)     8281        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) [(None, None, 512),  712704      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 91)     8281        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           bidirectional_1[0][1]            \n",
      "                                                                 bidirectional_1[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 512)          0           bidirectional_1[0][2]            \n",
      "                                                                 bidirectional_1[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 512),  1236992     embedding_2[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, None, None)   0           lstm_2[0][0]                     \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention (Activation)          (None, None, None)   0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, None, 512)    0           attention[0][0]                  \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, 1024)   0           dot_2[0][0]                      \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 91)     93275       concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,059,533\n",
      "Trainable params: 2,042,971\n",
      "Non-trainable params: 16,562\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:63: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "model, encoder_model, decoder_model = build_char_model(latent_dim=latent_dim, num_encoder_tokens=num_encoder_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit char model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/10\n",
      "3200/3200 [==============================] - 19s 6ms/step - loss: 3.3914 - categorical_accuracy: 0.1495 - val_loss: 3.0492 - val_categorical_accuracy: 0.1974\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.19740, saving model to best_model_char-50.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/keras/engine/network.py:872: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'concatenate_1/concat:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'concatenate_2/concat:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "3200/3200 [==============================] - 18s 5ms/step - loss: 2.5318 - categorical_accuracy: 0.2866 - val_loss: 2.3661 - val_categorical_accuracy: 0.3097\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.19740 to 0.30966, saving model to best_model_char-50.hdf5\n",
      "Epoch 3/10\n",
      "3200/3200 [==============================] - 18s 5ms/step - loss: 1.9284 - categorical_accuracy: 0.4297 - val_loss: 2.0300 - val_categorical_accuracy: 0.4166\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.30966 to 0.41655, saving model to best_model_char-50.hdf5\n",
      "Epoch 4/10\n",
      "3200/3200 [==============================] - 18s 6ms/step - loss: 1.4112 - categorical_accuracy: 0.5787 - val_loss: 1.6053 - val_categorical_accuracy: 0.5296\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy improved from 0.41655 to 0.52956, saving model to best_model_char-50.hdf5\n",
      "Epoch 5/10\n",
      "3200/3200 [==============================] - 18s 5ms/step - loss: 0.9256 - categorical_accuracy: 0.7185 - val_loss: 1.2236 - val_categorical_accuracy: 0.6367\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.52956 to 0.63668, saving model to best_model_char-50.hdf5\n",
      "Epoch 6/10\n",
      "3200/3200 [==============================] - 18s 5ms/step - loss: 0.5739 - categorical_accuracy: 0.8129 - val_loss: 0.8647 - val_categorical_accuracy: 0.7291\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy improved from 0.63668 to 0.72910, saving model to best_model_char-50.hdf5\n",
      "Epoch 7/10\n",
      "3200/3200 [==============================] - 18s 5ms/step - loss: 0.3416 - categorical_accuracy: 0.8729 - val_loss: 0.6416 - val_categorical_accuracy: 0.7841\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.72910 to 0.78410, saving model to best_model_char-50.hdf5\n",
      "Epoch 8/10\n",
      "3200/3200 [==============================] - 18s 6ms/step - loss: 0.2195 - categorical_accuracy: 0.9034 - val_loss: 0.5072 - val_categorical_accuracy: 0.8153\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy improved from 0.78410 to 0.81528, saving model to best_model_char-50.hdf5\n",
      "Epoch 9/10\n",
      "3200/3200 [==============================] - 18s 5ms/step - loss: 0.1512 - categorical_accuracy: 0.9207 - val_loss: 0.4264 - val_categorical_accuracy: 0.8358\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy improved from 0.81528 to 0.83579, saving model to best_model_char-50.hdf5\n",
      "Epoch 10/10\n",
      "3200/3200 [==============================] - 18s 6ms/step - loss: 0.1042 - categorical_accuracy: 0.9330 - val_loss: 0.3393 - val_categorical_accuracy: 0.8610\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy improved from 0.83579 to 0.86095, saving model to best_model_char-50.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f55585e2c18>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 10  \n",
    "lr = 0.01\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(lr=lr), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "#filepath=\"weights-improvement-{epoch:02d}-{val_categorical_accuracy:.2f}.hdf5\"\n",
    "filepath=\"best_model_char-{}.hdf5\".format(max_sent_len) # Save only the best model for inference step, as saving the epoch and metric might confuse the inference function which model to use\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "tbCallBack = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "callbacks_list = [checkpoint, tbCallBack]\n",
    "#callbacks_list = [checkpoint, tbCallBack, lrate]\n",
    "\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          #validation_data = ([test_encoder_input_data, test_decoder_input_data], test_decoder_target_data),\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_split=0.2,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/keras/engine/network.py:872: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'input_9:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'input_10:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "encoder_char_model_file = 'encoder_char_model-{}.hdf5'\n",
    "decoder_char_model_file = 'decoder_char_model-{}.hdf5'\n",
    "encoder_model.save('encoder_char_model-{}.hdf5'.format(max_sent_len))\n",
    "decoder_model.save('decoder_char_model-{}.hdf5'.format(max_sent_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Hierarichal model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build word vocab (target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words_seq_len=15\n",
    "max_chars_seq_len=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = target_texts\n",
    "vocab_to_int, int_to_vocab = build_words_vocab(all_texts)\n",
    "word2int = vocab_to_int\n",
    "int2word = int_to_vocab\n",
    "np.savez('vocab_hier-{}-{}'.format(max_words_seq_len, max_chars_seq_len), char2int=char2int, int2char=int2char, word2int=word2int, int2word=int2word, max_words_seq_len=max_words_seq_len, max_char_seq_len=max_chars_seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t': 2,\n",
       " '\\n': 3,\n",
       " ' ': 1,\n",
       " '&': 175,\n",
       " \"'re\": 652,\n",
       " \"'s\": 303,\n",
       " 'UNK': 0,\n",
       " 'aadc': 624,\n",
       " 'abd': 296,\n",
       " 'abnormality': 55,\n",
       " 'acc': 119,\n",
       " 'access': 482,\n",
       " 'accession': 35,\n",
       " 'accident': 7,\n",
       " 'accidental': 8,\n",
       " 'account': 129,\n",
       " 'accountability': 497,\n",
       " 'accounting': 628,\n",
       " 'acct': 390,\n",
       " 'acetaminophen': 714,\n",
       " 'act': 498,\n",
       " 'active': 328,\n",
       " 'actual': 447,\n",
       " 'acute': 53,\n",
       " 'additional': 421,\n",
       " 'address': 23,\n",
       " 'adjust': 212,\n",
       " 'adjustment': 150,\n",
       " 'administrators': 225,\n",
       " 'advice': 552,\n",
       " 'advise': 684,\n",
       " 'aid': 749,\n",
       " 'albuterol': 715,\n",
       " 'allergies': 323,\n",
       " 'allergy': 342,\n",
       " 'allowed': 151,\n",
       " 'allstate': 639,\n",
       " 'amount': 152,\n",
       " 'amounts': 148,\n",
       " 'amoxicillin': 324,\n",
       " 'anion': 361,\n",
       " 'ankle': 489,\n",
       " 'appeal': 163,\n",
       " 'appeals': 160,\n",
       " 'appearance': 597,\n",
       " 'applic': 202,\n",
       " 'application': 746,\n",
       " 'approval': 740,\n",
       " 'april': 398,\n",
       " 'arm': 559,\n",
       " 'arms': 410,\n",
       " 'arthiscopic': 91,\n",
       " 'asleep': 574,\n",
       " 'assist': 509,\n",
       " 'atlanta': 622,\n",
       " 'attendant': 271,\n",
       " 'attending': 440,\n",
       " 'authority': 677,\n",
       " 'automated': 270,\n",
       " 'availabie': 48,\n",
       " 'available': 50,\n",
       " 'ave': 493,\n",
       " 'awakened': 584,\n",
       " 'b': 460,\n",
       " 'back': 285,\n",
       " 'baker': 618,\n",
       " 'balance': 215,\n",
       " 'banks': 502,\n",
       " 'bartruff': 516,\n",
       " 'basic': 349,\n",
       " 'becomes': 417,\n",
       " 'bedford': 608,\n",
       " 'behalf': 607,\n",
       " 'behaviors': 598,\n",
       " 'benefit': 122,\n",
       " 'benefits': 104,\n",
       " 'best': 485,\n",
       " 'better': 592,\n",
       " 'billed': 147,\n",
       " 'billing': 221,\n",
       " 'birth': 18,\n",
       " 'black': 179,\n",
       " 'bldg': 610,\n",
       " 'blvd': 518,\n",
       " 'bmi': 710,\n",
       " 'body': 587,\n",
       " 'bp': 703,\n",
       " 'bpm': 706,\n",
       " 'brainard': 258,\n",
       " 'bravo': 142,\n",
       " 'bridgeport': 494,\n",
       " 'bruce': 432,\n",
       " 'bruising': 553,\n",
       " 'bulk': 716,\n",
       " 'bun': 356,\n",
       " 'business': 83,\n",
       " 'caitlen': 657,\n",
       " 'calc': 363,\n",
       " 'calcium': 358,\n",
       " 'call': 274,\n",
       " 'cardholder': 745,\n",
       " 'care': 547,\n",
       " 'caregiver': 601,\n",
       " 'carrier': 156,\n",
       " 'carroll': 658,\n",
       " 'cast': 208,\n",
       " 'cbc': 364,\n",
       " 'cellular': 659,\n",
       " 'center': 105,\n",
       " 'central': 644,\n",
       " 'changes': 576,\n",
       " 'chappaqua': 612,\n",
       " 'charge': 210,\n",
       " 'charges': 289,\n",
       " 'check': 458,\n",
       " 'checks': 219,\n",
       " 'chest': 299,\n",
       " 'chief': 529,\n",
       " 'child': 178,\n",
       " 'childrens': 341,\n",
       " 'chloride': 354,\n",
       " 'choice': 223,\n",
       " 'christopher': 515,\n",
       " 'cincinnati': 632,\n",
       " 'city': 25,\n",
       " 'cl': 507,\n",
       " 'claim': 4,\n",
       " 'claimant': 480,\n",
       " 'clinical': 702,\n",
       " 'clinton': 645,\n",
       " 'clo': 191,\n",
       " 'clumsiness': 582,\n",
       " 'cnp': 311,\n",
       " 'code': 27,\n",
       " 'collier': 526,\n",
       " 'comments': 535,\n",
       " 'commercial': 293,\n",
       " 'communicable': 505,\n",
       " 'comp': 701,\n",
       " 'comparison': 49,\n",
       " 'complaint': 264,\n",
       " 'completed': 442,\n",
       " 'compliance': 259,\n",
       " 'computer': 606,\n",
       " 'concussion': 435,\n",
       " 'condition': 664,\n",
       " 'conditions': 380,\n",
       " 'confinement': 666,\n",
       " 'confirmation': 112,\n",
       " 'confusion': 580,\n",
       " 'conrad': 437,\n",
       " 'cons': 197,\n",
       " 'considerations': 475,\n",
       " 'contact': 165,\n",
       " 'contents': 479,\n",
       " 'continued': 450,\n",
       " 'contract': 149,\n",
       " 'contrast': 139,\n",
       " 'contusion': 545,\n",
       " 'copy': 752,\n",
       " 'cormarison': 46,\n",
       " 'cough': 314,\n",
       " 'country': 28,\n",
       " 'county': 616,\n",
       " 'coverage': 113,\n",
       " 'covered': 153,\n",
       " 'cpt': 456,\n",
       " 'crea': 359,\n",
       " 'creatinine': 357,\n",
       " 'ct': 295,\n",
       " 'current': 213,\n",
       " 'customer': 115,\n",
       " 'dakota': 266,\n",
       " 'dallas': 654,\n",
       " 'dan': 173,\n",
       " 'date': 19,\n",
       " 'dates': 667,\n",
       " 'david': 431,\n",
       " 'day': 67,\n",
       " 'days': 214,\n",
       " 'daytime': 57,\n",
       " 'dea': 236,\n",
       " 'dear': 536,\n",
       " 'deductible': 155,\n",
       " 'deduction': 128,\n",
       " 'degree': 457,\n",
       " 'delivery': 446,\n",
       " 'departmant': 754,\n",
       " 'department': 262,\n",
       " 'dependent': 143,\n",
       " 'description': 186,\n",
       " 'detail': 144,\n",
       " 'details': 284,\n",
       " 'dev': 393,\n",
       " 'devin': 436,\n",
       " 'diagnoses': 329,\n",
       " 'diagnosis': 429,\n",
       " 'diff': 365,\n",
       " 'digit': 301,\n",
       " 'digitech': 605,\n",
       " 'dilantin': 717,\n",
       " 'directed': 420,\n",
       " 'disability': 466,\n",
       " 'discharge': 89,\n",
       " 'disease': 506,\n",
       " 'dizziness': 334,\n",
       " 'dob': 41,\n",
       " 'document': 384,\n",
       " 'doesn': 590,\n",
       " 'domestic': 662,\n",
       " 'due': 183,\n",
       " 'e': 187,\n",
       " 'east': 396,\n",
       " 'eastside': 389,\n",
       " 'ed': 528,\n",
       " 'education': 540,\n",
       " 'ee': 116,\n",
       " 'effective': 117,\n",
       " 'electronic': 95,\n",
       " 'electronically': 98,\n",
       " 'email': 29,\n",
       " 'emergency': 521,\n",
       " 'emerson': 82,\n",
       " 'employee': 118,\n",
       " 'employer': 93,\n",
       " 'employment': 92,\n",
       " 'ems': 514,\n",
       " 'english': 308,\n",
       " 'entities': 504,\n",
       " 'estab': 728,\n",
       " 'estimado': 538,\n",
       " 'estimated': 730,\n",
       " 'ethnicity': 304,\n",
       " 'event': 59,\n",
       " 'exam': 131,\n",
       " 'excuse': 395,\n",
       " 'expected': 445,\n",
       " 'experience': 279,\n",
       " 'explanation': 243,\n",
       " 'express': 734,\n",
       " 'ext': 651,\n",
       " 'extremity': 544,\n",
       " 'ez': 267,\n",
       " 'f': 130,\n",
       " 'facility': 451,\n",
       " 'falling': 573,\n",
       " 'family': 246,\n",
       " 'fax': 85,\n",
       " 'faxed': 141,\n",
       " 'february': 647,\n",
       " 'feel': 408,\n",
       " 'feeling': 532,\n",
       " 'female': 477,\n",
       " 'fiberglass': 206,\n",
       " 'filing': 459,\n",
       " 'findings': 51,\n",
       " 'finger': 194,\n",
       " 'first': 11,\n",
       " 'fl': 371,\n",
       " 'floor': 611,\n",
       " 'florida': 630,\n",
       " 'fmla': 106,\n",
       " 'folder': 478,\n",
       " 'follow': 418,\n",
       " 'following': 406,\n",
       " 'foot': 725,\n",
       " 'forearm': 205,\n",
       " 'form': 439,\n",
       " 'forms': 265,\n",
       " 'forwarding': 226,\n",
       " 'fraud': 100,\n",
       " 'frontal': 331,\n",
       " 'ft': 709,\n",
       " 'ga': 623,\n",
       " 'gabapentin': 718,\n",
       " 'gap': 362,\n",
       " 'gauntlet': 207,\n",
       " 'gelovich': 135,\n",
       " 'gender': 20,\n",
       " 'general': 589,\n",
       " 'get': 591,\n",
       " 'gets': 554,\n",
       " 'giddiness': 335,\n",
       " 'given': 426,\n",
       " 'glucose': 355,\n",
       " 'good': 641,\n",
       " 'governmental': 503,\n",
       " 'granting': 676,\n",
       " 'gregory': 508,\n",
       " 'grogginess': 571,\n",
       " 'group': 114,\n",
       " 'hand': 203,\n",
       " 'hands': 642,\n",
       " 'harges': 300,\n",
       " 'hct': 369,\n",
       " 'headache': 563,\n",
       " 'health': 224,\n",
       " 'healthcare': 522,\n",
       " 'help': 534,\n",
       " 'hgb': 368,\n",
       " 'hills': 180,\n",
       " 'hipaa': 499,\n",
       " 'hippa': 694,\n",
       " 'hispanic': 305,\n",
       " 'hives': 327,\n",
       " 'holder': 699,\n",
       " 'home': 546,\n",
       " 'hospital': 40,\n",
       " 'hospitalization': 88,\n",
       " 'hospitals': 474,\n",
       " 'hours': 65,\n",
       " 'however': 537,\n",
       " 'hr': 320,\n",
       " 'http': 348,\n",
       " 'https': 614,\n",
       " 'humalog': 719,\n",
       " 'human': 263,\n",
       " 'hunington': 736,\n",
       " 'huntingdon': 698,\n",
       " 'ia': 646,\n",
       " 'icd': 443,\n",
       " 'icd=cc': 530,\n",
       " 'id': 232,\n",
       " 'identified': 56,\n",
       " 'identifier': 97,\n",
       " 'identiﬁer': 433,\n",
       " 'idiopathic': 382,\n",
       " 'illumigene': 346,\n",
       " 'important': 162,\n",
       " 'impression': 52,\n",
       " 'improved': 277,\n",
       " 'inability': 583,\n",
       " 'inc': 230,\n",
       " 'include': 330,\n",
       " 'including': 678,\n",
       " 'increase': 413,\n",
       " 'increased': 594,\n",
       " 'indicated': 672,\n",
       " 'indicator': 75,\n",
       " 'individual': 237,\n",
       " 'info': 282,\n",
       " 'information': 10,\n",
       " 'injured': 558,\n",
       " 'injury': 9,\n",
       " 'ins': 185,\n",
       " 'instructions': 428,\n",
       " 'insur': 290,\n",
       " 'insurance': 469,\n",
       " 'insured': 108,\n",
       " 'internal': 688,\n",
       " 'interpreters': 255,\n",
       " 'inthalangsy': 650,\n",
       " 'invoice': 615,\n",
       " 'jacksonville': 653,\n",
       " 'jacquelin': 257,\n",
       " 'jager': 146,\n",
       " 'january': 120,\n",
       " 'jasminder': 391,\n",
       " 'jason': 635,\n",
       " 'johnson': 492,\n",
       " 'june': 434,\n",
       " 'kari': 170,\n",
       " 'karl': 248,\n",
       " 'keep': 386,\n",
       " 'kg': 317,\n",
       " 'knee': 430,\n",
       " 'know': 166,\n",
       " 'l': 679,\n",
       " 'label': 747,\n",
       " 'labs': 345,\n",
       " 'lamictal': 720,\n",
       " 'language': 21,\n",
       " 'languages': 164,\n",
       " 'last': 14,\n",
       " 'latino': 306,\n",
       " 'law': 513,\n",
       " 'lbs': 316,\n",
       " 'leaflets': 604,\n",
       " 'left': 44,\n",
       " 'legs': 411,\n",
       " 'lesser': 680,\n",
       " 'lethargy': 313,\n",
       " 'letter': 627,\n",
       " 'life': 468,\n",
       " 'light': 567,\n",
       " 'line': 24,\n",
       " 'list': 337,\n",
       " 'llc': 732,\n",
       " 'lmp': 711,\n",
       " 'location': 696,\n",
       " 'lockbox': 620,\n",
       " 'long': 467,\n",
       " 'loss': 579,\n",
       " 'lower': 204,\n",
       " 'lumbosacral': 415,\n",
       " 'lund': 171,\n",
       " 'lymphocytes': 378,\n",
       " 'lyrica': 721,\n",
       " 'm': 188,\n",
       " 'mail': 261,\n",
       " 'make': 218,\n",
       " 'male': 476,\n",
       " 'management': 631,\n",
       " 'marco': 619,\n",
       " 'materials': 541,\n",
       " 'may': 176,\n",
       " 'mch': 372,\n",
       " 'mchc': 374,\n",
       " 'mcv': 370,\n",
       " 'md': 690,\n",
       " 'med': 733,\n",
       " 'medexpress': 691,\n",
       " 'medical': 77,\n",
       " 'medication': 336,\n",
       " 'medications': 338,\n",
       " 'medicine': 689,\n",
       " 'meds': 713,\n",
       " 'medsupport': 660,\n",
       " 'member': 673,\n",
       " 'memory': 578,\n",
       " 'merchant': 737,\n",
       " 'message': 217,\n",
       " 'met': 729,\n",
       " 'metabolic': 350,\n",
       " 'mi': 462,\n",
       " 'middle': 13,\n",
       " 'min': 726,\n",
       " 'mini': 201,\n",
       " 'missed': 69,\n",
       " 'mmhg': 704,\n",
       " 'moderat': 190,\n",
       " 'moderate': 198,\n",
       " 'modifiers': 250,\n",
       " 'monica': 490,\n",
       " 'monocytes': 379,\n",
       " 'monthly': 124,\n",
       " 'montly': 126,\n",
       " 'motor': 471,\n",
       " 'mpv': 375,\n",
       " 'mr': 401,\n",
       " 'mri': 137,\n",
       " 'mrn': 34,\n",
       " 'mso': 731,\n",
       " 'myco': 347,\n",
       " 'n': 617,\n",
       " 'name': 12,\n",
       " 'napies': 524,\n",
       " 'naples': 519,\n",
       " 'nausea': 564,\n",
       " 'nch': 520,\n",
       " 'neck': 586,\n",
       " 'network': 247,\n",
       " 'neurontin': 722,\n",
       " 'neutrophils': 377,\n",
       " 'new': 189,\n",
       " 'newsom': 310,\n",
       " 'next': 87,\n",
       " 'noise': 568,\n",
       " 'non': 294,\n",
       " 'none': 47,\n",
       " 'north': 525,\n",
       " 'northeast': 527,\n",
       " 'northhuntingdon': 755,\n",
       " 'norwin': 697,\n",
       " 'note': 549,\n",
       " 'notes': 343,\n",
       " 'number': 17,\n",
       " 'numbers': 531,\n",
       " 'numbness': 556,\n",
       " 'ny': 613,\n",
       " 'occurs': 407,\n",
       " 'offic': 196,\n",
       " 'office': 648,\n",
       " 'officer': 260,\n",
       " 'oh': 633,\n",
       " 'online': 278,\n",
       " 'original': 233,\n",
       " 'orthopedic': 168,\n",
       " 'orthopedist': 172,\n",
       " 'osseous': 54,\n",
       " 'otherwise': 511,\n",
       " 'outpatient': 76,\n",
       " 'owner': 388,\n",
       " 'oxygen': 321,\n",
       " 'pa': 394,\n",
       " 'paciente': 539,\n",
       " 'page': 30,\n",
       " 'paid': 157,\n",
       " 'pain': 414,\n",
       " 'palmer': 174,\n",
       " 'paper': 424,\n",
       " 'parents': 550,\n",
       " 'park': 517,\n",
       " 'part': 441,\n",
       " 'participant': 231,\n",
       " 'partner': 663,\n",
       " 'pat': 211,\n",
       " 'patient': 33,\n",
       " 'patrick': 81,\n",
       " 'pay': 269,\n",
       " 'payable': 220,\n",
       " 'payment': 298,\n",
       " 'payments': 272,\n",
       " 'payroll': 127,\n",
       " 'pc': 181,\n",
       " 'peds': 542,\n",
       " 'pelv': 297,\n",
       " 'pending': 216,\n",
       " 'per': 449,\n",
       " 'performed': 454,\n",
       " 'period': 241,\n",
       " 'permitted': 512,\n",
       " 'person': 675,\n",
       " 'personality': 575,\n",
       " 'pg': 373,\n",
       " 'ph': 400,\n",
       " 'phalangealfx': 193,\n",
       " 'phone': 58,\n",
       " 'phycian': 670,\n",
       " 'phys': 133,\n",
       " 'physically': 63,\n",
       " 'physician': 37,\n",
       " 'physicians': 473,\n",
       " 'pip': 643,\n",
       " 'plan': 239,\n",
       " 'plantation': 638,\n",
       " 'platelets': 376,\n",
       " 'please': 273,\n",
       " 'pm': 665,\n",
       " 'pmp': 712,\n",
       " 'pmt': 182,\n",
       " 'pocket': 242,\n",
       " 'policies': 661,\n",
       " 'policy': 94,\n",
       " 'policyholder': 387,\n",
       " 'possible': 326,\n",
       " 'postal': 26,\n",
       " 'potassium': 353,\n",
       " 'preference': 22,\n",
       " 'preferred': 307,\n",
       " 'premium': 125,\n",
       " 'prescriber': 423,\n",
       " 'prescription': 425,\n",
       " 'prescriptions': 422,\n",
       " 'preventative': 427,\n",
       " 'primary': 402,\n",
       " 'print': 234,\n",
       " 'printed': 111,\n",
       " 'privacy': 500,\n",
       " 'probihited': 484,\n",
       " 'problem': 381,\n",
       " 'proc': 287,\n",
       " 'procedure': 90,\n",
       " 'procedures': 724,\n",
       " 'processing': 621,\n",
       " 'prohibited': 510,\n",
       " 'provide': 681,\n",
       " 'provided': 603,\n",
       " 'provider': 78,\n",
       " 'pulse': 705,\n",
       " 'purchase': 739,\n",
       " 'purposes': 245,\n",
       " 'qualified': 253,\n",
       " 'questions': 222,\n",
       " 'rad': 200,\n",
       " 'radiology': 31,\n",
       " 'range': 352,\n",
       " 'rash': 325,\n",
       " 'ratio': 360,\n",
       " 'rbc': 367,\n",
       " 'rd': 609,\n",
       " 're': 625,\n",
       " 'reach': 486,\n",
       " 'reason': 154,\n",
       " 'receipt': 276,\n",
       " 'record': 741,\n",
       " 'ref': 36,\n",
       " 'reference': 744,\n",
       " 'referring': 132,\n",
       " 'regional': 229,\n",
       " 'related': 71,\n",
       " 'relationship': 674,\n",
       " 'released': 602,\n",
       " 'report': 32,\n",
       " 'request': 656,\n",
       " 'requested': 228,\n",
       " 'requests': 107,\n",
       " 'required': 74,\n",
       " 'resp': 707,\n",
       " 'responsibility': 158,\n",
       " 'results': 140,\n",
       " 'retain': 244,\n",
       " 'return': 487,\n",
       " 'returned': 70,\n",
       " 'reviewed': 102,\n",
       " 'rights': 161,\n",
       " 'roles': 79,\n",
       " 'route': 693,\n",
       " 'rt': 252,\n",
       " 'rule': 501,\n",
       " 'sales': 751,\n",
       " 'santana': 636,\n",
       " 'sat': 322,\n",
       " 'scheduled': 68,\n",
       " 'school': 600,\n",
       " 'security': 16,\n",
       " 'see': 283,\n",
       " 'seek': 551,\n",
       " 'seizures': 588,\n",
       " 'send': 753,\n",
       " 'sensitivity': 566,\n",
       " 'september': 438,\n",
       " 'service': 227,\n",
       " 'services': 249,\n",
       " 'sever': 199,\n",
       " 'severe': 412,\n",
       " 'sex': 700,\n",
       " 'shaffer': 491,\n",
       " 'short': 464,\n",
       " 'show': 286,\n",
       " 'sick': 596,\n",
       " 'side': 397,\n",
       " 'sign': 254,\n",
       " 'signature': 110,\n",
       " 'signed': 99,\n",
       " 'sincerely': 637,\n",
       " 'singh': 392,\n",
       " 'sinusitis': 332,\n",
       " 'sleepiness': 570,\n",
       " 'socia': 695,\n",
       " 'social': 15,\n",
       " 'sodium': 351,\n",
       " 'southwest': 629,\n",
       " 'spanish': 463,\n",
       " 'special': 548,\n",
       " 'specially': 687,\n",
       " 'specialty': 167,\n",
       " 'specifics': 655,\n",
       " 'spine': 292,\n",
       " 'splint': 195,\n",
       " 'spouse': 177,\n",
       " 'sprained': 488,\n",
       " 'state': 452,\n",
       " 'statement': 184,\n",
       " 'statements': 101,\n",
       " 'status': 240,\n",
       " 'stephen': 134,\n",
       " 'stiff': 585,\n",
       " 'stop': 685,\n",
       " 'stopped': 60,\n",
       " 'strain': 404,\n",
       " 'strained': 405,\n",
       " 'strictly': 483,\n",
       " 'study': 39,\n",
       " 'submission': 96,\n",
       " 'subtotal': 750,\n",
       " 'suffix': 461,\n",
       " 'suicidal': 533,\n",
       " 'summary': 238,\n",
       " 'surgeon': 169,\n",
       " 'surgery': 73,\n",
       " 'surgical': 455,\n",
       " 'suzanne': 309,\n",
       " 'swelling': 595,\n",
       " 'symptoms': 562,\n",
       " 'system': 523,\n",
       " 'take': 419,\n",
       " 'taking': 339,\n",
       " 'tax': 136,\n",
       " 'tc': 251,\n",
       " 'technique': 42,\n",
       " 'telephone': 84,\n",
       " 'temp': 319,\n",
       " 'teri': 668,\n",
       " 'term': 465,\n",
       " 'tests': 344,\n",
       " 'th_ar_ltr': 634,\n",
       " 'tha': 682,\n",
       " 'thirty': 626,\n",
       " 'thorac': 291,\n",
       " 'thoracic': 403,\n",
       " 'three': 727,\n",
       " 'time': 72,\n",
       " 'tingling': 557,\n",
       " 'today': 302,\n",
       " 'todays': 756,\n",
       " 'total': 123,\n",
       " 'totals': 159,\n",
       " 'trace': 743,\n",
       " 'transaction': 738,\n",
       " 'trauma': 560,\n",
       " 'treating': 80,\n",
       " 'treatment': 683,\n",
       " 'trouble': 572,\n",
       " 'tvr': 748,\n",
       " 'tx': 192,\n",
       " 'type': 5,\n",
       " 'uc': 735,\n",
       " 'unable': 444,\n",
       " 'unauthorized': 481,\n",
       " 'units': 288,\n",
       " 'unknown': 38,\n",
       " 'unspecified': 333,\n",
       " 'unum': 103,\n",
       " 'unusual': 569,\n",
       " 'update': 281,\n",
       " 'upon': 275,\n",
       " 'upper': 543,\n",
       " 'urgent': 692,\n",
       " 'urticaria': 383,\n",
       " 'us': 496,\n",
       " 'vaginal': 448,\n",
       " 'valacyclovir': 723,\n",
       " 'vb': 6,\n",
       " 'vehicle': 472,\n",
       " 'views': 43,\n",
       " 'violation': 671,\n",
       " 'visa': 742,\n",
       " 'vision': 577,\n",
       " 'visit': 86,\n",
       " 'vitals': 315,\n",
       " 'voluntary': 470,\n",
       " 'vomiting': 565,\n",
       " 'vyphaphone': 649,\n",
       " 'walking': 581,\n",
       " 'watch': 561,\n",
       " 'ways': 268,\n",
       " 'wbc': 366,\n",
       " 'weak': 416,\n",
       " 'weakness': 409,\n",
       " 'website': 235,\n",
       " 'weekly': 399,\n",
       " 'weigth': 708,\n",
       " 'wellness': 121,\n",
       " 'willochel': 686,\n",
       " 'willochell': 669,\n",
       " 'wish': 385,\n",
       " 'without': 138,\n",
       " 'work': 64,\n",
       " 'worked': 66,\n",
       " 'working': 61,\n",
       " 'worry': 599,\n",
       " 'worse': 555,\n",
       " 'worsens': 593,\n",
       " 'wrist': 45,\n",
       " 'written': 256,\n",
       " 'wt': 318,\n",
       " 'wv': 495,\n",
       " 'yes': 62,\n",
       " 'youre': 640,\n",
       " 'yrs': 209,\n",
       " 'zachary': 145,\n",
       " 'zip': 453,\n",
       " 'zyrtec': 340,\n",
       " '|': 280,\n",
       " '’': 109,\n",
       " '•': 312}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'UNK',\n",
       " 1: ' ',\n",
       " 2: '\\t',\n",
       " 3: '\\n',\n",
       " 4: 'claim',\n",
       " 5: 'type',\n",
       " 6: 'vb',\n",
       " 7: 'accident',\n",
       " 8: 'accidental',\n",
       " 9: 'injury',\n",
       " 10: 'information',\n",
       " 11: 'first',\n",
       " 12: 'name',\n",
       " 13: 'middle',\n",
       " 14: 'last',\n",
       " 15: 'social',\n",
       " 16: 'security',\n",
       " 17: 'number',\n",
       " 18: 'birth',\n",
       " 19: 'date',\n",
       " 20: 'gender',\n",
       " 21: 'language',\n",
       " 22: 'preference',\n",
       " 23: 'address',\n",
       " 24: 'line',\n",
       " 25: 'city',\n",
       " 26: 'postal',\n",
       " 27: 'code',\n",
       " 28: 'country',\n",
       " 29: 'email',\n",
       " 30: 'page',\n",
       " 31: 'radiology',\n",
       " 32: 'report',\n",
       " 33: 'patient',\n",
       " 34: 'mrn',\n",
       " 35: 'accession',\n",
       " 36: 'ref',\n",
       " 37: 'physician',\n",
       " 38: 'unknown',\n",
       " 39: 'study',\n",
       " 40: 'hospital',\n",
       " 41: 'dob',\n",
       " 42: 'technique',\n",
       " 43: 'views',\n",
       " 44: 'left',\n",
       " 45: 'wrist',\n",
       " 46: 'cormarison',\n",
       " 47: 'none',\n",
       " 48: 'availabie',\n",
       " 49: 'comparison',\n",
       " 50: 'available',\n",
       " 51: 'findings',\n",
       " 52: 'impression',\n",
       " 53: 'acute',\n",
       " 54: 'osseous',\n",
       " 55: 'abnormality',\n",
       " 56: 'identified',\n",
       " 57: 'daytime',\n",
       " 58: 'phone',\n",
       " 59: 'event',\n",
       " 60: 'stopped',\n",
       " 61: 'working',\n",
       " 62: 'yes',\n",
       " 63: 'physically',\n",
       " 64: 'work',\n",
       " 65: 'hours',\n",
       " 66: 'worked',\n",
       " 67: 'day',\n",
       " 68: 'scheduled',\n",
       " 69: 'missed',\n",
       " 70: 'returned',\n",
       " 71: 'related',\n",
       " 72: 'time',\n",
       " 73: 'surgery',\n",
       " 74: 'required',\n",
       " 75: 'indicator',\n",
       " 76: 'outpatient',\n",
       " 77: 'medical',\n",
       " 78: 'provider',\n",
       " 79: 'roles',\n",
       " 80: 'treating',\n",
       " 81: 'patrick',\n",
       " 82: 'emerson',\n",
       " 83: 'business',\n",
       " 84: 'telephone',\n",
       " 85: 'fax',\n",
       " 86: 'visit',\n",
       " 87: 'next',\n",
       " 88: 'hospitalization',\n",
       " 89: 'discharge',\n",
       " 90: 'procedure',\n",
       " 91: 'arthiscopic',\n",
       " 92: 'employment',\n",
       " 93: 'employer',\n",
       " 94: 'policy',\n",
       " 95: 'electronic',\n",
       " 96: 'submission',\n",
       " 97: 'identifier',\n",
       " 98: 'electronically',\n",
       " 99: 'signed',\n",
       " 100: 'fraud',\n",
       " 101: 'statements',\n",
       " 102: 'reviewed',\n",
       " 103: 'unum',\n",
       " 104: 'benefits',\n",
       " 105: 'center',\n",
       " 106: 'fmla',\n",
       " 107: 'requests',\n",
       " 108: 'insured',\n",
       " 109: '’',\n",
       " 110: 'signature',\n",
       " 111: 'printed',\n",
       " 112: 'confirmation',\n",
       " 113: 'coverage',\n",
       " 114: 'group',\n",
       " 115: 'customer',\n",
       " 116: 'ee',\n",
       " 117: 'effective',\n",
       " 118: 'employee',\n",
       " 119: 'acc',\n",
       " 120: 'january',\n",
       " 121: 'wellness',\n",
       " 122: 'benefit',\n",
       " 123: 'total',\n",
       " 124: 'monthly',\n",
       " 125: 'premium',\n",
       " 126: 'montly',\n",
       " 127: 'payroll',\n",
       " 128: 'deduction',\n",
       " 129: 'account',\n",
       " 130: 'f',\n",
       " 131: 'exam',\n",
       " 132: 'referring',\n",
       " 133: 'phys',\n",
       " 134: 'stephen',\n",
       " 135: 'gelovich',\n",
       " 136: 'tax',\n",
       " 137: 'mri',\n",
       " 138: 'without',\n",
       " 139: 'contrast',\n",
       " 140: 'results',\n",
       " 141: 'faxed',\n",
       " 142: 'bravo',\n",
       " 143: 'dependent',\n",
       " 144: 'detail',\n",
       " 145: 'zachary',\n",
       " 146: 'jager',\n",
       " 147: 'billed',\n",
       " 148: 'amounts',\n",
       " 149: 'contract',\n",
       " 150: 'adjustment',\n",
       " 151: 'allowed',\n",
       " 152: 'amount',\n",
       " 153: 'covered',\n",
       " 154: 'reason',\n",
       " 155: 'deductible',\n",
       " 156: 'carrier',\n",
       " 157: 'paid',\n",
       " 158: 'responsibility',\n",
       " 159: 'totals',\n",
       " 160: 'appeals',\n",
       " 161: 'rights',\n",
       " 162: 'important',\n",
       " 163: 'appeal',\n",
       " 164: 'languages',\n",
       " 165: 'contact',\n",
       " 166: 'know',\n",
       " 167: 'specialty',\n",
       " 168: 'orthopedic',\n",
       " 169: 'surgeon',\n",
       " 170: 'kari',\n",
       " 171: 'lund',\n",
       " 172: 'orthopedist',\n",
       " 173: 'dan',\n",
       " 174: 'palmer',\n",
       " 175: '&',\n",
       " 176: 'may',\n",
       " 177: 'spouse',\n",
       " 178: 'child',\n",
       " 179: 'black',\n",
       " 180: 'hills',\n",
       " 181: 'pc',\n",
       " 182: 'pmt',\n",
       " 183: 'due',\n",
       " 184: 'statement',\n",
       " 185: 'ins',\n",
       " 186: 'description',\n",
       " 187: 'e',\n",
       " 188: 'm',\n",
       " 189: 'new',\n",
       " 190: 'moderat',\n",
       " 191: 'clo',\n",
       " 192: 'tx',\n",
       " 193: 'phalangealfx',\n",
       " 194: 'finger',\n",
       " 195: 'splint',\n",
       " 196: 'offic',\n",
       " 197: 'cons',\n",
       " 198: 'moderate',\n",
       " 199: 'sever',\n",
       " 200: 'rad',\n",
       " 201: 'mini',\n",
       " 202: 'applic',\n",
       " 203: 'hand',\n",
       " 204: 'lower',\n",
       " 205: 'forearm',\n",
       " 206: 'fiberglass',\n",
       " 207: 'gauntlet',\n",
       " 208: 'cast',\n",
       " 209: 'yrs',\n",
       " 210: 'charge',\n",
       " 211: 'pat',\n",
       " 212: 'adjust',\n",
       " 213: 'current',\n",
       " 214: 'days',\n",
       " 215: 'balance',\n",
       " 216: 'pending',\n",
       " 217: 'message',\n",
       " 218: 'make',\n",
       " 219: 'checks',\n",
       " 220: 'payable',\n",
       " 221: 'billing',\n",
       " 222: 'questions',\n",
       " 223: 'choice',\n",
       " 224: 'health',\n",
       " 225: 'administrators',\n",
       " 226: 'forwarding',\n",
       " 227: 'service',\n",
       " 228: 'requested',\n",
       " 229: 'regional',\n",
       " 230: 'inc',\n",
       " 231: 'participant',\n",
       " 232: 'id',\n",
       " 233: 'original',\n",
       " 234: 'print',\n",
       " 235: 'website',\n",
       " 236: 'dea',\n",
       " 237: 'individual',\n",
       " 238: 'summary',\n",
       " 239: 'plan',\n",
       " 240: 'status',\n",
       " 241: 'period',\n",
       " 242: 'pocket',\n",
       " 243: 'explanation',\n",
       " 244: 'retain',\n",
       " 245: 'purposes',\n",
       " 246: 'family',\n",
       " 247: 'network',\n",
       " 248: 'karl',\n",
       " 249: 'services',\n",
       " 250: 'modifiers',\n",
       " 251: 'tc',\n",
       " 252: 'rt',\n",
       " 253: 'qualified',\n",
       " 254: 'sign',\n",
       " 255: 'interpreters',\n",
       " 256: 'written',\n",
       " 257: 'jacquelin',\n",
       " 258: 'brainard',\n",
       " 259: 'compliance',\n",
       " 260: 'officer',\n",
       " 261: 'mail',\n",
       " 262: 'department',\n",
       " 263: 'human',\n",
       " 264: 'complaint',\n",
       " 265: 'forms',\n",
       " 266: 'dakota',\n",
       " 267: 'ez',\n",
       " 268: 'ways',\n",
       " 269: 'pay',\n",
       " 270: 'automated',\n",
       " 271: 'attendant',\n",
       " 272: 'payments',\n",
       " 273: 'please',\n",
       " 274: 'call',\n",
       " 275: 'upon',\n",
       " 276: 'receipt',\n",
       " 277: 'improved',\n",
       " 278: 'online',\n",
       " 279: 'experience',\n",
       " 280: '|',\n",
       " 281: 'update',\n",
       " 282: 'info',\n",
       " 283: 'see',\n",
       " 284: 'details',\n",
       " 285: 'back',\n",
       " 286: 'show',\n",
       " 287: 'proc',\n",
       " 288: 'units',\n",
       " 289: 'charges',\n",
       " 290: 'insur',\n",
       " 291: 'thorac',\n",
       " 292: 'spine',\n",
       " 293: 'commercial',\n",
       " 294: 'non',\n",
       " 295: 'ct',\n",
       " 296: 'abd',\n",
       " 297: 'pelv',\n",
       " 298: 'payment',\n",
       " 299: 'chest',\n",
       " 300: 'harges',\n",
       " 301: 'digit',\n",
       " 302: 'today',\n",
       " 303: \"'s\",\n",
       " 304: 'ethnicity',\n",
       " 305: 'hispanic',\n",
       " 306: 'latino',\n",
       " 307: 'preferred',\n",
       " 308: 'english',\n",
       " 309: 'suzanne',\n",
       " 310: 'newsom',\n",
       " 311: 'cnp',\n",
       " 312: '•',\n",
       " 313: 'lethargy',\n",
       " 314: 'cough',\n",
       " 315: 'vitals',\n",
       " 316: 'lbs',\n",
       " 317: 'kg',\n",
       " 318: 'wt',\n",
       " 319: 'temp',\n",
       " 320: 'hr',\n",
       " 321: 'oxygen',\n",
       " 322: 'sat',\n",
       " 323: 'allergies',\n",
       " 324: 'amoxicillin',\n",
       " 325: 'rash',\n",
       " 326: 'possible',\n",
       " 327: 'hives',\n",
       " 328: 'active',\n",
       " 329: 'diagnoses',\n",
       " 330: 'include',\n",
       " 331: 'frontal',\n",
       " 332: 'sinusitis',\n",
       " 333: 'unspecified',\n",
       " 334: 'dizziness',\n",
       " 335: 'giddiness',\n",
       " 336: 'medication',\n",
       " 337: 'list',\n",
       " 338: 'medications',\n",
       " 339: 'taking',\n",
       " 340: 'zyrtec',\n",
       " 341: 'childrens',\n",
       " 342: 'allergy',\n",
       " 343: 'notes',\n",
       " 344: 'tests',\n",
       " 345: 'labs',\n",
       " 346: 'illumigene',\n",
       " 347: 'myco',\n",
       " 348: 'http',\n",
       " 349: 'basic',\n",
       " 350: 'metabolic',\n",
       " 351: 'sodium',\n",
       " 352: 'range',\n",
       " 353: 'potassium',\n",
       " 354: 'chloride',\n",
       " 355: 'glucose',\n",
       " 356: 'bun',\n",
       " 357: 'creatinine',\n",
       " 358: 'calcium',\n",
       " 359: 'crea',\n",
       " 360: 'ratio',\n",
       " 361: 'anion',\n",
       " 362: 'gap',\n",
       " 363: 'calc',\n",
       " 364: 'cbc',\n",
       " 365: 'diff',\n",
       " 366: 'wbc',\n",
       " 367: 'rbc',\n",
       " 368: 'hgb',\n",
       " 369: 'hct',\n",
       " 370: 'mcv',\n",
       " 371: 'fl',\n",
       " 372: 'mch',\n",
       " 373: 'pg',\n",
       " 374: 'mchc',\n",
       " 375: 'mpv',\n",
       " 376: 'platelets',\n",
       " 377: 'neutrophils',\n",
       " 378: 'lymphocytes',\n",
       " 379: 'monocytes',\n",
       " 380: 'conditions',\n",
       " 381: 'problem',\n",
       " 382: 'idiopathic',\n",
       " 383: 'urticaria',\n",
       " 384: 'document',\n",
       " 385: 'wish',\n",
       " 386: 'keep',\n",
       " 387: 'policyholder',\n",
       " 388: 'owner',\n",
       " 389: 'eastside',\n",
       " 390: 'acct',\n",
       " 391: 'jasminder',\n",
       " 392: 'singh',\n",
       " 393: 'dev',\n",
       " 394: 'pa',\n",
       " 395: 'excuse',\n",
       " 396: 'east',\n",
       " 397: 'side',\n",
       " 398: 'april',\n",
       " 399: 'weekly',\n",
       " 400: 'ph',\n",
       " 401: 'mr',\n",
       " 402: 'primary',\n",
       " 403: 'thoracic',\n",
       " 404: 'strain',\n",
       " 405: 'strained',\n",
       " 406: 'following',\n",
       " 407: 'occurs',\n",
       " 408: 'feel',\n",
       " 409: 'weakness',\n",
       " 410: 'arms',\n",
       " 411: 'legs',\n",
       " 412: 'severe',\n",
       " 413: 'increase',\n",
       " 414: 'pain',\n",
       " 415: 'lumbosacral',\n",
       " 416: 'weak',\n",
       " 417: 'becomes',\n",
       " 418: 'follow',\n",
       " 419: 'take',\n",
       " 420: 'directed',\n",
       " 421: 'additional',\n",
       " 422: 'prescriptions',\n",
       " 423: 'prescriber',\n",
       " 424: 'paper',\n",
       " 425: 'prescription',\n",
       " 426: 'given',\n",
       " 427: 'preventative',\n",
       " 428: 'instructions',\n",
       " 429: 'diagnosis',\n",
       " 430: 'knee',\n",
       " 431: 'david',\n",
       " 432: 'bruce',\n",
       " 433: 'identiﬁer',\n",
       " 434: 'june',\n",
       " 435: 'concussion',\n",
       " 436: 'devin',\n",
       " 437: 'conrad',\n",
       " 438: 'september',\n",
       " 439: 'form',\n",
       " 440: 'attending',\n",
       " 441: 'part',\n",
       " 442: 'completed',\n",
       " 443: 'icd',\n",
       " 444: 'unable',\n",
       " 445: 'expected',\n",
       " 446: 'delivery',\n",
       " 447: 'actual',\n",
       " 448: 'vaginal',\n",
       " 449: 'per',\n",
       " 450: 'continued',\n",
       " 451: 'facility',\n",
       " 452: 'state',\n",
       " 453: 'zip',\n",
       " 454: 'performed',\n",
       " 455: 'surgical',\n",
       " 456: 'cpt',\n",
       " 457: 'degree',\n",
       " 458: 'check',\n",
       " 459: 'filing',\n",
       " 460: 'b',\n",
       " 461: 'suffix',\n",
       " 462: 'mi',\n",
       " 463: 'spanish',\n",
       " 464: 'short',\n",
       " 465: 'term',\n",
       " 466: 'disability',\n",
       " 467: 'long',\n",
       " 468: 'life',\n",
       " 469: 'insurance',\n",
       " 470: 'voluntary',\n",
       " 471: 'motor',\n",
       " 472: 'vehicle',\n",
       " 473: 'physicians',\n",
       " 474: 'hospitals',\n",
       " 475: 'considerations',\n",
       " 476: 'male',\n",
       " 477: 'female',\n",
       " 478: 'folder',\n",
       " 479: 'contents',\n",
       " 480: 'claimant',\n",
       " 481: 'unauthorized',\n",
       " 482: 'access',\n",
       " 483: 'strictly',\n",
       " 484: 'probihited',\n",
       " 485: 'best',\n",
       " 486: 'reach',\n",
       " 487: 'return',\n",
       " 488: 'sprained',\n",
       " 489: 'ankle',\n",
       " 490: 'monica',\n",
       " 491: 'shaffer',\n",
       " 492: 'johnson',\n",
       " 493: 'ave',\n",
       " 494: 'bridgeport',\n",
       " 495: 'wv',\n",
       " 496: 'us',\n",
       " 497: 'accountability',\n",
       " 498: 'act',\n",
       " 499: 'hipaa',\n",
       " 500: 'privacy',\n",
       " 501: 'rule',\n",
       " 502: 'banks',\n",
       " 503: 'governmental',\n",
       " 504: 'entities',\n",
       " 505: 'communicable',\n",
       " 506: 'disease',\n",
       " 507: 'cl',\n",
       " 508: 'gregory',\n",
       " 509: 'assist',\n",
       " 510: 'prohibited',\n",
       " 511: 'otherwise',\n",
       " 512: 'permitted',\n",
       " 513: 'law',\n",
       " 514: 'ems',\n",
       " 515: 'christopher',\n",
       " 516: 'bartruff',\n",
       " 517: 'park',\n",
       " 518: 'blvd',\n",
       " 519: 'naples',\n",
       " 520: 'nch',\n",
       " 521: 'emergency',\n",
       " 522: 'healthcare',\n",
       " 523: 'system',\n",
       " 524: 'napies',\n",
       " 525: 'north',\n",
       " 526: 'collier',\n",
       " 527: 'northeast',\n",
       " 528: 'ed',\n",
       " 529: 'chief',\n",
       " 530: 'icd=cc',\n",
       " 531: 'numbers',\n",
       " 532: 'feeling',\n",
       " 533: 'suicidal',\n",
       " 534: 'help',\n",
       " 535: 'comments',\n",
       " 536: 'dear',\n",
       " 537: 'however',\n",
       " 538: 'estimado',\n",
       " 539: 'paciente',\n",
       " 540: 'education',\n",
       " 541: 'materials',\n",
       " 542: 'peds',\n",
       " 543: 'upper',\n",
       " 544: 'extremity',\n",
       " 545: 'contusion',\n",
       " 546: 'home',\n",
       " 547: 'care',\n",
       " 548: 'special',\n",
       " 549: 'note',\n",
       " 550: 'parents',\n",
       " 551: 'seek',\n",
       " 552: 'advice',\n",
       " 553: 'bruising',\n",
       " 554: 'gets',\n",
       " 555: 'worse',\n",
       " 556: 'numbness',\n",
       " 557: 'tingling',\n",
       " 558: 'injured',\n",
       " 559: 'arm',\n",
       " 560: 'trauma',\n",
       " 561: 'watch',\n",
       " 562: 'symptoms',\n",
       " 563: 'headache',\n",
       " 564: 'nausea',\n",
       " 565: 'vomiting',\n",
       " 566: 'sensitivity',\n",
       " 567: 'light',\n",
       " 568: 'noise',\n",
       " 569: 'unusual',\n",
       " 570: 'sleepiness',\n",
       " 571: 'grogginess',\n",
       " 572: 'trouble',\n",
       " 573: 'falling',\n",
       " 574: 'asleep',\n",
       " 575: 'personality',\n",
       " 576: 'changes',\n",
       " 577: 'vision',\n",
       " 578: 'memory',\n",
       " 579: 'loss',\n",
       " 580: 'confusion',\n",
       " 581: 'walking',\n",
       " 582: 'clumsiness',\n",
       " 583: 'inability',\n",
       " 584: 'awakened',\n",
       " 585: 'stiff',\n",
       " 586: 'neck',\n",
       " 587: 'body',\n",
       " 588: 'seizures',\n",
       " 589: 'general',\n",
       " 590: 'doesn',\n",
       " 591: 'get',\n",
       " 592: 'better',\n",
       " 593: 'worsens',\n",
       " 594: 'increased',\n",
       " 595: 'swelling',\n",
       " 596: 'sick',\n",
       " 597: 'appearance',\n",
       " 598: 'behaviors',\n",
       " 599: 'worry',\n",
       " 600: 'school',\n",
       " 601: 'caregiver',\n",
       " 602: 'released',\n",
       " 603: 'provided',\n",
       " 604: 'leaflets',\n",
       " 605: 'digitech',\n",
       " 606: 'computer',\n",
       " 607: 'behalf',\n",
       " 608: 'bedford',\n",
       " 609: 'rd',\n",
       " 610: 'bldg',\n",
       " 611: 'floor',\n",
       " 612: 'chappaqua',\n",
       " 613: 'ny',\n",
       " 614: 'https',\n",
       " 615: 'invoice',\n",
       " 616: 'county',\n",
       " 617: 'n',\n",
       " 618: 'baker',\n",
       " 619: 'marco',\n",
       " 620: 'lockbox',\n",
       " 621: 'processing',\n",
       " 622: 'atlanta',\n",
       " 623: 'ga',\n",
       " 624: 'aadc',\n",
       " 625: 're',\n",
       " 626: 'thirty',\n",
       " 627: 'letter',\n",
       " 628: 'accounting',\n",
       " 629: 'southwest',\n",
       " 630: 'florida',\n",
       " 631: 'management',\n",
       " 632: 'cincinnati',\n",
       " 633: 'oh',\n",
       " 634: 'th_ar_ltr',\n",
       " 635: 'jason',\n",
       " 636: 'santana',\n",
       " 637: 'sincerely',\n",
       " 638: 'plantation',\n",
       " 639: 'allstate',\n",
       " 640: 'youre',\n",
       " 641: 'good',\n",
       " 642: 'hands',\n",
       " 643: 'pip',\n",
       " 644: 'central',\n",
       " 645: 'clinton',\n",
       " 646: 'ia',\n",
       " 647: 'february',\n",
       " 648: 'office',\n",
       " 649: 'vyphaphone',\n",
       " 650: 'inthalangsy',\n",
       " 651: 'ext',\n",
       " 652: \"'re\",\n",
       " 653: 'jacksonville',\n",
       " 654: 'dallas',\n",
       " 655: 'specifics',\n",
       " 656: 'request',\n",
       " 657: 'caitlen',\n",
       " 658: 'carroll',\n",
       " 659: 'cellular',\n",
       " 660: 'medsupport',\n",
       " 661: 'policies',\n",
       " 662: 'domestic',\n",
       " 663: 'partner',\n",
       " 664: 'condition',\n",
       " 665: 'pm',\n",
       " 666: 'confinement',\n",
       " 667: 'dates',\n",
       " 668: 'teri',\n",
       " 669: 'willochell',\n",
       " 670: 'phycian',\n",
       " 671: 'violation',\n",
       " 672: 'indicated',\n",
       " 673: 'member',\n",
       " 674: 'relationship',\n",
       " 675: 'person',\n",
       " 676: 'granting',\n",
       " 677: 'authority',\n",
       " 678: 'including',\n",
       " 679: 'l',\n",
       " 680: 'lesser',\n",
       " 681: 'provide',\n",
       " 682: 'tha',\n",
       " 683: 'treatment',\n",
       " 684: 'advise',\n",
       " 685: 'stop',\n",
       " 686: 'willochel',\n",
       " 687: 'specially',\n",
       " 688: 'internal',\n",
       " 689: 'medicine',\n",
       " 690: 'md',\n",
       " 691: 'medexpress',\n",
       " 692: 'urgent',\n",
       " 693: 'route',\n",
       " 694: 'hippa',\n",
       " 695: 'socia',\n",
       " 696: 'location',\n",
       " 697: 'norwin',\n",
       " 698: 'huntingdon',\n",
       " 699: 'holder',\n",
       " 700: 'sex',\n",
       " 701: 'comp',\n",
       " 702: 'clinical',\n",
       " 703: 'bp',\n",
       " 704: 'mmhg',\n",
       " 705: 'pulse',\n",
       " 706: 'bpm',\n",
       " 707: 'resp',\n",
       " 708: 'weigth',\n",
       " 709: 'ft',\n",
       " 710: 'bmi',\n",
       " 711: 'lmp',\n",
       " 712: 'pmp',\n",
       " 713: 'meds',\n",
       " 714: 'acetaminophen',\n",
       " 715: 'albuterol',\n",
       " 716: 'bulk',\n",
       " 717: 'dilantin',\n",
       " 718: 'gabapentin',\n",
       " 719: 'humalog',\n",
       " 720: 'lamictal',\n",
       " 721: 'lyrica',\n",
       " 722: 'neurontin',\n",
       " 723: 'valacyclovir',\n",
       " 724: 'procedures',\n",
       " 725: 'foot',\n",
       " 726: 'min',\n",
       " 727: 'three',\n",
       " 728: 'estab',\n",
       " 729: 'met',\n",
       " 730: 'estimated',\n",
       " 731: 'mso',\n",
       " 732: 'llc',\n",
       " 733: 'med',\n",
       " 734: 'express',\n",
       " 735: 'uc',\n",
       " 736: 'hunington',\n",
       " 737: 'merchant',\n",
       " 738: 'transaction',\n",
       " 739: 'purchase',\n",
       " 740: 'approval',\n",
       " 741: 'record',\n",
       " 742: 'visa',\n",
       " 743: 'trace',\n",
       " 744: 'reference',\n",
       " 745: 'cardholder',\n",
       " 746: 'application',\n",
       " 747: 'label',\n",
       " 748: 'tvr',\n",
       " 749: 'aid',\n",
       " 750: 'subtotal',\n",
       " 751: 'sales',\n",
       " 752: 'copy',\n",
       " 753: 'send',\n",
       " 754: 'departmant',\n",
       " 755: 'northhuntingdon',\n",
       " 756: 'todays'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_word_tokens=len(sorted(list(word2int)))\n",
    "num_char_tokens=len(sorted(list(char2int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vecotrize hierarichal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_char_input_data, decoder_word_input_data, decoder_word_target_data = vectorize_hier_data(input_texts, \n",
    "                                                                                                target_texts, \n",
    "                                                                                                max_words_seq_len, \n",
    "                                                                                                max_chars_seq_len, \n",
    "                                                                                                num_char_tokens, \n",
    "                                                                                                num_word_tokens, \n",
    "                                                                                                word2int, \n",
    "                                                                                                char2int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load char encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py:269: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "encoder_char_model = load_model(encoder_char_model_file.format(max_sent_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Hierarichal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder-decoder  model:\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 15, 20)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 multiple             720985      lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "                                                                 lambda_10[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "                                                                 lambda_12[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "                                                                 lambda_14[0][0]                  \n",
      "                                                                 lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1024)         0           model_2[1][1]                    \n",
      "                                                                 model_2[1][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1024)         0           model_2[2][1]                    \n",
      "                                                                 model_2[2][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 1024)         0           model_2[3][1]                    \n",
      "                                                                 model_2[3][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1024)         0           model_2[4][1]                    \n",
      "                                                                 model_2[4][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1024)         0           model_2[5][1]                    \n",
      "                                                                 model_2[5][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 1024)         0           model_2[6][1]                    \n",
      "                                                                 model_2[6][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 1024)         0           model_2[7][1]                    \n",
      "                                                                 model_2[7][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 1024)         0           model_2[8][1]                    \n",
      "                                                                 model_2[8][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 1024)         0           model_2[9][1]                    \n",
      "                                                                 model_2[9][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 1024)         0           model_2[10][1]                   \n",
      "                                                                 model_2[10][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 1024)         0           model_2[11][1]                   \n",
      "                                                                 model_2[11][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 1024)         0           model_2[12][1]                   \n",
      "                                                                 model_2[12][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 1024)         0           model_2[13][1]                   \n",
      "                                                                 model_2[13][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 1024)         0           model_2[14][1]                   \n",
      "                                                                 model_2[14][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 1024)         0           model_2[15][1]                   \n",
      "                                                                 model_2[15][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 1024)      0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 1024)      0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 1024)      0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1, 1024)      0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1, 1024)      0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 1, 1024)      0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 1, 1024)      0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 1, 1024)      0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 1, 1024)      0           concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 1, 1024)      0           concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 1, 1024)      0           concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 1, 1024)      0           concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 1, 1024)      0           concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 1, 1024)      0           concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 1, 1024)      0           concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 15, 1024)     0           reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "                                                                 reshape_6[0][0]                  \n",
      "                                                                 reshape_7[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "                                                                 reshape_9[0][0]                  \n",
      "                                                                 reshape_10[0][0]                 \n",
      "                                                                 reshape_11[0][0]                 \n",
      "                                                                 reshape_12[0][0]                 \n",
      "                                                                 reshape_13[0][0]                 \n",
      "                                                                 reshape_14[0][0]                 \n",
      "                                                                 reshape_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 15)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) [(None, 15, 512), (N 2623488     concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 15, 1024)     775168      input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 512)          0           bidirectional_2[0][1]            \n",
      "                                                                 bidirectional_2[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 512)          0           bidirectional_2[0][2]            \n",
      "                                                                 bidirectional_2[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 15, 512), (N 3147776     embedding_3[0][0]                \n",
      "                                                                 concatenate_20[0][0]             \n",
      "                                                                 concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_3 (Dot)                     (None, 15, 15)       0           lstm_4[0][0]                     \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 15, 15)       0           dot_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_4 (Dot)                     (None, 15, 512)      0           activation_1[0][0]               \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 15, 1024)     0           dot_4[0][0]                      \n",
      "                                                                 lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 15, 757)      775925      concatenate_22[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 8,043,342\n",
      "Trainable params: 8,035,061\n",
      "Non-trainable params: 8,281\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:70: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "model, encoder_model, decoder_model = build_hier_model(encoder_char_model=encoder_char_model, \n",
    "                              max_words_seq_len=max_words_seq_len,\n",
    "                              max_char_seq_len=max_chars_seq_len,\n",
    "                              num_word_tokens=num_word_tokens,\n",
    "                              num_char_tokens=num_char_tokens, \n",
    "                              latent_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 15, 20)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 20)           0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 multiple             720985      lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "                                                                 lambda_10[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "                                                                 lambda_12[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "                                                                 lambda_14[0][0]                  \n",
      "                                                                 lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1024)         0           model_2[1][1]                    \n",
      "                                                                 model_2[1][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1024)         0           model_2[2][1]                    \n",
      "                                                                 model_2[2][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 1024)         0           model_2[3][1]                    \n",
      "                                                                 model_2[3][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1024)         0           model_2[4][1]                    \n",
      "                                                                 model_2[4][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 1024)         0           model_2[5][1]                    \n",
      "                                                                 model_2[5][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 1024)         0           model_2[6][1]                    \n",
      "                                                                 model_2[6][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 1024)         0           model_2[7][1]                    \n",
      "                                                                 model_2[7][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 1024)         0           model_2[8][1]                    \n",
      "                                                                 model_2[8][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 1024)         0           model_2[9][1]                    \n",
      "                                                                 model_2[9][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 1024)         0           model_2[10][1]                   \n",
      "                                                                 model_2[10][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 1024)         0           model_2[11][1]                   \n",
      "                                                                 model_2[11][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 1024)         0           model_2[12][1]                   \n",
      "                                                                 model_2[12][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 1024)         0           model_2[13][1]                   \n",
      "                                                                 model_2[13][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 1024)         0           model_2[14][1]                   \n",
      "                                                                 model_2[14][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 1024)         0           model_2[15][1]                   \n",
      "                                                                 model_2[15][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 1024)      0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 1024)      0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 1024)      0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1, 1024)      0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1, 1024)      0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 1, 1024)      0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 1, 1024)      0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 1, 1024)      0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 1, 1024)      0           concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 1, 1024)      0           concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 1, 1024)      0           concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 1, 1024)      0           concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 1, 1024)      0           concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 1, 1024)      0           concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 1, 1024)      0           concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 15, 1024)     0           reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "                                                                 reshape_6[0][0]                  \n",
      "                                                                 reshape_7[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "                                                                 reshape_9[0][0]                  \n",
      "                                                                 reshape_10[0][0]                 \n",
      "                                                                 reshape_11[0][0]                 \n",
      "                                                                 reshape_12[0][0]                 \n",
      "                                                                 reshape_13[0][0]                 \n",
      "                                                                 reshape_14[0][0]                 \n",
      "                                                                 reshape_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) [(None, 15, 512), (N 2623488     concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 512)          0           bidirectional_2[0][1]            \n",
      "                                                                 bidirectional_2[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 512)          0           bidirectional_2[0][2]            \n",
      "                                                                 bidirectional_2[0][4]            \n",
      "==================================================================================================\n",
      "Total params: 3,344,473\n",
      "Trainable params: 3,336,192\n",
      "Non-trainable params: 8,281\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 15)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 15, 1024)     775168      input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 15, 512), (N 3147776     embedding_3[0][0]                \n",
      "                                                                 input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 15, 512)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dot_3 (Dot)                     (None, 15, 15)       0           lstm_4[1][0]                     \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 15, 15)       0           dot_3[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_4 (Dot)                     (None, 15, 512)      0           activation_1[1][0]               \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 15, 1024)     0           dot_4[1][0]                      \n",
      "                                                                 lstm_4[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 15, 757)      775925      concatenate_22[1][0]             \n",
      "==================================================================================================\n",
      "Total params: 4,698,869\n",
      "Trainable params: 4,698,869\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Hierarichal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/10\n",
      "3200/3200 [==============================] - 51s 16ms/step - loss: 0.2140 - categorical_accuracy: 0.8723 - val_loss: 0.5549 - val_categorical_accuracy: 0.8331\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.83310, saving model to best_hier_model-15-20.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/keras/engine/network.py:872: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'concatenate_20/concat:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'concatenate_21/concat:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "3200/3200 [==============================] - 32s 10ms/step - loss: 0.1375 - categorical_accuracy: 0.8928 - val_loss: 0.5317 - val_categorical_accuracy: 0.8556\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.83310 to 0.85560, saving model to best_hier_model-15-20.hdf5\n",
      "Epoch 3/10\n",
      "3200/3200 [==============================] - 32s 10ms/step - loss: 0.1331 - categorical_accuracy: 0.8891 - val_loss: 0.5166 - val_categorical_accuracy: 0.8453\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy did not improve from 0.85560\n",
      "Epoch 4/10\n",
      "3200/3200 [==============================] - 33s 10ms/step - loss: 0.1060 - categorical_accuracy: 0.8858 - val_loss: 0.5027 - val_categorical_accuracy: 0.8570\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy improved from 0.85560 to 0.85700, saving model to best_hier_model-15-20.hdf5\n",
      "Epoch 5/10\n",
      "3200/3200 [==============================] - 32s 10ms/step - loss: 0.1106 - categorical_accuracy: 0.8918 - val_loss: 0.6341 - val_categorical_accuracy: 0.8390\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.85700\n",
      "Epoch 6/10\n",
      "3200/3200 [==============================] - 33s 10ms/step - loss: 0.1177 - categorical_accuracy: 0.8917 - val_loss: 0.6133 - val_categorical_accuracy: 0.8360\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.85700\n",
      "Epoch 7/10\n",
      "3200/3200 [==============================] - 33s 10ms/step - loss: 0.1402 - categorical_accuracy: 0.8854 - val_loss: 0.7180 - val_categorical_accuracy: 0.7987\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy did not improve from 0.85700\n",
      "Epoch 8/10\n",
      "3200/3200 [==============================] - 32s 10ms/step - loss: 0.1607 - categorical_accuracy: 0.8839 - val_loss: 0.6219 - val_categorical_accuracy: 0.8265\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.85700\n",
      "Epoch 9/10\n",
      "3200/3200 [==============================] - 32s 10ms/step - loss: 0.1692 - categorical_accuracy: 0.8881 - val_loss: 0.6435 - val_categorical_accuracy: 0.8200\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.85700\n",
      "Epoch 10/10\n",
      "3200/3200 [==============================] - 32s 10ms/step - loss: 0.2016 - categorical_accuracy: 0.8726 - val_loss: 0.6840 - val_categorical_accuracy: 0.7983\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.85700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f54da9f0c50>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 10 \n",
    "lr = 0.01\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(lr=lr), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "#filepath=\"weights-improvement-{epoch:02d}-{val_categorical_accuracy:.2f}.hdf5\"\n",
    "filepath=\"best_hier_model-{}-{}.hdf5\".format(max_words_seq_len,max_chars_seq_len) # Save only the best model for inference step, as saving the epoch and metric might confuse the inference function which model to use\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "tbCallBack = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "callbacks_list = [checkpoint, tbCallBack]\n",
    "#callbacks_list = [checkpoint, tbCallBack, lrate]\n",
    "model.fit([encoder_char_input_data, decoder_word_input_data], decoder_word_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_split=0.2,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Climt Type: VB Accident - Accidnytal Injury\n",
      "GT sentence: Claim Type: VB Accident - Accidental Injury\n",
      "\n",
      "Decoded sentence: type UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Policyhoder/Owner Informaton\n",
      "GT sentence: Policyholder/Owner Information\n",
      "\n",
      "Decoded sentence: pip central UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: First Nme:\n",
      "GT sentence: First Name:\n",
      "\n",
      "Decoded sentence: first missed work UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Middle aNme/Initialo:\n",
      "GT sentence: Middle Name/Initial:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Last Namet:\n",
      "GT sentence: Last Name:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Social Secruitly Number:\n",
      "GT sentence: Social Security Number:\n",
      "\n",
      "Decoded sentence: pip central UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Birth Dat:q\n",
      "GT sentence: Birth Date:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Geder:\n",
      "GT sentence: Gender:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Langkugae Preference:\n",
      "GT sentence: Language Preference:\n",
      "\n",
      "Decoded sentence: first missed work UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: AddressL ien 1:\n",
      "GT sentence: Address Line 1:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: City:\n",
      "GT sentence: City:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: State/Povince:\n",
      "GT sentence: State/Province:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Potsalr Code:\n",
      "GT sentence: Postal Code:\n",
      "\n",
      "Decoded sentence: date UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Countr:j\n",
      "GT sentence: Country:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Email Address:\n",
      "GT sentence: Email Address:\n",
      "\n",
      "Decoded sentence: date UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Ptage 1 of 1\n",
      "GT sentence: Page 1 of 1\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: RAjDIOLOGY\n",
      "GT sentence: RADIOLOGY\n",
      "\n",
      "Decoded sentence: number UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: REPORT\n",
      "GT sentence: REPORT\n",
      "\n",
      "Decoded sentence: number UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: www.rays.ent\n",
      "GT sentence: www.rays.net\n",
      "\n",
      "Decoded sentence: address UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Patein tMRhN Accession No. Ref. Physician\n",
      "GT sentence: Patient MRN Accession No. Ref. Physician\n",
      "\n",
      "Decoded sentence: mrn accession UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: UNKNWN\n",
      "GT sentence: UNKNOWN\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Study \n",
      "GT sentence: Study \n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Study Dateu:\n",
      "GT sentence: Study Date:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: ospiatlC ode: 202 6\n",
      "GT sentence: Hospital Code: 2026 \n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: DOB\n",
      "GT sentence: DOB:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: 43.\n",
      "GT sentence: 43F.\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Technique:  viewsl eftwris\n",
      "GT sentence: Technique: 3 views left wrist\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Cormqarison: None availabi\n",
      "GT sentence: Cormarison: None availabie\n",
      "\n",
      "Decoded sentence: released UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Comparison: Noe available\n",
      "GT sentence: Comparison: None available\n",
      "\n",
      "Decoded sentence: released UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: FINDINSG\n",
      "\n",
      "GT sentence: FINDINGS:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: IPMRSESION:c\n",
      "GT sentence: IMPRESSION:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: 2. No acute oseous abtnormality identified.\n",
      "GT sentence: 2. No acute osseous abnormality identified.\n",
      "\n",
      "Decoded sentence: chest UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: DaytimePhone:\n",
      "GT sentence: Daytime Phone:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Claihm Event Informatio\n",
      "\n",
      "GT sentence: Claim Event Information\n",
      "\n",
      "Decoded sentence: pip central UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Stopped oWrking?: Yes\n",
      "GT sentence: Stopped Working?: Yes\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: aDte Lats Physically at Work:\n",
      "GT sentence: Date Last Physically at Work:\n",
      "\n",
      "Decoded sentence: first missed work UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Hours Worke don Last Day: 8\n",
      "GT sentence: Hours Worked on Last Day: 8\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Hours cSheduled to Work on Last Day:\n",
      "GT sentence: Hours Scheduled to Work on Last Day:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Date FirstM issefd Work:\n",
      "GT sentence: Date First Missed Work:\n",
      "\n",
      "Decoded sentence: first missed work UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Returned t Work:? No\n",
      "GT sentence: Returned to Work?: No\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: ccident Work Reltated: Ys\n",
      "GT sentence: Accident Work Related: Yes\n",
      "\n",
      "Decoded sentence: dates UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: iTmse of Adccident:\n",
      "GT sentence: Time of Accident:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Ascciden tDate:\n",
      "GT sentence: Accident Date:\n",
      "\n",
      "Decoded sentence: date UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Sugrery Informtaion\n",
      "GT sentence: Surgery Information\n",
      "\n",
      "Decoded sentence: health system UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Is Surgery Requierd :Yes\n",
      "GT sentence: Is Surgery Required: Yes\n",
      "\n",
      "Decoded sentence: released UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Surgerty Date:\n",
      "GT sentence: Surgery Date:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: npatiet/Outpaltient Indciator: Oudtpaitent\n",
      "GT sentence: Inpatient/Outpatient Indicator: Outpatient\n",
      "\n",
      "Decoded sentence: released UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Medical ProviderI nformation - Physicia\n",
      "GT sentence: Medical Provider Information - Physician\n",
      "\n",
      "Decoded sentence: phys UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Medica lProviderR olers: Treating\n",
      "GT sentence: Medical Provider Roles: Treating\n",
      "\n",
      "Decoded sentence: released UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Provider Firs Name: Ptric\n",
      "GT sentence: Provider First Name: Patrick\n",
      "\n",
      "Decoded sentence: online | update info sever UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Provider Last Name: Emerosn\n",
      "GT sentence: Provider Last Name: Emerson\n",
      "\n",
      "Decoded sentence: online | update info sever UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Adress Lnie 1 :\n",
      "GT sentence: Address Line 1 :\n",
      "\n",
      "Decoded sentence: dates UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Ciy\n",
      "GT sentence: City:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Sate/rovince:\n",
      "GT sentence: State/Province:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Postal Code\n",
      "GT sentence: Postal Code:\n",
      "\n",
      "Decoded sentence: pip central UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Country:\n",
      "GT sentence: Country:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Businesos Telephone:\n",
      "GT sentence: Business Telephone:\n",
      "\n",
      "Decoded sentence: first missed work UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Business Fa\n",
      "GT sentence: Business Fax\n",
      "\n",
      "Decoded sentence: pip central UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Datheof Firsut Visit:\n",
      "GT sentence: Date of First Visit:\n",
      "\n",
      "Decoded sentence: first missed work UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Date of Nex tVisit:\n",
      "GT sentence: Date of Next Visit:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Medical Provider Information - Holspitalization\n",
      "GT sentence: Medical Provider Information - Hospitalization\n",
      "\n",
      "Decoded sentence: pip central UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Hospital Name:\n",
      "GT sentence: Hospital Name:\n",
      "\n",
      "Decoded sentence: telephone number UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Adrdess Linea 1:\n",
      "GT sentence: Address Line 1:\n",
      "\n",
      "Decoded sentence: line UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: City:\n",
      "GT sentence: City:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: State/Province:\n",
      "GT sentence: State/Province:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Postal Cmode:\n",
      "GT sentence: Postal Code:\n",
      "\n",
      "Decoded sentence: date UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Country:\n",
      "GT sentence: Country:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: ateo f Visit/Admission:\n",
      "GT sentence: Date of Visit/Admission:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: afte of Discharge:\n",
      "GT sentence: Date of Discharge:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Procedure: Lyeft wrist arthiscopcb surngrey\n",
      "GT sentence: Procedure: Left wrist arthiscopic surgery\n",
      "\n",
      "Decoded sentence: released UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Empoyment Infolrmation\n",
      "GT sentence: Employment Information\n",
      "\n",
      "Decoded sentence: pip central UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Empolyer Noame:\n",
      "GT sentence: Employer Name:\n",
      "\n",
      "Decoded sentence: date UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Polcicy Numbler:\n",
      "GT sentence: Policy Number:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Electronic Submission\n",
      "GT sentence: Electronic Submission\n",
      "\n",
      "Decoded sentence: pip central UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Cqlaim vent Identifierm:\n",
      "GT sentence: Claim Event Identifier:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Sbmissiony Date:\n",
      "GT sentence: Submission Date:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: eEledctronicallcy Signed Indicatorf: Yes\n",
      "GT sentence: Electronically Signed Indicator: Yes\n",
      "\n",
      "Decoded sentence: due receipt UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Fraugd Statements Reviewe dand Eelctrodnicalyl\n",
      "GT sentence: Fraud Statements Reviewed and Electronically\n",
      "\n",
      "Decoded sentence: first unable UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Signed Date\n",
      "GT sentence: Signed Date:\n",
      "\n",
      "Decoded sentence: pip central UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: unmuy\n",
      "GT sentence: unum\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: he Benezfits Cente\n",
      "\n",
      "GT sentence: The Benefits Center\n",
      "\n",
      "Decoded sentence: pip central ems center UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: (Not for FMLAR eqsts)\n",
      "GT sentence: (Not for FMLA Requests)\n",
      "\n",
      "Decoded sentence: exam finger UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: eEelctronicall Signed 02/28/2018\n",
      "GT sentence: Electronically Signed 02/28/2018\n",
      "\n",
      "Decoded sentence: pip central center UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Insurde’sSignasture Date Signed\n",
      "GT sentence: Insured’s Signature Date Signed\n",
      "\n",
      "Decoded sentence: ’ UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Prinated Name Social Secruity Number\n",
      "GT sentence: Printed Name Social Security Number\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: CL-11i1 6(11/14)\n",
      "GT sentence: CL-1116 (11/14)\n",
      "\n",
      "Decoded sentence: surgery information UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: nUum\n",
      "GT sentence: Unum\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Cofnirmation of Coverage\n",
      "GT sentence: Confirmation of Coverage\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Employer:\n",
      "GT sentence: Employer:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Group Policy #\n",
      "\n",
      "GT sentence: Group Policy #:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: uCustomer  Polcigy #:\n",
      "GT sentence: Customer  Policy #:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: EE Name:\n",
      "GT sentence: EE Name:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Insurd Coverge Type Coverage Effective Date\n",
      "GT sentence: Insured Coverage Type Coverage Effective Date\n",
      "\n",
      "Decoded sentence: first missed work UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Epmloyee ff-Job Acc January 1, 2017\n",
      "GT sentence: Employee Off-Job Acc January 1, 2017\n",
      "\n",
      "Decoded sentence: brainard UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Emlployee Wellness Bnefit January 1, 2107\n",
      "GT sentence: Employee Wellness Benefit January 1, 2017\n",
      "\n",
      "Decoded sentence: brainard UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Total Motnhl yyPremiu:m\n",
      "GT sentence: Total Monthly Premium:\n",
      "\n",
      "Decoded sentence: dates UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: otal Emlpoyee Msontly Payrll Deducto\n",
      "GT sentence: Total Employee Montly Payroll Deduction:\n",
      "\n",
      "Decoded sentence: phys UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Nawme:\n",
      "GT sentence: Name:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: MRN #:\n",
      "GT sentence: MRN #:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n",
      "-\n",
      "Input sentence: Accuont:\n",
      "GT sentence: Account:\n",
      "\n",
      "Decoded sentence: UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK UNK  \n"
     ]
    }
   ],
   "source": [
    "# Sample output from train data\n",
    "decoded_sentences = []\n",
    "target_texts_ =  []\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "\n",
    "    input_seq = encoder_char_input_data[seq_index: seq_index + 1]\n",
    "    target_seq = np.argmax(decoder_word_target_data[seq_index: seq_index + 1], axis=-1)\n",
    "    #print(target_seq)\n",
    "    \n",
    "    decoded_sentence, _ = decode_sequence(input_seq, encoder_model, decoder_model, max_words_seq_len, num_word_tokens, int2word)\n",
    "    target_text = target_texts[seq_index][1:-1]\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('GT sentence:', target_text)\n",
    "    print('Decoded sentence:', decoded_sentence)   \n",
    "    decoded_sentences.append(decoded_sentence)\n",
    "    target_texts_.append(target_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
