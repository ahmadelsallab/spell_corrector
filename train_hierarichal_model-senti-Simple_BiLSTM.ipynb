{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Bidirectional, Concatenate, GRU, Dot, TimeDistributed, Activation, Embedding, Lambda, Concatenate, Reshape\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, LearningRateScheduler\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from keras.models import load_model\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import pandas as pd\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit gpu allocation. allow_growth, or gpu_fraction\n",
    "def gpu_alloc():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_alloc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chars_vocab(all_texts):\n",
    "    '''Build vocab dictionary to victorize chars into ints'''\n",
    "    vocab_to_int = {}\n",
    "    count = 0 # Start index for any char will be 1, as 0 is masked by the Embedding/Masking layer\n",
    "    codes = ['UNK', ' ', '\\t','\\n']# Start 'UNK' at the first entry, to keep its index=0 to be masked\n",
    "    for code in codes:\n",
    "        if code not in vocab_to_int:\n",
    "            vocab_to_int[code] = count\n",
    "            count += 1    \n",
    "    \n",
    "    for sentence in all_texts:\n",
    "        for char in sentence:\n",
    "            if char not in vocab_to_int:\n",
    "                vocab_to_int[char] = count\n",
    "                count += 1\n",
    "\n",
    "\n",
    "    '''''Build inverse translation from int to char'''\n",
    "    int_to_vocab = {}\n",
    "    for character, value in vocab_to_int.items():\n",
    "        int_to_vocab[value] = character\n",
    "        \n",
    "    return vocab_to_int, int_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sentences_data(input_texts, target_labels, max_sents_per_doc, max_words_per_sent, max_chars_per_word, \n",
    "                             num_classes, char2int):\n",
    "\n",
    "    \n",
    "    \n",
    "    hier_input_data = np.zeros((len(input_texts), \n",
    "                                max_sents_per_doc, \n",
    "                                max_words_per_sent, \n",
    "                                max_chars_per_word), dtype='float32')\n",
    "    \n",
    "        \n",
    "    hier_target_data = np.zeros((len(input_texts), num_classes), dtype='float32')\n",
    "    if(target_labels == None):\n",
    "        target_labels = np.zeros(len(input_texts), dtype='int32')\n",
    "    \n",
    "    for i, (input_text, target_label) in enumerate(zip(input_texts, target_labels)):\n",
    "        #sents_lst = sent_tokenize(clean_str(BeautifulSoup(input_text).get_text())) # TODO: Move to clean str\n",
    "        sents_lst = sent_tokenize(input_text)\n",
    "        \n",
    "        \n",
    "        if len(sents_lst) > max_sents_per_doc:\n",
    "            continue\n",
    "        \n",
    "        for j, sent in enumerate(sents_lst):\n",
    "                \n",
    "            words_lst = word_tokenize(input_text)\n",
    "            \n",
    "            if(len(words_lst) > max_words_per_sent):\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            for k, word in enumerate(words_lst):\n",
    "                \n",
    "                \n",
    "                if(len(word) > max_chars_per_word):\n",
    "                    continue\n",
    "                \n",
    "                for l, char in enumerate(word):\n",
    "                    # c0..cn\n",
    "                    if(char in char2int):\n",
    "                        hier_input_data[i, j, k, l] = char2int[char]\n",
    "                        try:\n",
    "                            hier_target_data[i, target_label] = 1\n",
    "                        except:\n",
    "                            print(target_label)\n",
    "\n",
    "                \n",
    "    return hier_input_data, hier_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chars2word_model_simple_BiLSTM(num_encoder_tokens, latent_dim):\n",
    "    # Define an input sequence and process it.\n",
    "    encoder_inputs = Input(shape=(None,), dtype='float32')\n",
    "    encoder_inputs_ = Embedding(num_encoder_tokens, num_encoder_tokens,                           \n",
    "                            weights=[np.eye(num_encoder_tokens)],\n",
    "                            mask_zero=True, trainable=False)(encoder_inputs)    \n",
    "    #encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "    encoder = Bidirectional(LSTM(latent_dim, return_state=True, return_sequences=True)) # Bi LSTM\n",
    "    encoder_outputs, state_f_h, state_f_c, state_b_h, state_b_c = encoder(encoder_inputs_)# Bi LSTM\n",
    " \n",
    "    encoder_embedding_output = Lambda(lambda x: x[:,-1,:])(encoder_outputs)\n",
    "    encoder_word_embedding_model = Model(input=encoder_inputs, output=encoder_embedding_output)\n",
    "\n",
    "    return encoder_word_embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_words2sent_model_simple_BiLSTM(encoder_word_embedding_model, \n",
    "                           max_words_seq_len, \n",
    "                           max_char_seq_len, \n",
    "                           latent_dim):\n",
    "    # Define an input sequence and process it.\n",
    "\n",
    "    inputs = Input(shape=(max_words_seq_len, max_char_seq_len,), dtype='float32')\n",
    "    #print(inputs.shape)\n",
    "    input_words = TimeDistributed(encoder_word_embedding_model)(inputs)\n",
    "\n",
    "    encoder_inputs_ = input_words   \n",
    "    #encoder_inputs = Input(shape=(None, char_vocab_size))\n",
    "    encoder = Bidirectional(LSTM(latent_dim, return_state=True, return_sequences=True)) # Bi LSTM\n",
    "    encoder_outputs, state_f_h, state_f_c, state_b_h, state_b_c = encoder(encoder_inputs_)# Bi LSTM\n",
    "        \n",
    "    encoder_embedding_output = Lambda(lambda x: x[:,-1,:])(encoder_outputs)\n",
    "    encoder_sentence_embedding_model = Model(input=inputs, output=encoder_embedding_output)\n",
    "\n",
    "    return encoder_sentence_embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def build_sent2doc_model(encoder_sentence_embedding_model, \n",
    "                         max_sents_seq_len, \n",
    "                         max_words_seq_len, \n",
    "                         max_char_seq_len, \n",
    "                         word2sent_latent_dim,\n",
    "                         sent2doc_latent_dim):\n",
    "    \n",
    "    inputs = Input(shape=(max_sents_seq_len, max_words_seq_len, max_char_seq_len,), dtype='float32')\n",
    "    \n",
    "    sents_states = []\n",
    "    \n",
    "    for s in range(max_sents_seq_len):\n",
    "        \n",
    "        encoder_words_inputs = Lambda(lambda x: x[:,s,:,:])(inputs)\n",
    "        #print(encoder_words_inputs.shape)\n",
    "        encoder_words_outputs = encoder_sentence_embedding_model(encoder_words_inputs)\n",
    "        encoder_words_outputs = Reshape((1,word2sent_latent_dim*2))(encoder_words_outputs)\n",
    "        #_, h, c = encoder_sentence_embedding_model(encoder_words_inputs)\n",
    "        '''\n",
    "        input_words = TimeDistributed(encoder_word_embedding_model)(inputs)\n",
    "\n",
    "        encoder_inputs_ = input_words   \n",
    "        #encoder_inputs = Input(shape=(None, char_vocab_size))\n",
    "        encoder = Bidirectional(LSTM(latent_dim, return_state=True, return_sequences=True)) # Bi LSTM\n",
    "        encoder_outputs, state_f_h, state_f_c, state_b_h, state_b_c = encoder(encoder_inputs_)# Bi LSTM\n",
    "\n",
    "        encoder_embedding_output = Lambda(lambda x: x[:,-1,:])(encoder_outputs)\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        #encoder_words_states = Concatenate()([h,c])\n",
    "        #print(encoder_chars_states)\n",
    "        #encoder_words_states = Reshape((1,word2sent_latent_dim*4))(encoder_words_states)\n",
    "        #print(encoder_words_outputs.shape)\n",
    "        sents_states.append(encoder_words_outputs)\n",
    "    #print(sents_states)\n",
    "    input_sents = Concatenate(axis=-2)(sents_states)\n",
    "    #print(input_sents.shape)\n",
    "    encoder_inputs_ = input_sents   \n",
    "    encoder = Bidirectional(LSTM(sent2doc_latent_dim, return_state=True, return_sequences=True)) # Bi LSTM\n",
    "    encoder_outputs, state_f_h, state_f_c, state_b_h, state_b_c = encoder(encoder_inputs_)# Bi LSTM\n",
    "    state_h = Concatenate()([state_f_h, state_b_h])# Bi LSTM\n",
    "    state_c = Concatenate()([state_f_c, state_b_c])# Bi LSTM\n",
    "    encoder_embedding_output = Lambda(lambda x: x[:,-1,:])(encoder_outputs)\n",
    "    \n",
    "    encoder_document_embedding_model = Model(input=inputs, output=encoder_embedding_output)\n",
    "    '''\n",
    "    preds = Dense(2, activation='softmax')(encoder_embedding_output)\n",
    "    model = Model(inputs, preds)\n",
    "    '''\n",
    "    #return model, encoder_document_embedding_model\n",
    "    return encoder_document_embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hier_senti_model(encoder_document_embedding_model,\n",
    "                           max_sents_seq_len, \n",
    "                           max_words_seq_len, \n",
    "                           max_char_seq_len):\n",
    "    inputs = Input(shape=(max_sents_seq_len, max_words_seq_len, max_char_seq_len,), dtype='float32')\n",
    "    encoder_embedding_output = encoder_document_embedding_model(inputs)\n",
    "    preds = Dense(2, activation='softmax')(encoder_embedding_output)\n",
    "    model = Model(inputs, preds)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for dataset\n",
    "    Every dataset is lower cased except\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"\\\\\", \"\", string)    \n",
    "    string = re.sub(r\"\\'\", \"\", string)    \n",
    "    string = re.sub(r\"\\\"\", \"\", string)    \n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../dat/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = 'imdb/labeledTrainData.tsv'\n",
    "data_train = pd.read_csv(os.path.join(data_path, data_file), sep='\\t')\n",
    "print(data_train.shape)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train = data_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12311_10</td>\n",
       "      <td>Naturally in a film who's main themes are of m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8348_2</td>\n",
       "      <td>This movie is a disaster within a disaster fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5828_4</td>\n",
       "      <td>All in all, this is a movie for kids. We saw i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7186_2</td>\n",
       "      <td>Afraid of the Dark left me with the impression...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12128_7</td>\n",
       "      <td>A very accurate depiction of small time mob li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             review\n",
       "0  12311_10  Naturally in a film who's main themes are of m...\n",
       "1    8348_2  This movie is a disaster within a disaster fil...\n",
       "2    5828_4  All in all, this is a movie for kids. We saw i...\n",
       "3    7186_2  Afraid of the Dark left me with the impression...\n",
       "4   12128_7  A very accurate depiction of small time mob li..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = 'imdb/testData.tsv'\n",
    "data_test = pd.read_csv(os.path.join(data_path, data_file), sep='\\t')\n",
    "print(data_test.shape)\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test = data_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        With all this stuff going down at the moment w...\n",
       "1        \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2        The film starts with a manager (Nicholas Bell)...\n",
       "3        It must be assumed that those who praised this...\n",
       "4        Superbly trashy and wondrously unpretentious 8...\n",
       "5        I dont know why people think this is such a ba...\n",
       "6        This movie could have been very good, but come...\n",
       "7        I watched this video at a friend's house. I'm ...\n",
       "8        A friend of mine bought this film for £1, and ...\n",
       "9        <br /><br />This movie is full of references. ...\n",
       "10       What happens when an army of wetbacks, towelhe...\n",
       "11       Although I generally do not like remakes belie...\n",
       "12       \\Mr. Harvey Lights a Candle\\\" is anchored by a...\n",
       "13       I had a feeling that after \\Submerged\\\", this ...\n",
       "14       note to George Litman, and others: the Mystery...\n",
       "15       Stephen King adaptation (scripted by King hims...\n",
       "16       `The Matrix' was an exciting summer blockbuste...\n",
       "17       Ulli Lommel's 1980 film 'The Boogey Man' is no...\n",
       "18       This movie is one among the very few Indian mo...\n",
       "19       Most people, especially young people, may not ...\n",
       "20       \\Soylent Green\\\" is one of the best and most d...\n",
       "21       Michael Stearns plays Mike, a sexually frustra...\n",
       "22       This happy-go-luck 1939 military swashbuckler,...\n",
       "23       I would love to have that two hours of my life...\n",
       "24       The script for this movie was probably found i...\n",
       "25       Looking for Quo Vadis at my local video store,...\n",
       "26       Note to all mad scientists everywhere: if you'...\n",
       "27       What the ........... is this ? This must, with...\n",
       "28       Intrigued by the synopsis (every gay video the...\n",
       "29       Would anyone really watch this RUBBISH if it d...\n",
       "                               ...                        \n",
       "24970    Red Rock West (1993)<br /><br />Nicolas Cage g...\n",
       "24971    what can i say?, ms Erika Eleniak is my favori...\n",
       "24972    The spoiler warning is for those people who wa...\n",
       "24973    What do you call a horror story without horror...\n",
       "24974    Though not a horror film in the traditional se...\n",
       "24975    This was what black society was like before th...\n",
       "24976    They probably should have called this movie Th...\n",
       "24977    Attractive Marjorie(Farrah Fawcett)lives in fe...\n",
       "24978    Vaguely reminiscent of great 1940's westerns, ...\n",
       "24979    I admit I had no idea what to expect before vi...\n",
       "24980    To me, the final scene, in which Harris respon...\n",
       "24981    This is by far the funniest short made by the ...\n",
       "24982    To be a Buster Keaton fan is to have your hear...\n",
       "24983    I was one of those \\few Americans\\\" that grew ...\n",
       "24984    Visually disjointed and full of itself, the di...\n",
       "24985    this movie had more holes than a piece of swis...\n",
       "24986    Last November, I had a chance to see this film...\n",
       "24987    First off, I'd like to make a correction on an...\n",
       "24988    While originally reluctant to jump on the band...\n",
       "24989    I heard about this movie when watching VH1's \\...\n",
       "24990    I've never been huge on IMAX films. They're co...\n",
       "24991    Steve McQueen has certainly a lot of loyal fan...\n",
       "24992    Sometimes you wonder how some people get fundi...\n",
       "24993    I am a student of film, and have been for seve...\n",
       "24994    Unimaginably stupid, redundant and humiliating...\n",
       "24995    It seems like more consideration has gone into...\n",
       "24996    I don't believe they made this film. Completel...\n",
       "24997    Guy is a loser. Can't get girls, needs to buil...\n",
       "24998    This 30 minute documentary Buñuel made in the ...\n",
       "24999    I saw this movie as a child and it broke my he...\n",
       "Name: review, Length: 25000, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = data_train.review  + data_test.review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /opt/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chars_per_words_lengths = []\n",
    "words_per_sents_lengths = []\n",
    "sents_per_docs_lengths = []\n",
    "\n",
    "# Chars per word should be on all text\n",
    "\n",
    "for text in all_texts:\n",
    "    \n",
    "    sents = sent_tokenize(clean_str(BeautifulSoup(text).get_text()))\n",
    "    sents_per_docs_lengths.append(len(sents))\n",
    "    for sent in sents:       \n",
    "    \n",
    "        words = word_tokenize(sent)\n",
    "        words_per_sents_lengths.append(len(words))\n",
    "        for word in words:\n",
    "            chars_per_words_lengths.append(len(word))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdbaef00cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h_s = plt.hist(sents_per_docs_lengths, bins=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.207560000000001"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sents_per_docs_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(sents_per_docs_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.078223632261627"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(sents_per_docs_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAFalJREFUeJzt3X+sX3Wd5/HnyxbQ1XVa5Gq6bdni2OyKJla8gbruHy66pTCbKZNoAtkMjUvSWQNZ3Zhdy2yyjD9INNmRXRIlwywdysQRWdShwTrdpjKZmChQRgaoyPYKrFQ6ULeAumZxwPf+8f1c/c7l23s/vfeWe9v7fCQn3+95n88538/nnurLc87n+zVVhSRJPV610B2QJJ08DA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVK3GUMjyauT3Jvkb5IcSPKJVr8lyeNJHmjLhlZPkhuSTCR5MMl5Q8famuRgW7YO1d+V5KG2zw1JciIGK0mam+UdbV4ALqyqnyU5DfhWkm+0bf+hqu6Y0v5iYH1bLgBuBC5IciZwLTAOFHB/kl1V9Wxrsw34DrAb2Ax8A0nSojLjlUYN/KytntaW6b4RuAW4te33HWBFklXARcDeqjragmIvsLlte31VfbsG3zS8Fbh0DmOSJJ0gPVcaJFkG3A+8Bfh8Vd2T5MPAdUn+M7AP2F5VLwCrgSeHdj/UatPVD42oT+uss86qdevW9XRfktTcf//9P66qsdnu3xUaVfUSsCHJCuBrSd4OXAP8LXA6cBPwceCTwKjnETWL+ssk2cbgNhZnn302+/fv7+m+JKlJ8r/nsv9xzZ6qqueAvwQ2V9XhdgvqBeBPgPNbs0PA2qHd1gBPzVBfM6I+6vNvqqrxqhofG5t1UEqSZqln9tRYu8IgyWuA9wPfb88iaDOdLgUebrvsAq5os6g2As9X1WFgD7ApycokK4FNwJ627adJNrZjXQHcOb/DlCTNh57bU6uAne25xquA26vqriTfTDLG4PbSA8C/be13A5cAE8DPgQ8BVNXRJJ8C7mvtPllVR9v7DwO3AK9hMGvKmVOStAjlZP1p9PHx8fKZhiQdnyT3V9X4bPf3G+GSpG6GhiSpm6EhSepmaEiSuhkakqRuhgawbvvXF7oLknRSMDQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3ZZ8aPhtcEnqt+RDQ5LUz9CQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1mzE0krw6yb1J/ibJgSSfaPVzktyT5GCSLyc5vdXPaOsTbfu6oWNd0+qPJrloqL651SaSbJ//YUqS5kPPlcYLwIVV9Q5gA7A5yUbgs8D1VbUeeBa4srW/Eni2qt4CXN/akeRc4DLgbcBm4AtJliVZBnweuBg4F7i8tX1F+X0NSZrZjKFRAz9rq6e1pYALgTtafSdwaXu/pa3Ttr8vSVr9tqp6oaoeByaA89syUVWPVdUvgNtaW0nSItP1TKNdETwAPAPsBX4APFdVL7Ymh4DV7f1q4EmAtv154A3D9Sn7HKsuSVpkukKjql6qqg3AGgZXBm8d1ay95hjbjrf+Mkm2JdmfZP+RI0dm7rgkaV4d1+ypqnoO+EtgI7AiyfK2aQ3wVHt/CFgL0Lb/BnB0uD5ln2PVR33+TVU1XlXjY2Njx9N1SdI86Jk9NZZkRXv/GuD9wCPA3cAHWrOtwJ3t/a62Ttv+zaqqVr+sza46B1gP3AvcB6xvs7FOZ/CwfNd8DE6SNL+Wz9yEVcDONsvpVcDtVXVXku8BtyX5NPBd4ObW/mbgT5NMMLjCuAygqg4kuR34HvAicFVVvQSQ5GpgD7AM2FFVB+ZthNNwxpQkHZ8ZQ6OqHgTeOaL+GIPnG1Pr/w/44DGOdR1w3Yj6bmB3R38lSQvIb4RLkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaAzxG+KSND1DQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUbcbQSLI2yd1JHklyIMlHWv0PkvwoyQNtuWRon2uSTCR5NMlFQ/XNrTaRZPtQ/Zwk9yQ5mOTLSU6f74FKkuau50rjReBjVfVWYCNwVZJz27brq2pDW3YDtG2XAW8DNgNfSLIsyTLg88DFwLnA5UPH+Ww71nrgWeDKeRqfJGkezRgaVXW4qv66vf8p8AiweppdtgC3VdULVfU4MAGc35aJqnqsqn4B3AZsSRLgQuCOtv9O4NLZDkiSdOIc1zONJOuAdwL3tNLVSR5MsiPJylZbDTw5tNuhVjtW/Q3Ac1X14pS6JGmR6Q6NJK8DvgJ8tKp+AtwI/CawATgM/OFk0xG71yzqo/qwLcn+JPuPHDnS23VJ0jzpCo0kpzEIjC9W1VcBqurpqnqpqn4J/DGD208wuFJYO7T7GuCpaeo/BlYkWT6l/jJVdVNVjVfV+NjYWE/XJUnzqGf2VICbgUeq6nND9VVDzX4HeLi93wVcluSMJOcA64F7gfuA9W2m1OkMHpbvqqoC7gY+0PbfCtw5t2FJkk6E5TM34T3A7wIPJXmg1X6fweynDQxuJT0B/B5AVR1IcjvwPQYzr66qqpcAklwN7AGWATuq6kA73seB25J8Gvgug5CSJC0yM4ZGVX2L0c8ddk+zz3XAdSPqu0ftV1WP8evbW5KkRcpvhEuSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkrot2dBYt/3rC90FSTrpLNnQkCQdP0NDktTN0JAkdTM0JEndZgyNJGuT3J3kkSQHknyk1c9MsjfJwfa6stWT5IYkE0keTHLe0LG2tvYHk2wdqr8ryUNtnxuS5EQMVpI0Nz1XGi8CH6uqtwIbgauSnAtsB/ZV1XpgX1sHuBhY35ZtwI0wCBngWuAC4Hzg2smgaW22De23ee5DkyTNtxlDo6oOV9Vft/c/BR4BVgNbgJ2t2U7g0vZ+C3BrDXwHWJFkFXARsLeqjlbVs8BeYHPb9vqq+nZVFXDr0LEkSYvIcT3TSLIOeCdwD/CmqjoMg2AB3tiarQaeHNrtUKtNVz80oi5JWmS6QyPJ64CvAB+tqp9M13RErWZRH9WHbUn2J9l/5MiRmbosSZpnXaGR5DQGgfHFqvpqKz/dbi3RXp9p9UPA2qHd1wBPzVBfM6L+MlV1U1WNV9X42NhYT9clSfOoZ/ZUgJuBR6rqc0ObdgGTM6C2AncO1a9os6g2As+321d7gE1JVrYH4JuAPW3bT5NsbJ91xdCxJEmLyPKONu8Bfhd4KMkDrfb7wGeA25NcCfwQ+GDbthu4BJgAfg58CKCqjib5FHBfa/fJqjra3n8YuAV4DfCNtkiSFpkZQ6OqvsXo5w4A7xvRvoCrjnGsHcCOEfX9wNtn6oskaWH5jfAR/AVcSRrN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdD4xj8/9SQpJczNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd1mDI0kO5I8k+ThodofJPlRkgfacsnQtmuSTCR5NMlFQ/XNrTaRZPtQ/Zwk9yQ5mOTLSU6fzwFKkuZPz5XGLcDmEfXrq2pDW3YDJDkXuAx4W9vnC0mWJVkGfB64GDgXuLy1BfhsO9Z64FngyrkMSJJ04swYGlX1V8DRzuNtAW6rqheq6nFgAji/LRNV9VhV/QK4DdiSJMCFwB1t/53Apcc5BknSK2QuzzSuTvJgu321stVWA08OtTnUaseqvwF4rqpenFKXJC1Csw2NG4HfBDYAh4E/bPWMaFuzqI+UZFuS/Un2Hzly5Ph6LEmas1mFRlU9XVUvVdUvgT9mcPsJBlcKa4eargGemqb+Y2BFkuVT6sf63JuqaryqxsfGxmbTdUnSHMwqNJKsGlr9HWByZtUu4LIkZyQ5B1gP3AvcB6xvM6VOZ/CwfFdVFXA38IG2/1bgztn0SZJ04i2fqUGSLwHvBc5Kcgi4Fnhvkg0MbiU9AfweQFUdSHI78D3gReCqqnqpHedqYA+wDNhRVQfaR3wcuC3Jp4HvAjfP2+gkSfNqxtCoqstHlI/5X+xVdR1w3Yj6bmD3iPpj/Pr2liRpEfMb4ZKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhsY01m3/+kJ3QZIWFUNDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNKZwmq0kHZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6jZjaCTZkeSZJA8P1c5MsjfJwfa6stWT5IYkE0keTHLe0D5bW/uDSbYO1d+V5KG2zw1JMt+DlCTNj54rjVuAzVNq24F9VbUe2NfWAS4G1rdlG3AjDEIGuBa4ADgfuHYyaFqbbUP7Tf0sSdIiMWNoVNVfAUenlLcAO9v7ncClQ/Vba+A7wIokq4CLgL1VdbSqngX2ApvbttdX1berqoBbh44lSVpkZvtM401VdRigvb6x1VcDTw61O9Rq09UPjahLkhah+X4QPup5RM2iPvrgybYk+5PsP3LkyCy7KEmardmGxtPt1hLt9ZlWPwSsHWq3BnhqhvqaEfWRquqmqhqvqvGxsbFZdl2SNFuzDY1dwOQMqK3AnUP1K9osqo3A8+321R5gU5KV7QH4JmBP2/bTJBvbrKkrho61KPhbVJL0a8tnapDkS8B7gbOSHGIwC+ozwO1JrgR+CHywNd8NXAJMAD8HPgRQVUeTfAq4r7X7ZFVNPlz/MIMZWq8BvtEWSdIiNGNoVNXlx9j0vhFtC7jqGMfZAewYUd8PvH2mfkiSFp7fCJckdTM0JEndDA1JUjdDo4MzqCRpwNCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktRtSYaGX9aTpNlZkqEhSZodQ0OS1M3QkCR1MzQ6+RxEkgwNSdJxMDQkSd0MDUlSN0PjOPhcQ9JSZ2hIkrrNKTSSPJHkoSQPJNnfamcm2ZvkYHtd2epJckOSiSQPJjlv6DhbW/uDSbbObUiSpBNlPq40/kVVbaiq8ba+HdhXVeuBfW0d4GJgfVu2ATfCIGSAa4ELgPOBayeDRpK0uJyI21NbgJ3t/U7g0qH6rTXwHWBFklXARcDeqjpaVc8Ce4HNJ6BfkqQ5mmtoFPA/k9yfZFurvamqDgO01ze2+mrgyaF9D7XaseqSpEVm+Rz3f09VPZXkjcDeJN+fpm1G1Gqa+ssPMAimbQBnn3328fZVkjRHc7rSqKqn2uszwNcYPJN4ut12or0+05ofAtYO7b4GeGqa+qjPu6mqxqtqfGxsbC5dnzWn3UpaymYdGklem+QfTr4HNgEPA7uAyRlQW4E72/tdwBVtFtVG4Pl2+2oPsCnJyvYAfFOrSZIWmbncnnoT8LUkk8f5s6r6iyT3AbcnuRL4IfDB1n43cAkwAfwc+BBAVR1N8ingvtbuk1V1dA79kiSdILMOjap6DHjHiPr/Ad43ol7AVcc41g5gx2z7Ikl6ZfiNcElSN0NDktTN0JgFZ1BJWqoMDUlSN0NDktTN0Jglb1FJWooMDUlSN0NDktTN0JAkdTM05sDnGpKWGkNDktTN0JAkdTM0JEndDI058rmGpKXE0JgHBoekpcLQkCR1MzQkSd0MjXniLSpJS4GhIUnqZmjMM684JJ3KDI0TwOCQdKoyNE4Qg0PSqWjRhEaSzUkeTTKRZPtC92c2pgbFuu1fNzwknVIWRWgkWQZ8HrgYOBe4PMm5C9ur+WN4SDpVLIrQAM4HJqrqsar6BXAbsGWB+zTvJsNjMkAMEkknm+UL3YFmNfDk0Poh4IIF6ssr4niD44nP/NbL2j7xmd+a935J0nQWS2hkRK1e1ijZBmxrqz9L8ugsP+8s4Mez3HdB5LN9tQ4n3djn0VIeOyzt8S/lscPfH/8/nsuBFktoHALWDq2vAZ6a2qiqbgJumuuHJdlfVeNzPc7JyLEvzbHD0h7/Uh47zO/4F8szjfuA9UnOSXI6cBmwa4H7JEmaYlFcaVTVi0muBvYAy4AdVXVggbslSZpiUYQGQFXtBna/Qh8351tcJzHHvnQt5fEv5bHDPI4/VS973ixJ0kiL5ZmGJOkksKRC41T4qZLpJFmb5O4kjyQ5kOQjrX5mkr1JDrbXla2eJDe0v8eDSc5b2BHMXZJlSb6b5K62fk6Se9rYv9wmWpDkjLY+0bavW8h+z4ckK5LckeT77d/Au5fKuU/y79u/+YeTfCnJq0/lc59kR5Jnkjw8VDvuc51ka2t/MMnWns9eMqFxqv9USfMi8LGqeiuwEbiqjXE7sK+q1gP72joM/hbr27INuPGV7/K8+wjwyND6Z4Hr29ifBa5s9SuBZ6vqLcD1rd3J7r8Bf1FV/xR4B4O/wyl/7pOsBv4dMF5Vb2cwmeYyTu1zfwuweUrtuM51kjOBaxl8kfp84NrJoJlWVS2JBXg3sGdo/RrgmoXu1wke853AvwQeBVa12irg0fb+j4DLh9r/qt3JuDD4fs8+4ELgLgZfGv0xsHzqvwEGM/Xe3d4vb+2y0GOYw9hfDzw+dQxL4dzz61+UOLOdy7uAi071cw+sAx6e7bkGLgf+aKj+99oda1kyVxqM/qmS1QvUlxOuXXK/E7gHeFNVHQZor29szU61v8l/Bf4j8Mu2/gbguap6sa0Pj+9XY2/bn2/tT1ZvBo4Af9Juz/33JK9lCZz7qvoR8F+AHwKHGZzL+1k6537S8Z7rWf0bWEqh0fVTJaeCJK8DvgJ8tKp+Ml3TEbWT8m+S5F8Bz1TV/cPlEU2rY9vJaDlwHnBjVb0T+L/8+vbEKKfM+NstlS3AOcA/Al7L4JbMVKfquZ/JscY7q7/DUgqNrp8qOdklOY1BYHyxqr7ayk8nWdW2rwKeafVT6W/yHuC3kzzB4FeSL2Rw5bEiyeT3kYbH96uxt+2/ARx9JTs8zw4Bh6rqnrZ+B4MQWQrn/v3A41V1pKr+Dvgq8M9YOud+0vGe61n9G1hKoXHK/1RJkgA3A49U1eeGNu0CJmdGbGXwrGOyfkWbXbEReH7y8vZkU1XXVNWaqlrH4Nx+s6r+NXA38IHWbOrYJ/8mH2jtT9r/tVlVfws8meSftNL7gO+xBM49g9tSG5P8g/afgcmxL4lzP+R4z/UeYFOSle1qbVOrTW+hH+a8wg+OLgH+F/AD4D8tdH9OwPj+OYPLyweBB9pyCYP7tfuAg+31zNY+DGaU/QB4iMHskwUfxzz8Hd4L3NXevxm4F5gA/gdwRqu/uq1PtO1vXuh+z8O4NwD72/n/c2DlUjn3wCeA7wMPA38KnHEqn3vgSwye3/wdgyuGK2dzroF/0/4OE8CHej7bb4RLkrotpdtTkqQ5MjQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LU7f8Dn4FkA7m9xT0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdb9c2b1908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h_w = plt.hist(words_per_sents_lengths, bins=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.041184586362728"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(words_per_sents_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "961"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(words_per_sents_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.656008276804595"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(words_per_sents_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAD8CAYAAACyyUlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAE0xJREFUeJzt3X+s3fV93/Hnazik+Y0JDnKxNdPWS8OixiEWccdUpbCCQVNNJNhMp2BFTO4y2JKp0mo6aaRJK6VSm2xoHRUdHhBlEErIsAKp6zpM1aaEcJ0QMHGp7wiDGzzsxISwRUsLee+P87nK8c25vtf3Y+45Tp4P6eh8z/t8vp/P+95zzCvn+/2em1QVkiT1+FvjbkCSdOozTCRJ3QwTSVI3w0SS1M0wkSR1M0wkSd0ME0lSN8NEktRtwTBJsjbJg0kOJHk8yQdb/cNJvpnkkXa7fGifG5JMJ3kiyaVD9c2tNp1kx1D93CQPJTmY5NNJTm/1V7fH0+35dQutIUlaflnoG/BJVgOrq+orSd4A7AOuAP4R8H+q6vfnjD8PuBO4APhp4M+Bv9Oe/ivgV4AZ4GHg6qr6epK7gXur6q4kfwR8rapuTvLPgV+oqn+WZCvw3qr6x/OtUVUvz/dznHXWWbVu3brF/2YkSezbt+9bVbVqoXErFhpQVYeAQ237xSQHgHOOs8sW4K6q+j7wjSTTDP6jDzBdVU8CJLkL2NLmuwj4tTbmduDDwM1trg+3+j3Af0iS46zxxfmaWrduHVNTUwv9uJKkIUn+12LGndA5k3aY6Z3AQ610fZJHk+xMsrLVzgGeGdptptXmq78Z+E5VvTSnfsxc7fkX2vj55pIkjcGiwyTJ64HPAB+qqu8y+OTws8AGBp9c/mB26Ijdawn1pcw1t+ftSaaSTB05cmTELpKkk2FRYZLkVQyC5FNVdS9AVT1XVS9X1Q+AP+aHh7JmgLVDu68Bnj1O/VvAGUlWzKkfM1d7/k3A0ePMdYyquqWqNlbVxlWrFjzkJ0laosVczRXgVuBAVX18qL56aNh7gf1texewtV2JdS6wHvgygxPu69uVW6cDW4FdNbgC4EHgyrb/NuC+obm2te0rgS+08fOtIUkagwVPwAMXAu8DHkvySKv9FnB1kg0MDi89Bfw6QFU93q7O+jrwEnDd7FVWSa4HdgOnATur6vE2328CdyX5HeCrDMKLdv/JdoL9KIMAOu4akqTlt+ClwT8uNm7cWF7NJUknJsm+qtq40Di/AS9J6maYSJK6GSaSpG6GiSSpm2EiSepmmEiSuhkmkqRuhokkqZthIknqZphIkroZJpKkboaJJKmbYSJJ6maYSJK6GSaSpG6GiSSpm2EiSepmmEiSuhkmkqRuhokkqZthIknqZphIkroZJpKkboaJJKmbYSJJ6maYnGTrdtw/7hYkadkZJpKkboaJJKmbYSJJ6maYSJK6GSaSpG6GiSSpm2EiSepmmEiSui0YJknWJnkwyYEkjyf5YKufmWRPkoPtfmWrJ8lNSaaTPJrk/KG5trXxB5NsG6q/K8ljbZ+bkmSpa0iSlt9iPpm8BPxGVb0N2ARcl+Q8YAewt6rWA3vbY4DLgPXtth24GQbBANwIvBu4ALhxNhzamO1D+21u9RNaQ5I0HguGSVUdqqqvtO0XgQPAOcAW4PY27Hbgira9BbijBr4EnJFkNXApsKeqjlbV88AeYHN77o1V9cWqKuCOOXOdyBqSpDE4oXMmSdYB7wQeAs6uqkMwCBzgLW3YOcAzQ7vNtNrx6jMj6ixhDUnSGCw6TJK8HvgM8KGq+u7xho6o1RLqx21nMfsk2Z5kKsnUkSNHFphSkrRUiwqTJK9iECSfqqp7W/m52UNL7f5wq88Aa4d2XwM8u0B9zYj6UtY4RlXdUlUbq2rjqlWrFvOjSpKWYDFXcwW4FThQVR8femoXMHtF1jbgvqH6Ne2Kq03AC+0Q1W7gkiQr24n3S4Dd7bkXk2xqa10zZ64TWUOSNAYrFjHmQuB9wGNJHmm13wI+Btyd5FrgaeCq9twDwOXANPA94P0AVXU0yUeBh9u4j1TV0bb9AeA24DXA59uNE11DkjQeC4ZJVf13Rp+jALh4xPgCrptnrp3AzhH1KeDtI+rfPtE1JEnLz2/AS5K6GSaSpG6GiSSpm2EiSepmmEiSuhkmkqRuhokkqZthIknqZphIkroZJpKkbobJEqzbcf+4W5CkiWKYSJK6GSaSpG6GiSSpm2EiSepmmCyCJ9wl6fgME0lSN8NEktTNMJEkdTNMJEndDBNJUjfDRJLUzTCRJHUzTCRJ3QwTSVI3w0SS1M0wkSR1M0wkSd0ME0lSN8NEktTNMJEkdTNMJEndDBNJUjfDRJLUbcEwSbIzyeEk+4dqH07yzSSPtNvlQ8/dkGQ6yRNJLh2qb2616SQ7hurnJnkoycEkn05yequ/uj2ebs+vW2gNSdJ4LOaTyW3A5hH1T1TVhnZ7ACDJecBW4O+2ff5jktOSnAb8IXAZcB5wdRsL8HttrvXA88C1rX4t8HxV/RzwiTZu3jVO7MeWJJ1MC4ZJVf0FcHSR820B7qqq71fVN4Bp4IJ2m66qJ6vqr4G7gC1JAlwE3NP2vx24Ymiu29v2PcDFbfx8a0iSxqTnnMn1SR5th8FWtto5wDNDY2Zabb76m4HvVNVLc+rHzNWef6GNn28uSdKYLDVMbgZ+FtgAHAL+oNUzYmwtob6UuX5Eku1JppJMHTlyZNQQSdJJsKQwqarnqurlqvoB8Mf88DDTDLB2aOga4Nnj1L8FnJFkxZz6MXO159/E4HDbfHON6vOWqtpYVRtXrVq1lB9VkrQISwqTJKuHHr4XmL3SaxewtV2JdS6wHvgy8DCwvl25dTqDE+i7qqqAB4Er2/7bgPuG5trWtq8EvtDGz7eGJGlMViw0IMmdwHuAs5LMADcC70mygcHhpaeAXweoqseT3A18HXgJuK6qXm7zXA/sBk4DdlbV422J3wTuSvI7wFeBW1v9VuCTSaYZfCLZutAakqTxWDBMqurqEeVbR9Rmx/8u8Lsj6g8AD4yoP8mIq7Gq6v8BV53IGpKk8fAb8JKkboaJJKmbYSJJ6maYSJK6GSaSpG6GiSSpm2EiSepmmEiSuhkmkqRuhokkqZthIknqZphIkroZJpKkboaJJKmbYSJJ6maYSJK6GSaSpG6GiSSpm2EiSepmmEiSuhkmkqRuhokkqZthIknqZphIkroZJpKkboaJJKmbYSJJ6maYSJK6GSaSpG6GiSSpm2EiSepmmEiSuhkmkqRuhokkqduCYZJkZ5LDSfYP1c5MsifJwXa/stWT5KYk00keTXL+0D7b2viDSbYN1d+V5LG2z01JstQ1JEnjsZhPJrcBm+fUdgB7q2o9sLc9BrgMWN9u24GbYRAMwI3Au4ELgBtnw6GN2T603+alrCFJGp8Fw6Sq/gI4Oqe8Bbi9bd8OXDFUv6MGvgSckWQ1cCmwp6qOVtXzwB5gc3vujVX1xaoq4I45c53IGpKkMVnqOZOzq+oQQLt/S6ufAzwzNG6m1Y5XnxlRX8oakqQxOdkn4DOiVkuoL2WNHx2YbE8ylWTqyJEjC0wrSVqqpYbJc7OHltr94VafAdYOjVsDPLtAfc2I+lLW+BFVdUtVbayqjatWrTqhH1CStHhLDZNdwOwVWduA+4bq17QrrjYBL7RDVLuBS5KsbCfeLwF2t+deTLKpXcV1zZy5TmSNU8K6HfePuwVJOulWLDQgyZ3Ae4CzkswwuCrrY8DdSa4FngauasMfAC4HpoHvAe8HqKqjST4KPNzGfaSqZk/qf4DBFWOvAT7fbpzoGpKk8VkwTKrq6nmeunjE2AKum2eencDOEfUp4O0j6t8+0TUkSePhN+AlSd0ME0lSN8NEktTNMJEkdTNMJEndDBNJUjfDRJLUzTCRJHUzTCRJ3QwTSVI3w0SS1M0wkSR1M0wkSd0ME0lSN8NEktTNMBkz/58XJf04MEwkSd0ME0lSN8NEktTNMJEkdTNMJEndDBNJUjfDRJLUzTCRJHUzTCRJ3QwTSVI3w0SS1M0wkSR1M0wkSd0ME0lSN8NEktTNMJEkdTNMJEndDBNJUreuMEnyVJLHkjySZKrVzkyyJ8nBdr+y1ZPkpiTTSR5Ncv7QPNva+INJtg3V39Xmn2775nhrSJLG42R8MvnlqtpQVRvb4x3A3qpaD+xtjwEuA9a323bgZhgEA3Aj8G7gAuDGoXC4uY2d3W/zAmtIksbglTjMtQW4vW3fDlwxVL+jBr4EnJFkNXApsKeqjlbV88AeYHN77o1V9cWqKuCOOXONWkOSNAa9YVLAnyXZl2R7q51dVYcA2v1bWv0c4JmhfWda7Xj1mRH1460hSRqD3jC5sKrOZ3AI67okv3ScsRlRqyXUFy3J9iRTSaaOHDlyIruOzbod94+7BUk6YV1hUlXPtvvDwGcZnPN4rh2iot0fbsNngLVDu68Bnl2gvmZEneOsMbe/W6pqY1VtXLVq1VJ/TEnSApYcJklel+QNs9vAJcB+YBcwe0XWNuC+tr0LuKZd1bUJeKEdotoNXJJkZTvxfgmwuz33YpJN7Squa+bMNWoNSdIYrOjY92zgs+1q3RXAf6mqP03yMHB3kmuBp4Gr2vgHgMuBaeB7wPsBqupoko8CD7dxH6mqo237A8BtwGuAz7cbwMfmWUOSNAZLDpOqehJ4x4j6t4GLR9QLuG6euXYCO0fUp4C3L3YNSdJ4+A14SVI3w0SS1M0wkSR1M0wkSd0ME0lSN8NEktTNMJEkdTNMJEndDBNJUjfDRJLUzTCRJHUzTCRJ3QwTSVI3w0SS1M0wkSR1M0wkSd0ME0lSN8NEktTNMJEkdTNMJEndDBNJUjfDRJLUzTCRJHUzTCRJ3QwTSVI3w0SS1M0wkSR1M0wkSd0ME0lSN8NEktTNMJEkdTNMJEndDJMfI+t23D/uFiT9hDJMJEndTukwSbI5yRNJppPsGHc/k8ZPKpKWyykbJklOA/4QuAw4D7g6yXnj7UqSfjKdsmECXABMV9WTVfXXwF3AljH3NNH8pCLplXIqh8k5wDNDj2daTYu0ULgYPpIWK1U17h6WJMlVwKVV9U/b4/cBF1TVvxgasx3Y3h6+FXjiBJY4C/jWSWr3ZJrUvmBye5vUvmBye5vUvmBye5vUvqCvt79dVasWGrRiiZNPghlg7dDjNcCzwwOq6hbglqVMnmSqqjYuvb1XxqT2BZPb26T2BZPb26T2BZPb26T2BcvT26l8mOthYH2Sc5OcDmwFdo25J0n6iXTKfjKpqpeSXA/sBk4DdlbV42NuS5J+Ip2yYQJQVQ8AD7xC0y/p8NgymNS+YHJ7m9S+YHJ7m9S+YHJ7m9S+YBl6O2VPwEuSJsepfM5EkjQhDJM5JulPtCTZmeRwkv1DtTOT7ElysN2vHENfa5M8mORAkseTfHCCevupJF9O8rXW22+3+rlJHmq9fbpdtLHskpyW5KtJPjdhfT2V5LEkjySZarVJeD3PSHJPkr9s77dfnJC+3tp+V7O37yb50IT09q/ae39/kjvbv4lX/H1mmAyZwD/RchuweU5tB7C3qtYDe9vj5fYS8BtV9TZgE3Bd+z1NQm/fBy6qqncAG4DNSTYBvwd8ovX2PHDtGHoD+CBwYOjxpPQF8MtVtWHoEtJJeD3/PfCnVfXzwDsY/O7G3ldVPdF+VxuAdwHfAz477t6SnAP8S2BjVb2dwcVJW1mO91lVeWs34BeB3UOPbwBuGHNP64D9Q4+fAFa37dXAExPwe7sP+JVJ6w14LfAV4N0MvrC1YtTrvIz9rGHwH5iLgM8BmYS+2tpPAWfNqY319QTeCHyDdm53Uvoa0eclwP+YhN744V8GOZPBBVafAy5djveZn0yOdSr8iZazq+oQQLt/yzibSbIOeCfwEBPSWzuU9AhwGNgD/E/gO1X1Uhsyrtf13wH/GvhBe/zmCekLoIA/S7Kv/eUIGP/r+TPAEeA/t0OD/ynJ6yagr7m2Ane27bH2VlXfBH4feBo4BLwA7GMZ3meGybEyoublbvNI8nrgM8CHquq74+5nVlW9XIPDD2sY/EHQt40atpw9JfmHwOGq2jdcHjF0XO+3C6vqfAaHeK9L8ktj6mPYCuB84OaqeifwfxnPobZ5tXMPvwr8ybh7AWjnaLYA5wI/DbyOwWs610l/nxkmx1rwT7RMgOeSrAZo94fH0USSVzEIkk9V1b2T1NusqvoO8N8YnNc5I8ns96rG8bpeCPxqkqcY/IXrixh8Uhl3XwBU1bPt/jCDY/8XMP7XcwaYqaqH2uN7GITLuPsadhnwlap6rj0ed2//APhGVR2pqr8B7gX+HsvwPjNMjnUq/ImWXcC2tr2NwfmKZZUkwK3Agar6+IT1tirJGW37NQz+cR0AHgSuHFdvVXVDVa2pqnUM3ldfqKp/Mu6+AJK8LskbZrcZnAPYz5hfz6r638AzSd7aShcDXx93X3NczQ8PccH4e3sa2JTkte3f6ezv7JV/n43zxNUk3oDLgb9icJz934y5lzsZHPf8Gwb/K+1aBsfZ9wIH2/2ZY+jr7zP4mPwo8Ei7XT4hvf0C8NXW237g37b6zwBfBqYZHJJ49Rhf1/cAn5uUvloPX2u3x2ff9xPyem4Aptrr+V+BlZPQV+vttcC3gTcN1cbeG/DbwF+29/8ngVcvx/vMb8BLkrp5mEuS1M0wkSR1M0wkSd0ME0lSN8NEktTNMJEkdTNMJEndDBNJUrf/D0aPc5l+bHZVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdb9c339048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h_c = plt.hist(chars_per_words_lengths, bins=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.1543703580505831"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(chars_per_words_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(chars_per_words_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5948381551535209"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(chars_per_words_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /opt/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "all_texts = list(all_texts.apply(BeautifulSoup).apply(BeautifulSoup.get_text).apply(clean_str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /opt/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "train_texts = list(data_train.review.apply(BeautifulSoup).apply(BeautifulSoup.get_text).apply(clean_str))\n",
    "test_texts = list(data_test.review.apply(BeautifulSoup).apply(BeautifulSoup.get_text).apply(clean_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build char vocab (all text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocab_to_int, int_to_vocab = build_chars_vocab(all_texts)\n",
    "#np.savez('vocab_char-{}'.format(max_sent_len), vocab_to_int=vocab_to_int, int_to_vocab=int_to_vocab, max_sent_len=max_sent_len, min_sent_len=min_sent_len )\n",
    "char2int = vocab_to_int\n",
    "int2char = int_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = sorted(list(vocab_to_int))\n",
    "target_characters = sorted(list(vocab_to_int))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in all_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 25000\n",
      "Number of unique input tokens: 162\n",
      "Number of unique output tokens: 162\n",
      "Max sequence length for inputs: 14299\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:', len(all_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t': 2,\n",
       " '\\n': 3,\n",
       " ' ': 1,\n",
       " '!': 37,\n",
       " '#': 67,\n",
       " '$': 51,\n",
       " '%': 60,\n",
       " '&': 55,\n",
       " '(': 35,\n",
       " ')': 36,\n",
       " '*': 53,\n",
       " '+': 66,\n",
       " ',': 23,\n",
       " '-': 41,\n",
       " '.': 27,\n",
       " '/': 49,\n",
       " '0': 31,\n",
       " '1': 42,\n",
       " '2': 30,\n",
       " '3': 56,\n",
       " '4': 48,\n",
       " '5': 45,\n",
       " '6': 43,\n",
       " '7': 50,\n",
       " '8': 46,\n",
       " '9': 44,\n",
       " ':': 39,\n",
       " ';': 38,\n",
       " '<': 90,\n",
       " '=': 59,\n",
       " '>': 91,\n",
       " '?': 34,\n",
       " '@': 71,\n",
       " 'UNK': 0,\n",
       " '[': 62,\n",
       " ']': 63,\n",
       " '^': 89,\n",
       " '_': 72,\n",
       " '`': 57,\n",
       " 'a': 8,\n",
       " 'b': 28,\n",
       " 'c': 22,\n",
       " 'd': 16,\n",
       " 'e': 17,\n",
       " 'f': 12,\n",
       " 'g': 13,\n",
       " 'h': 7,\n",
       " 'i': 5,\n",
       " 'j': 19,\n",
       " 'k': 26,\n",
       " 'l': 9,\n",
       " 'm': 18,\n",
       " 'n': 15,\n",
       " 'o': 14,\n",
       " 'p': 29,\n",
       " 'q': 33,\n",
       " 'r': 21,\n",
       " 's': 10,\n",
       " 't': 6,\n",
       " 'u': 11,\n",
       " 'v': 20,\n",
       " 'w': 4,\n",
       " 'x': 32,\n",
       " 'y': 24,\n",
       " 'z': 25,\n",
       " '{': 96,\n",
       " '|': 105,\n",
       " '}': 97,\n",
       " '~': 65,\n",
       " '\\x80': 123,\n",
       " '\\x84': 70,\n",
       " '\\x85': 64,\n",
       " '\\x8d': 134,\n",
       " '\\x8e': 155,\n",
       " '\\x91': 102,\n",
       " '\\x95': 125,\n",
       " '\\x96': 47,\n",
       " '\\x97': 73,\n",
       " '\\x9a': 159,\n",
       " '\\x9e': 156,\n",
       " '\\xa0': 148,\n",
       " '¡': 93,\n",
       " '¢': 133,\n",
       " '£': 52,\n",
       " '¤': 152,\n",
       " '¦': 118,\n",
       " '§': 153,\n",
       " '¨': 40,\n",
       " '©': 144,\n",
       " 'ª': 145,\n",
       " '«': 130,\n",
       " '\\xad': 150,\n",
       " '®': 83,\n",
       " '°': 146,\n",
       " '³': 149,\n",
       " '´': 54,\n",
       " '·': 106,\n",
       " 'º': 151,\n",
       " '»': 131,\n",
       " '½': 82,\n",
       " '¾': 122,\n",
       " '¿': 115,\n",
       " 'ß': 127,\n",
       " 'à': 81,\n",
       " 'á': 75,\n",
       " 'â': 84,\n",
       " 'ã': 98,\n",
       " 'ä': 76,\n",
       " 'å': 119,\n",
       " 'æ': 92,\n",
       " 'ç': 85,\n",
       " 'è': 68,\n",
       " 'é': 58,\n",
       " 'ê': 61,\n",
       " 'ë': 110,\n",
       " 'ì': 112,\n",
       " 'í': 113,\n",
       " 'î': 116,\n",
       " 'ï': 80,\n",
       " 'ð': 117,\n",
       " 'ñ': 101,\n",
       " 'ò': 114,\n",
       " 'ó': 69,\n",
       " 'ô': 107,\n",
       " 'õ': 120,\n",
       " 'ö': 86,\n",
       " 'ø': 104,\n",
       " 'ù': 87,\n",
       " 'ú': 132,\n",
       " 'û': 121,\n",
       " 'ü': 88,\n",
       " 'ý': 129,\n",
       " 'þ': 128,\n",
       " 'č': 154,\n",
       " 'ğ': 124,\n",
       " 'ı': 74,\n",
       " 'ō': 108,\n",
       " 'ř': 126,\n",
       " 'ż': 157,\n",
       " 'א': 137,\n",
       " 'ג': 136,\n",
       " 'ו': 142,\n",
       " 'י': 135,\n",
       " 'כ': 139,\n",
       " 'ל': 138,\n",
       " 'מ': 141,\n",
       " 'ן': 143,\n",
       " 'ר': 140,\n",
       " '–': 78,\n",
       " '‘': 79,\n",
       " '’': 77,\n",
       " '“': 99,\n",
       " '”': 100,\n",
       " '…': 103,\n",
       " '″': 111,\n",
       " '₤': 109,\n",
       " '▼': 158,\n",
       " '★': 160,\n",
       " '、': 95,\n",
       " '\\uf04a': 161,\n",
       " '\\uf0b7': 147,\n",
       " '，': 94}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'UNK',\n",
       " 1: ' ',\n",
       " 2: '\\t',\n",
       " 3: '\\n',\n",
       " 4: 'w',\n",
       " 5: 'i',\n",
       " 6: 't',\n",
       " 7: 'h',\n",
       " 8: 'a',\n",
       " 9: 'l',\n",
       " 10: 's',\n",
       " 11: 'u',\n",
       " 12: 'f',\n",
       " 13: 'g',\n",
       " 14: 'o',\n",
       " 15: 'n',\n",
       " 16: 'd',\n",
       " 17: 'e',\n",
       " 18: 'm',\n",
       " 19: 'j',\n",
       " 20: 'v',\n",
       " 21: 'r',\n",
       " 22: 'c',\n",
       " 23: ',',\n",
       " 24: 'y',\n",
       " 25: 'z',\n",
       " 26: 'k',\n",
       " 27: '.',\n",
       " 28: 'b',\n",
       " 29: 'p',\n",
       " 30: '2',\n",
       " 31: '0',\n",
       " 32: 'x',\n",
       " 33: 'q',\n",
       " 34: '?',\n",
       " 35: '(',\n",
       " 36: ')',\n",
       " 37: '!',\n",
       " 38: ';',\n",
       " 39: ':',\n",
       " 40: '¨',\n",
       " 41: '-',\n",
       " 42: '1',\n",
       " 43: '6',\n",
       " 44: '9',\n",
       " 45: '5',\n",
       " 46: '8',\n",
       " 47: '\\x96',\n",
       " 48: '4',\n",
       " 49: '/',\n",
       " 50: '7',\n",
       " 51: '$',\n",
       " 52: '£',\n",
       " 53: '*',\n",
       " 54: '´',\n",
       " 55: '&',\n",
       " 56: '3',\n",
       " 57: '`',\n",
       " 58: 'é',\n",
       " 59: '=',\n",
       " 60: '%',\n",
       " 61: 'ê',\n",
       " 62: '[',\n",
       " 63: ']',\n",
       " 64: '\\x85',\n",
       " 65: '~',\n",
       " 66: '+',\n",
       " 67: '#',\n",
       " 68: 'è',\n",
       " 69: 'ó',\n",
       " 70: '\\x84',\n",
       " 71: '@',\n",
       " 72: '_',\n",
       " 73: '\\x97',\n",
       " 74: 'ı',\n",
       " 75: 'á',\n",
       " 76: 'ä',\n",
       " 77: '’',\n",
       " 78: '–',\n",
       " 79: '‘',\n",
       " 80: 'ï',\n",
       " 81: 'à',\n",
       " 82: '½',\n",
       " 83: '®',\n",
       " 84: 'â',\n",
       " 85: 'ç',\n",
       " 86: 'ö',\n",
       " 87: 'ù',\n",
       " 88: 'ü',\n",
       " 89: '^',\n",
       " 90: '<',\n",
       " 91: '>',\n",
       " 92: 'æ',\n",
       " 93: '¡',\n",
       " 94: '，',\n",
       " 95: '、',\n",
       " 96: '{',\n",
       " 97: '}',\n",
       " 98: 'ã',\n",
       " 99: '“',\n",
       " 100: '”',\n",
       " 101: 'ñ',\n",
       " 102: '\\x91',\n",
       " 103: '…',\n",
       " 104: 'ø',\n",
       " 105: '|',\n",
       " 106: '·',\n",
       " 107: 'ô',\n",
       " 108: 'ō',\n",
       " 109: '₤',\n",
       " 110: 'ë',\n",
       " 111: '″',\n",
       " 112: 'ì',\n",
       " 113: 'í',\n",
       " 114: 'ò',\n",
       " 115: '¿',\n",
       " 116: 'î',\n",
       " 117: 'ð',\n",
       " 118: '¦',\n",
       " 119: 'å',\n",
       " 120: 'õ',\n",
       " 121: 'û',\n",
       " 122: '¾',\n",
       " 123: '\\x80',\n",
       " 124: 'ğ',\n",
       " 125: '\\x95',\n",
       " 126: 'ř',\n",
       " 127: 'ß',\n",
       " 128: 'þ',\n",
       " 129: 'ý',\n",
       " 130: '«',\n",
       " 131: '»',\n",
       " 132: 'ú',\n",
       " 133: '¢',\n",
       " 134: '\\x8d',\n",
       " 135: 'י',\n",
       " 136: 'ג',\n",
       " 137: 'א',\n",
       " 138: 'ל',\n",
       " 139: 'כ',\n",
       " 140: 'ר',\n",
       " 141: 'מ',\n",
       " 142: 'ו',\n",
       " 143: 'ן',\n",
       " 144: '©',\n",
       " 145: 'ª',\n",
       " 146: '°',\n",
       " 147: '\\uf0b7',\n",
       " 148: '\\xa0',\n",
       " 149: '³',\n",
       " 150: '\\xad',\n",
       " 151: 'º',\n",
       " 152: '¤',\n",
       " 153: '§',\n",
       " 154: 'č',\n",
       " 155: '\\x8e',\n",
       " 156: '\\x9e',\n",
       " 157: 'ż',\n",
       " 158: '▼',\n",
       " 159: '\\x9a',\n",
       " 160: '★',\n",
       " 161: '\\uf04a'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(int_to_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train review model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load documents data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_SENTS_PER_DOC = 21\n",
      "\n",
      "MAX_WORDS_PER_SENT = 26\n",
      "\n",
      "MAX_CHARS_PER_WORD = 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MAX_SENTS_PER_DOC = int(np.mean(sents_per_docs_lengths)) + 1\n",
    "MAX_WORDS_PER_SENT = int(np.mean(words_per_sents_lengths)) + 1\n",
    "MAX_CHARS_PER_WORD = int(np.mean(chars_per_words_lengths)) + 1\n",
    "\n",
    "#MAX_SENTS_PER_DOC = 10\n",
    "#MAX_WORDS_PER_SENT = 40\n",
    "#MAX_CHARS_PER_WORD = 20\n",
    "print('MAX_SENTS_PER_DOC = ' + str(MAX_SENTS_PER_DOC) + '\\n')\n",
    "print('MAX_WORDS_PER_SENT = ' + str(MAX_WORDS_PER_SENT) + '\\n')\n",
    "print('MAX_CHARS_PER_WORD = ' + str(MAX_CHARS_PER_WORD) + '\\n')\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "EMBEDDING_DIM = 50\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize documents data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_data, train_targets = vectorize_sentences_data(input_texts=train_texts, \n",
    "                                                               target_labels=list(data_train.sentiment), \n",
    "                                                               max_sents_per_doc=MAX_SENTS_PER_DOC, \n",
    "                                                               max_words_per_sent=MAX_WORDS_PER_SENT, \n",
    "                                                               max_chars_per_word=MAX_CHARS_PER_WORD, \n",
    "                                                               num_classes=NUM_CLASSES, \n",
    "                                                               char2int=char2int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_data, _ = vectorize_sentences_data(input_texts=test_texts, \n",
    "                                               target_labels=None, \n",
    "                                               max_sents_per_doc=MAX_SENTS_PER_DOC, \n",
    "                                               max_words_per_sent=MAX_WORDS_PER_SENT, \n",
    "                                               max_chars_per_word=MAX_CHARS_PER_WORD, \n",
    "                                               num_classes=NUM_CLASSES, \n",
    "                                               char2int=char2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 21, 26, 5)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 21, 26, 5)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"la...)`\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 162)         26244     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection [(None, None, 256), (None 297984    \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 256)               0         \n",
      "=================================================================\n",
      "Total params: 324,228\n",
      "Trainable params: 297,984\n",
      "Non-trainable params: 26,244\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"la...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 26, 5)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 26, 256)           324228    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection [(None, 26, 128), (None,  164352    \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 488,580\n",
      "Trainable params: 462,336\n",
      "Non-trainable params: 26,244\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"la...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 21, 26, 5)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 26, 5)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 26, 5)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 26, 5)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 26, 5)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 26, 5)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 26, 5)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 26, 5)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 26, 5)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 26, 5)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 26, 5)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 26, 5)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 26, 5)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 26, 5)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 26, 5)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 26, 5)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 26, 5)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 26, 5)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 26, 5)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 26, 5)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 26, 5)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 26, 5)        0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 128)          488580      lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "                                                                 lambda_10[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "                                                                 lambda_12[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "                                                                 lambda_14[0][0]                  \n",
      "                                                                 lambda_15[0][0]                  \n",
      "                                                                 lambda_16[0][0]                  \n",
      "                                                                 lambda_17[0][0]                  \n",
      "                                                                 lambda_18[0][0]                  \n",
      "                                                                 lambda_19[0][0]                  \n",
      "                                                                 lambda_20[0][0]                  \n",
      "                                                                 lambda_21[0][0]                  \n",
      "                                                                 lambda_22[0][0]                  \n",
      "                                                                 lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 128)       0           model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 128)       0           model_2[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 128)       0           model_2[3][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1, 128)       0           model_2[4][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1, 128)       0           model_2[5][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 1, 128)       0           model_2[6][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 1, 128)       0           model_2[7][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 1, 128)       0           model_2[8][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 1, 128)       0           model_2[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 1, 128)       0           model_2[10][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 1, 128)       0           model_2[11][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 1, 128)       0           model_2[12][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 1, 128)       0           model_2[13][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 1, 128)       0           model_2[14][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 1, 128)       0           model_2[15][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 1, 128)       0           model_2[16][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)            (None, 1, 128)       0           model_2[17][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_18 (Reshape)            (None, 1, 128)       0           model_2[18][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_19 (Reshape)            (None, 1, 128)       0           model_2[19][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_20 (Reshape)            (None, 1, 128)       0           model_2[20][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_21 (Reshape)            (None, 1, 128)       0           model_2[21][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 21, 128)      0           reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "                                                                 reshape_6[0][0]                  \n",
      "                                                                 reshape_7[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "                                                                 reshape_9[0][0]                  \n",
      "                                                                 reshape_10[0][0]                 \n",
      "                                                                 reshape_11[0][0]                 \n",
      "                                                                 reshape_12[0][0]                 \n",
      "                                                                 reshape_13[0][0]                 \n",
      "                                                                 reshape_14[0][0]                 \n",
      "                                                                 reshape_15[0][0]                 \n",
      "                                                                 reshape_16[0][0]                 \n",
      "                                                                 reshape_17[0][0]                 \n",
      "                                                                 reshape_18[0][0]                 \n",
      "                                                                 reshape_19[0][0]                 \n",
      "                                                                 reshape_20[0][0]                 \n",
      "                                                                 reshape_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) [(None, 21, 64), (No 41216       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 64)           0           bidirectional_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 529,796\n",
      "Trainable params: 503,552\n",
      "Non-trainable params: 26,244\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 21, 26, 5)         0         \n",
      "_________________________________________________________________\n",
      "model_3 (Model)              (None, 64)                529796    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 529,926\n",
      "Trainable params: 503,682\n",
      "Non-trainable params: 26,244\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "char2word_latent_dim = 128\n",
    "word2sent_latent_dim = 64\n",
    "sent2doc_latent_dim = 32\n",
    "char_vocab_size = len(char2int)\n",
    "\n",
    "#MAX_SENTS_PER_DOC = 11\n",
    "#MAX_WORDS_PER_SENT = 24\n",
    "#MAX_CHARS_PER_WORD = 5\n",
    "#_, _, _, encoder_word_embedding_model = build_chars2word_model(num_encoder_tokens=char_vocab_size, latent_dim=chars2word_latent_dim)\n",
    "encoder_word_embedding_model = build_chars2word_model_simple_BiLSTM(num_encoder_tokens=char_vocab_size, latent_dim=char2word_latent_dim)\n",
    "print(encoder_word_embedding_model.summary())\n",
    "'''\n",
    "_, _, _, encoder_sentence_embedding_model = build_words2sent_model(encoder_word_embedding_model, \n",
    "                                                                   max_words_seq_len=MAX_WORDS_PER_SENT, \n",
    "                                                                   max_char_seq_len=MAX_CHARS_PER_WORD,\n",
    "                                                                   latent_dim=words2sent_latent_dim)\n",
    "'''\n",
    "encoder_sentence_embedding_model = build_words2sent_model_simple_BiLSTM(encoder_word_embedding_model, \n",
    "                                                                   max_words_seq_len=MAX_WORDS_PER_SENT, \n",
    "                                                                   max_char_seq_len=MAX_CHARS_PER_WORD, \n",
    "                                                                   latent_dim=word2sent_latent_dim)\n",
    "print(encoder_sentence_embedding_model.summary())\n",
    "\n",
    "encoder_document_embedding_model = build_sent2doc_model(encoder_sentence_embedding_model, \n",
    "                                                 max_sents_seq_len=MAX_SENTS_PER_DOC, \n",
    "                                                 max_words_seq_len=MAX_WORDS_PER_SENT, \n",
    "                                                 max_char_seq_len=MAX_CHARS_PER_WORD, \n",
    "                                                 word2sent_latent_dim=word2sent_latent_dim,\n",
    "                                                 sent2doc_latent_dim=sent2doc_latent_dim)\n",
    "print(encoder_document_embedding_model.summary())\n",
    "model = build_hier_senti_model(encoder_document_embedding_model=encoder_document_embedding_model,\n",
    "                                max_sents_seq_len=MAX_SENTS_PER_DOC, \n",
    "                                max_words_seq_len=MAX_WORDS_PER_SENT, \n",
    "                                max_char_seq_len=MAX_CHARS_PER_WORD)\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "20000/20000 [==============================] - 1105s 55ms/step - loss: 5.9979e-04 - categorical_accuracy: 0.4273 - val_loss: 5.8734e-04 - val_categorical_accuracy: 0.9998\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.99980, saving model to best_hier_senti_model-21-26.hdf5\n",
      "Epoch 2/100\n",
      " 7808/20000 [==========>...................] - ETA: 11:41 - loss: 0.0010 - categorical_accuracy: 0.8030"
     ]
    }
   ],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 100\n",
    "lr = 0.01\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(lr=lr), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "#filepath=\"weights-improvement-{epoch:02d}-{val_categorical_accuracy:.2f}.hdf5\"\n",
    "filepath=\"best_hier_senti_model-{}-{}.hdf5\".format(MAX_SENTS_PER_DOC,MAX_WORDS_PER_SENT,MAX_CHARS_PER_WORD) # Save only the best model for inference step, as saving the epoch and metric might confuse the inference function which model to use\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "tbCallBack = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "callbacks_list = [checkpoint, tbCallBack]\n",
    "#callbacks_list = [checkpoint, tbCallBack, lrate]\n",
    "model.fit(train_input_data, train_targets,\n",
    "          #validation_data=(test_input_data, test_targets)\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_split=0.2,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, rev in enumerate(test_texts):\n",
    "    print(rev)\n",
    "    test_input = test_input_data[i].copy()\n",
    "    test_input = np.reshape(test_input, (1,test_input.shape[0], test_input.shape[1], test_input.shape[2]))\n",
    "    sentiment = np.argmax(model.predict(test_input))\n",
    "    print('Sentiment: ' + str(sentiment))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
